<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on 硕大的汤姆</title><link>https://chenminhua.github.io/posts/</link><description>Recent content in Posts on 硕大的汤姆</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 10 Feb 2026 20:00:08 +0800</lastBuildDate><atom:link href="https://chenminhua.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>置身事内</title><link>https://chenminhua.github.io/posts/2026_%E7%BD%AE%E8%BA%AB%E4%BA%8B%E5%86%85/</link><pubDate>Tue, 10 Feb 2026 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2026_%E7%BD%AE%E8%BA%AB%E4%BA%8B%E5%86%85/</guid><description>《置身事内》读书笔记。
我国规模超大，人口、面积、经济总量都与一个大洲的体量相当，各省份的规模也大都抵得上一个中型国家，广东和江苏相当于世界上第13和第14大经济体，超过西班牙和澳大利亚。山东、浙江、河南每一个单独计算都是世界前20大经济体，其中，河南仅次于荷兰。各个省相互之间差异极大：新疆的面积是海南的47倍；广东的人口是西藏的33倍，GDP总量是后者的62倍；北京的人均GDP是甘肃的5倍。这种经济发展水平的差异远大于美国各州。美国最富的纽约州人均GDP也不过是最穷的密西西比州的2.3倍。
在我国，政府不但影响“蛋糕”的分配，也参与“蛋糕”的生产，所以我们不可能脱离政府谈经济。
地方政府的权力与事务 中国的五级政府管理体系：中央—省—市—县区—乡镇。
央地关系历来是研究很多重大问题的主线。一方面，维持大一统的国家必然要求维护中央权威和统一领导；另一方面，中国之大又决定了政治体系的日常运作要以地方政府为主。
党和政府。中国共产党对政府的绝对领导是政治生活的主题。简单说来，党负责重大决策和人事任免，政府负责执行，但二者在组织上紧密交织、人员上高度重叠，很难严格区分。
条块分割，多重领导。我国政治体系的一个鲜明特点是“层层复制”：中央的主要政治架构，即党委、政府、人大、政协等，省、市、县三级都完全复制，即所谓“四套班子”。中央政府的主要部委，除外交部等个别例外，在各级政府中均有对应部门，比如中央政府有财政部、省政府有财政厅、市县政府有财政局等。这种从上到下的部门垂直关系，被称为“条条”，而横向的以行政区划为界的政府，被称为“块块”。大多数地方部门都要同时接受“条条”和“块块”的双重领导。拿县教育局来说，既要接受市教育局的指导，又要服从县委、县政府的领导。通常情况下，“条条”关系是业务关系，“块块”关系才是领导关系，因为地方党委和政府可以决定人事任免。
在复杂的行政体系中，权力高度分散在各部门，往往没有清晰的法律界限，所以一旦涉及跨部门或跨地区事务，办起来就比较复杂，常常理不清头绪，甚至面对相互矛盾的信息。部门之间也存在互相扯皮的问题，某件事只要有一个部门反对，就不容易办成。尤其当没有清楚的先例和流程时，办事人员会在部门之间“踢皮球”，或者干脆推给上级，所以权力与决策会自然而然向上集中。制度设计的一大任务就是要避免把过多决策推给上级，减轻上级负担，提高决策效率，所以体制内简化决策流程的原则之一，就是尽量在能达成共识的最低层级上解决问题。若是部门事务，本部门领导就可以决定；若是经常性的跨部门事务，则设置上级“分管领导”甚至“领导小组”来协调推进。比如经济事务，常常需要财政、工商、税务、发改委等多部门配合，因为发展经济是核心任务，所以地方大都有分管经济的领导，级别通常较高，比如常务副市长（一般是市委常委）。
外部性与规模经济 我国实行“属地管理”，地方事权与行政区划密不可分，所以我们先从行政区划角度来分析权力划分。影响行政区划的首要因素是“外部性”，这是个重要的经济学概念，简单来说就是人的行为影响到了别人。一件事情该不该由地方自主决定，可以从外部性的角度来考虑。若此事只影响本地，没有外部性，就该由本地全权处理；若还影响其他地方，那上级就该出面协调。
随着经济活动和人口集聚，需要打破现有的行政边界，在更大范围内提供无缝对接的标准化公共服务，所以就有了各种都市圈的规划，有些甚至上升到了国家战略，比如长三角一体化、京津冀一体化、粤港澳大湾区等。
我国经济中有个现象：处在行政交界（尤其是省交界处）的地区，经济发展普遍比较落后。省级的陆路交界线共66条，总长度5.2万公里，按边界两侧各15公里计算，总面积约156万平方公里，占国土面积的六分之一。然而，在2012年592个国家扶贫开发工作重点县中，却有超过一半位于省交界处，贫困发生率远高于非边界县。这一俗称“三不管地带”的现象，也可以用公共物品规模效应和边界的理论来解释。
行政边界影响经济发展，地方保护主义和市场分割现象今天依然存在，尤其在生产要素市场上，用地指标和户籍制度对土地和人口流动影响很大。从长期看，消除这种现象需要更深入的市场化改革。但在中短期内，调整行政区划、扩大城市规模乃至建设都市圈也能发挥作用。而且在像中国这样一个地区差异极大的大国，建设产品和要素的全国统一大市场必然是个长期过程，难免要先经过区域性整合。
复杂信息 绝大部分省份公布的GDP增长目标都会高于中央，而绝大多数地市的增长目标又会高于本省。比如2014年中央提出的增长目标是7.5%，但所有省设定的目标均高于7.5%，平均值是9.7%。到了市一级，将近九成的市级目标高于本省，平均值上涨到10.6%。这种“层层加码”现象的背后，既有上级层层施压和摊派的因素，也有下级为争取表现而主动加压的因素。但这些目标真能实现么？2017—2018年两年，不少省份（如辽宁、内蒙古、天津等）主动给GDP数字“挤水分”，幅度惊人，屡见报端。
正因为信息复杂多变，模糊不清的地方太多，而政府的繁杂事权又没有清楚的法律界定，所以体制内的实际权力和责任都高度个人化。我打个比方来说明规则模糊不清和权力个人化之间的关系。大学老师考核学生一般有两种方式：考试或写论文。若考卷都是标准化的选择题，那老师虽有出题的权力，但不能决定最后得分。但若考卷都是主观题，老师给分的自由度和权力就大一些。若是研究生毕业论文，不存在严格的客观判断标准，导师手中的权力就更大了，所以研究生称导师为“老板”，而不会称其他授课教师为“老板”。
因为信息复杂，不可信的信息比比皆是，而权力和责任又高度个人化，所以体制内的规章制度无法完全取代个人信任。上级在提拔下级时，除考虑工作能力外，关键岗位上都要尽量安排信得过的人。
招商引资 地方政府不仅可以为经济发展创造环境，它本身就是经济发展的深度参与者，这一点在招商引资过程中体现得淋漓尽致。
招商引资是地方政府的核心任务，是需要调动所有资源和手段去实现的目标。总的来说，对企业至关重要的生产要素，地方政府几乎都有很强的干预能力。其中土地直接归政府所有，资金则大多来自国有银行主导的金融体系和政府控制的其他渠道，比如国有投融资平台。对于劳动力，政府控制着户口，也掌握着教育和医疗等基本服务的供给，还掌握着土地供应，直接影响住房分配。而生产中的科技投入，也有相当大一部分来自公立大学和科研院所。除此之外，地方政府还有财税政策、产业政策、进出口政策等工具，都可能对企业产生重大影响。
这种“混合经济”体系，不是主流经济学教科书中所说的政府和市场的简单分工模式，即政府负责提供公共物品、市场主导其他资源配置；也不是简单的“政府搭台企业唱戏”模式。而是政府及其各类附属机构（国企、事业单位、大银行等）深度参与大多数生产和分配环节的模式。在我国，想脱离政府来了解经济，是不可能的。
财税与政府行为 事权下放，但财权上收。地方政府要负责修路、盖学校、搞治安（事权大），但手里能支配的钱却在减少。这种权责不对等，逼迫地方政府必须去寻找预算外的钱，为后来的“土地财政”埋下了伏笔。
自1994年实行分税制以来，地方财政预算支出就一直高于预算收入。近些年地方预算支出占全国预算支出的比重为85%，但收入的占比只有50%—55%，入不敷出的部分要通过中央转移支付来填补。
1994年分税制改革对政府行为和经济发展影响深远。
分税制改革 1994以前，地方政府是财政包干的，这导致中央财政预算收入占全国财政预算总收入的比重越来越低，而全国财政预算总收入占GDP的比重也越来越低（图2-2）。不仅中央变得越来越穷，财政整体也越来越穷。央地分成比例每隔几年就要重新谈判一次，若地方税收收入增长很快，下次谈判时可能会处于不利地位，落得一个更高的上缴基数和更吃亏的分成比例。为避免“鞭打快牛”，地方政府有意不让预算收入增长太快。另一方面，这也跟当时盛行的预算外收入有关。虽然地方预算内的税收收入要和中央分成，但预算外收入则可以独享。如果给企业减免税，“藏富于企业”，再通过其他诸如行政收费、集资、摊派、赞助等手段收一些回来，就可以避免和中央分成，变成可以完全自由支配的预算外收入。地方政府因此经常给本地企业违规减税，企业偷税漏税也非常普遍，税收收入自然上不去，但预算外收入却迅猛增长。
1994年的分税制改革把税收分为三类：中央税（如关税）、地方税（如营业税）、共享税（如增值税）。同时分设国税、地税两套机构，与地方财政部门脱钩，省以下税务机关以垂直管理为主，由上级税务机构负责管理人员和工资。这种设置可以减少地方政府对税收的干扰，保障中央税收收入，但缺点也很明显：两套机构导致税务系统人员激增，提高了税收征管成本，而且企业需要应付两套人马和审查，纳税成本也高。2018年，分立了24年的国税与地税再次开始合并。
分税制改革中最重要的税种是增值税，占全国税收收入的1/4。改革之前，增值税（即产品税）是最大的地方税，改革后变成共享税，中央拿走75%，留给地方25%。 为防止地方收入急剧下跌，中央设立了“税收返还”机制：保证改革后地方增值税收入与改革前一样，新增部分才和中央分。
2002年的所得税改革中，除一些特殊央企的所得税归中央外，所有企业的所得税中央和地方六四分成（仅2002年当年为五五分）。为防止地方收入下降，同样也设置了税收返还机制，并把2001年的所得税收入定为返还基数。
**分税制是20世纪90年代推行的根本性改革之一，也是最为成功的改革之一。**改革扭转了“两个比重”不断下滑的趋势（图2-2）：中央占全国预算收入的比重从改革前的22%一跃变成55%，并长期稳定在这一水平；国家预算收入占GDP的比重也从改革前的11%逐渐增加到了20%以上。改革大大增强了中央政府的宏观调控能力，为之后应付一系列重大冲击（1997年亚洲金融危机、2008年全球金融危机和汶川地震等）奠定了基础，也保障了一系列重大改革（如国企改革和国防现代化建设）和国家重点建设项目的顺利实施。分税制也从根本上改变了地方政府发展经济的模式。
土地财政 因为绝大多数税收征收自企业，且多在生产环节征收，所以地方政府重视企业而相对轻视民生，重视生产而相对轻视消费。 这种倚重生产的税制，刺激了各地竞相投资制造业、上马大项目，推动了制造业迅猛发展，加之充足高效的劳动力资源和全球产业链重整等内外因素，我国在短短二三十年内就成为世界第一制造业大国。当然这也造成了环境破坏，产能过剩等问题。
总的来看，分税制改革后，地方政府手中能用来发展经济的资源受到了几方面的挤压。首先，预算内财政支出从重点支持生产建设转向了重点支持公共服务和民生。20世纪90年代中后期，财政支出中“经济建设费”占40%，“社会文教费”（科教文卫及社会保障）只占26%。到了2018年，“社会文教费”支出占到了40%，“经济建设费”则下降了。其次，分税制改革前，企业不仅缴税，还要向地方政府缴纳很多费（行政收费、集资、摊派、赞助等），这部分预算外收入在改革后大大减少。90年代中后期，乡镇企业也纷纷改制，利润不再上缴，基层政府的预算外收入进一步减少。最后，2001年的税改中，中央政府又拿走了所得税收入的60%，加剧了地方财政压力。地方不得不另谋出路，寻找资金来源，轰轰烈烈的“土地财政”就此登场。
1998年发生了两件大事，城市土地的真正价值才开始显现。第一是单位停止福利分房，逐步实行住房分配货币化，商品房和房地产时代的大幕拉开。1997—2002年，城镇住宅新开工面积年均增速为26%，五年增长了近4倍。第二是修订后的《中华人民共和国土地管理法》开始实施，基本上锁死了农村集体土地的非农建设通道，规定了农地要想转为建设用地，必须经过征地后变成国有土地，这也就确立了城市政府对土地建设的垄断权力。
2001年，为治理土地开发中的腐败和混乱，国务院提出“大力推行招标拍卖”。2002年，国土部明确四类经营用地（商业、旅游、娱乐、房地产）采用“招拍挂”制度。于是各地政府开始大量征收农民土地然后有偿转让，土地财政开始膨胀。
2008年全球金融危机之后，在财政和信贷政策的共同刺激之下，土地转让收入再上一个台阶，2010年达到地方公共预算收入的68%。最近两年这一比重虽有所下降，但土地转让收入的绝对数额还在上涨，2018年达到62910亿元，比2010年高2.3倍。 与人力相比，土地更容易被资本化，将未来收益一股脑变成今天高升的地价，为地方政府所用。所以“土地财政”虽有种种弊端，但确实是过去数年城市化和工业化得以快速推进的重要资金来源。
政府投融资与债务 法律规定地方政府不能从银行贷款，2015 之前也不能发行债券，政府要借钱就要成立专门的公司（通常为国有独资企业），一般成为地方政府融资平台，或者城投公司。
随着城市化和商品房改革，土地价值飙升，政府不仅靠土地使用权转让收入支撑起了“土地财政”，还将未来的土地收益资本化，从银行和其他渠道借入了天量资金，利用“土地金融”的巨力，推动了快速的工业化和城市化。但同时也积累了大量债务。这套模式的关键是土地价格。只要不断地投资和建设能带来持续的经济增长，城市就会扩张，地价就会上涨，就可以偿还连本带利越滚越多的债务。可经济增速一旦放缓，地价下跌，土地出让收入减少，累积的债务就会成为沉重的负担，可能压垮融资平台甚至地方政府。
地方债的爆发始于2008—2009年。为应对从美国蔓延至全球的金融危机，我国当时迅速出台“4万亿”计划：中央政府投资1.18万亿元（包括汶川地震重建的财政拨款），地方政府投资2.82万亿元。为配合政策落地、帮助地方政府融资，中央也放宽了对地方融资平台和银行信贷的限制。2008年，全国共有融资平台公司3000余家，2009年激增至8000余家，其中六成左右是县一级政府融资平台。快速猛烈的经济刺激，对提振急速恶化的经济很有必要，但大水漫灌的结果必然是泥沙俱下。财政状况不佳的地方也能大量借钱，盈利前景堪忧的项目也能大量融资。短短三五年，地方政府就积累了天量债务。直到十年后的今天，这些债务依然没有完全化解，还存在不小的风险。
1998年，国家开发银行（以下简称“国开行”）和安徽芜湖市合作，把8个城市建设项目捆绑在一起，放入专门创立的城投公司芜湖建投，以该公司为单一借款人向国开行借款10.8亿元。这对当时的芜湖来说是笔大钱，为城市建设打下了基础。当时还不能用土地生财，只能靠市财政全面兜底，用预算安排的偿还基金做偿债来源。2002年，全国开始推行土地“招拍挂”，政府授权芜湖建投以土地出让收益做质押作为还款保证。2003年，在国开行和天津的合作中，开始允许以土地增值收益作为贷款还款来源。这些做法后来就成了全国城投公司的标准模式。
城商行主要由地方政府控制。2015年，七成左右的城商行的第一股东是地方政府。在各地招商引资竞争中，金融资源和融资能力是核心竞争力之一，因此地方政府往往掌控至少一家银行，方便为融资平台公司和基础设施建设提供贷款。但城商行为融资平台贷款存在两大风险。其一，基础设施建设项目周期长，需要中长期贷款。国开行是政策性银行，有稳定的长期资金来源，适合提供中长期贷款。但商业银行的资金大都来自短期存款，与中长期贷款期限不匹配，容易产生风险。其二，四大行的存款来源庞大稳定，可以承受一定程度的期限错配。但城商行的存款来源并不稳定，自有资本也比较薄弱，所以经常需要在资本市场上融资，容易出现风险。
地方政府的债务究竟有多少，没人知道确切数字。账面上明确的“显性负债”不难算，麻烦主要在于各种“隐性负债”，其中融资平台公司的负债占大头。
地方债总体水平虽然不低，但也不算特别高。就算占GDP六成，再加上中央政府国债，政府债务总额占GDP的比重也不足八成。相比之下，2018年美国政府债务占GDP的比重为107%，日本更是高达237%。而且我国地方政府借来的钱，并没有多少用于政府运营性支出，也没有像一些欧洲国家如希腊那样去支付社会保障，而主要是投资在了基础设施项目上，形成了实实在在的资产。虽然这些投资项目的回报率很低，可能平均不到1%，但如果“算大账”，事实上也拉动了GDP，完善了基础设施，方便了民众生活，整体经济与社会效益可能比项目回报率高。此外，我国政府外债很少。根据国家外汇管理局《2019年中国国际收支报告》中的数据，2019年末广义政府（政府加央行）的外债余额为3072亿美元，仅占GDP的2%。
融资平台投资回报率低，收入就低，还债就有困难。由于有地方政府背后支持，这些公司只要能还上利息和到期的部分本金，就能靠借新还旧来滚动和延续其余债务。但大多数融资平台收入太少，就算是只还利息也要靠政府补贴。2017年，除了北京、上海、广东、福建、四川和安徽等六省市外，其他省份的融资平台公司的平均收入，若扣除政府补贴，都无法覆盖债务利息支出。但政府补贴的前提是政府有钱，这些钱主要来自和土地开发有关的各种收入。一旦经济遇冷，地价下跌，政府也背不起这沉重的债务。
政府产业引导基金 美国最大的LP就包括加州公立系统雇员养老金（CalPERS）和宾州公立学校雇员退休金（PSERS）等。一些国家的主权投资机构也是声誉卓著的LP，比如新加坡的淡马锡和GIC、挪威主权财富基金（GPFG）等。而国内最大的一类LP就是政府产业引导基金，其中既有中央政府的基金比如规模庞大的国家集成电路产业投资基金（即著名的“大基金”），也有地方政府的基金，比如深圳市引导基金及其管理机构深圳创新投资基团（即著名的“深创投”）。
与地方政府投资企业的传统方式相比，产业引导基金或投资基金有三个特点。
第一，大多数引导基金不直接投资企业，而是做LP，把钱交给市场化的私募基金的GP去投资企业。一支私募基金的LP通常有多个，不止有政府引导基金，还有其他社会资本。因此通过投资一支私募基金，有限的政府基金就可以带动更多社会资本投资目标产业，故称为“产业引导”基金。同时，因为政府引导基金本身就是一支基金，投资对象又是各种私募基金，所以也被称为“基金中的基金”或“母基金”（fund of funds, FOF）。 第二，把政府引导基金交给市场化的基金管理人运作，实质上是借用市场力量去使用财政资金，其中涉及诸多制度改革，也在实践中遭遇了各种困难。 第三，大多数引导基金的最终投向都是“战略新兴产业”，比如芯片和新能源汽车，而不允许投向基础设施和房地产。 政府不仅修路，还直接下场做VC（风险投资）。以“合肥模式”为例，合肥政府通过引导基金，在京东方最困难的时候巨资入股，赌赢了面板产业，后来又押注了半导体和新能源汽车。
政府引导基金的本质是把“行政招商”变成了“资本招商”。但这也有风险，比如烂尾的武汉弘芯。成功的关键在于：政府是否真的懂产业，以及是否有退出的市场化机制。
城市化与不平衡 地方政府喜欢把地变成城市（因为能卖钱、能抵押），但不喜欢把外地农民变成市民（因为要提供教育医疗，要花钱）。但，城市化的核心不应该是土地，应该是人。
这导致了严重的供需错配：人口大量流入的一二线城市，建设用地指标被严格控制（供给少），房价飞涨；而人口流出的三四线城市，反而有大量用地指标（供给多），库存积压。这种“东边干旱，西边浇水”的模式需要改革。2020年，中央提出要对建设用地指标的跨区域流转进行改革，探索建立全国性建设用地指标跨区域交易机制（见第二节），已是针对这一情况的改革尝试。
高房价的本质是土地供给的垄断和资源分配的空间错配。
建设用地指标不能在全国交易，土地使用效率很难提高。地方政府招商引资竞争虽然激烈，也经常以土地作为手段，却很难持续提高土地资源利用效率。发达地区土地需求旺盛，地价大涨，本应增加用地指标，既满足需求也抑制地价。但因为土地分配受制于行政边界，结果却是欠发达地区能以超低价格（甚至免费）大量供应土地。
房地产常被称作“经济周期之母”，根源就在于其内在的供需矛盾：一方面，银行可以通过按揭创造几乎无限的新购买力；而另一方面，不可再生的城市土地供给却有限。
根据中国人民银行的这项调查，城镇居民2019年的负债中有76%是房贷。而从资产端看，城镇居民的主要财产也就是房子。房产占了家庭资产的近七成，其中六成是住房，一成是商铺。而在美国居民的财富中，72%是金融资产，房产占比不到28%。中国人财富的压舱石是房子，美国人财富的压舱石是金融资产。这个重大差别可以帮助理解两国的一些基本政策，比如中国对房市的重视以及美国对股市的重视。
按照中国人民银行的调查数据，北京居民的户均总资产（不是净资产，未扣除房贷和其他负债）是893万元，上海是807万元，是新疆（128万元）和吉林（142万元）的六七倍。这个差距大部分来自房价。房价上涨也拉大了同城之内的不平等。房价上涨不仅会增加按揭债务负担，还会拉大贫富差距，进而刺激低收入人群举债消费，这一现象被称为“消费下渗”（trickle-down consumption），这在发达国家是很普遍的。</description></item><item><title>空腹的奇妙自愈力</title><link>https://chenminhua.github.io/posts/2026_%E7%A9%BA%E8%85%B9%E7%9A%84%E5%A5%87%E5%A6%99%E8%87%AA%E6%84%88%E5%8A%9B/</link><pubDate>Sat, 24 Jan 2026 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2026_%E7%A9%BA%E8%85%B9%E7%9A%84%E5%A5%87%E5%A6%99%E8%87%AA%E6%84%88%E5%8A%9B/</guid><description>这是一本关于断食的书。
一日三餐让我们的消化系统变成了永不休息的机器，为了消化源源不断的食物，胰腺不停分泌着胰岛素，肝脏则忙于代谢解毒，肠胃在不停蠕动&amp;hellip;而间歇性断食则给我们的消化系统、代谢系统乃至每一个细胞一个宝贵的“休整”机会。当我们暂时停止了外部食物的摄入，身体就会从一个“持续合成、储存”的模式，切换到一个“向内分解、清理”的模式。这正是启动我们身体“自愈力”的总开关。
在空腹的状态下，细胞会开启自噬，身体会开始燃脂，激素水平也能得到校准和平衡。
细胞自噬是深植于我们生命基因中的一套最根本的“自我清洁与修复”程序。而间歇性断食，正是唤醒这头“沉睡的雄狮”的最简单、最有效的方法。它通过创造一个短暂的、可控的“能量压力”，来重新激活这个古老的自愈机制，让我们身体的每一个细胞都能定期地进行一场彻底的“大扫除”，从而由内而外地焕发出全新的生命力。
我们的身体天生就配备了两套燃料系统：一套是以“葡萄糖”（来源于碳水化合物）为燃料的系统，另一套则是以“脂肪”（以及其分解产物“酮体”）为燃料的系统。然而，在现代饮食模式下，我们绝大多数人常年都几乎只使用第一套“燃糖”系统，而那套更高效、更清洁、更持久的“燃脂”系统却几乎处于“闲置报废”的状态。间歇性断食，其核心作用之一，就是通过强制性地“清空油箱”，来迫使我们的身体重新启动并熟练掌握那套被遗忘已久的“燃脂”技能，从而完成一场深刻的“代谢革命”。
在现代“一日三餐、外加零食”的模式下，我们的血糖和胰岛素水平几乎一整天都处于较高的“峰值”状态。这种模式会带来几个严重的问题。
“能量的不稳定”。血糖来得快，去得也快，容易造成能量水平的大起大落。 “抑制脂肪燃烧”。只要血液中有足够的胰岛素存在，我们的身体就“不会”去燃烧脂肪。因为胰岛素的信号非常明确：“现在不缺能量，请全力储存！”所以，频繁进食等于是在不断地给身体下达“储存脂肪”的命令。 “胰岛素抵抗”。长期高强度的胰岛素分泌，会使我们的细胞对胰岛素的“信号”变得越来越不敏感，这就是“胰岛素抵抗”。 当我们停止进食大约12到16个小时后，储存在肝脏里的“糖原”就会被基本耗尽。此时，身体发现主要的“燃糖”燃料没有了，它就必须启动“B计划”，也就是切换到“燃脂”模式。我们的身体会开始分解储存在脂肪细胞里的脂肪，将其转化为“脂肪酸”和“酮体”，来为身体和大脑提供能量。这个过程，就是从“燃糖”到“燃脂”的华丽转身。 与血糖不同，脂肪和酮体的能量释放是平稳而持久的。一旦身体适应了燃脂模式，我们就不会再经历那种忽高忽低的“能量过山车”，饥饿感会大大降低，精力会变得更加稳定和充沛。
轻断食入门 找到最适合你的“空腹”方案 “16∶8断食法”。
“5∶2断食法”。它的核心是：在一周七天中，你选择五天保持正常的、健康的饮食，不刻意计算卡路里；然后选择两个不连续的日子（比如周二和周四）作为“断食日”。在断食日你并不是完全不吃东西，而是将热量的摄入限制在一个非常低的水平，通常是建议女性摄入500大卡，男性摄入600大卡。你可以选择将这些热量集中在一餐吃完，或者分两餐吃。
吃-停-吃”(Eat-Stop-Eat)。它的操作更加简单粗暴：在一周之内，选择一天或两天进行一次完整的24小时断食。例如，你在周一的晚上7点吃完了晚餐，那么直到周二的晚上7点，你才吃下一餐。在这24小时之内，你完全不摄入任何有热量的食物。
“隔日断食法”(Alternate-Day Fasting)。顾名思义，就是“吃一天，断一天”。在“断食日”，你可以选择完全不吃，或者像5∶2断食法一样，只摄入极低的热量（约500大卡）。
最后，还有一种更进阶的方案，叫作“OMAD”(One Meal A Day)，即“每日一餐”。
断食期间做什么 平稳度过“空腹期”的实用技巧 在断食期间可以喝水，黑咖啡，或者茶。不要去碰任何有热量的食物和饮料，因为他们会打破断食状态，升高胰岛素水平，抑制细胞自噬和脂肪燃烧。
你可能会被饥饿感打扰，但是要明白饥饿感像一阵波浪，它会达到一个高峰，但如果你不去理会它，喝点水，分散一下注意力，它通常会在十几二十分钟后自行消退。
断食期间可以运动，而且“空腹运动”好处多多。在空腹状态下进行中低强度的有氧运动，比如快走、慢跑、游泳等，由于体内的糖原水平较低，身体会更高效地直接燃烧脂肪来供能，这对于减脂来说效果极佳。但是，对于高强度的力量训练，建议最好安排在进食窗口期内，或者在训练后尽快补充蛋白质，以促进肌肉的修复和生长。
断食结束后的复食也是一门艺术。我们可以遵循以下几个核心原则。
“小份量开始”。你的第一餐分量一定要小，大约是你正常饭量的三分之一到一半即可。 “选择易消化的食物”。一个极佳的选择是“骨头汤”或“蔬菜清汤”。它们富含电解质和易于吸收的氨基酸，能温和地“唤醒”你的消化道，为你后续的进食打下一个良好的基础。其他一些好的选择包括：蒸熟的、非淀粉类的蔬菜（如菠菜、西葫芦、西兰花）；富含健康脂肪的牛油果；发酵食品，如酸奶、开菲尔、泡菜（其中的益生菌有助于恢复肠道功能）；以及小份的、优质的蛋白质，如鱼肉、鸡蛋羹等。 “避免刺激性食物”。首当其冲的就是“高糖分和精制碳水化合物”，比如甜点、含糖饮料、白米饭、白面包等。它们会导致血糖和胰岛素的剧烈波动，让你之前断食的代谢成果付诸东流。其次，要避免“油腻、煎炸”的食物。大量的脂肪需要胆囊和胰腺分泌大量的消化液来处理，这对于一个刚刚“复工”的消化系统来说负担太重。此外，生的、坚硬的蔬菜（如沙拉），以及坚果、豆类等，在第一餐中也最好避免，因为它们相对难消化。辛辣的食物也可能会刺激到敏感的肠胃。 “慢慢地吃，充分咀嚼”。这一点非常重要。每一口食物都尽量咀嚼20到30次，使其在口腔中就与唾液淀粉酶充分混合，完成初步的消化。慢慢地吃，也能让你的大脑有充足的时间来接收到“饱”的信号，避免无意中吃得过量。 一个比较稳妥的复食流程可以是这样的：在准备结束断食时，先喝一小碗温热的骨头汤或蔬菜汤。等待半小时到一小时，感受一下身体的反应。如果没有不适，再吃一些蒸熟的蔬菜和一小份蛋白质。然后，再逐渐地恢复到你正常的饮食。</description></item><item><title>12 Rules for Life</title><link>https://chenminhua.github.io/posts/2026_12_rules/</link><pubDate>Fri, 16 Jan 2026 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2026_12_rules/</guid><description>去年，在我儿子出生的前几天，我看到了 Jordan Peterson 的一个演讲，内容就是他的书《人生十二法则》。老爷子的演讲风趣幽默，又和蔼可亲。你能感觉到，他是真的希望你能过好自己的一生。最近又翻出他的书来看，每一条 rule 都简单朴实又振聋发聩。
1. Stand up straight with your shoulders back Your posture signals to yourself (and others) that you are ready to face challenges and take responsibility.
2. Treat yourself like someone you are responsible for helping People often care for others better than they care for themselves. Give yourself the same attention and compassion.
3. Make friends with people who want the best for you Avoid those who drag you down or envy you.</description></item><item><title>The Art of Spending Money：关于金钱、幸福与人生的思考</title><link>https://chenminhua.github.io/posts/2026_the_art_of_spending_money/</link><pubDate>Wed, 14 Jan 2026 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2026_the_art_of_spending_money/</guid><description>这不是一本教你如何消费的书，而是一本关于如何度过美好人生的书。
我们在谈论金钱时，往往过于关注“如何赚取”或“如何投资”，却很少探讨“如何花钱”。然而，赚钱只是手段，花钱才是我们与世界交互的方式。如何从财富中获得真正的幸福？这是一个比积累财富更值得深思的问题。
心理学家卡尔·荣格曾列出内心幸福圆满的五个根本要素：
身心健康； 良好的人际关系与亲密关系（如和睦的婚姻、温暖的家庭、真挚的友谊）； 感受并欣赏艺术与自然之美的能力； 适当的生活水平与满意的工作； 能够成功应对世事变迁、人生浮沉的哲学观念或宗教信仰。 你会发现，这些要素中，金钱只是其中的一部分，且往往是作为“适当的生活水平”这一基础而存在。
一、 欲望的心理学：你真正想要的是什么？ 1. 并没有“正确”的花钱方式 关于消费观念的大多数争论，往往源于我们试图用自己的价值观去衡量别人。有人喜欢豪车名表，有人钟情于米其林餐厅，也有人愿意散尽千金去环游世界或帮助他人。
这个世界上不存在所谓的“正确消费方式”。如果因为你喜欢某种方式，就认为别人也该如此，这是一种极度不成熟的表现；反之亦然。你必须诚实地面对自己，弄清楚什么能真正让你感到快乐和满足，而不是让社会或他人告诉你该把钱花在哪里。
2. 误判的渴望：不仅是物，更是尊重 很多时候，我们以为自己想要的是豪车豪宅，但内心深处真正渴望的，其实是尊重、钦佩和关注。
这就引出了一个悖论：当你开着豪车经过时，人们确实会行注目礼，但他们关注的是那辆车，而不是车里的你。他们想象的是自己开着这辆车的样子。
亚当·斯密曾深刻地指出，驱动人们追逐财富的动力往往是“被观察、被关注、被带着同情、满意和赞许的目光注视”。我们看重“金钱带来的关注”，甚至胜过金钱本身带来的舒适。
不妨试试写一份“反向讣告”：写下你希望在自己葬礼上被人们提及的内容，然后倒推你该如何生活。你绝不会希望人们在葬礼上谈论你的股票账户、豪宅面积或名贵手表。当你因为“你是谁”而不是“你拥有什么”赢得尊重时，你对浮华事物的欲望便会骤降。
3. 多巴胺的陷阱 欲望就像一笔隐性债务，只有将其还清（满足欲望或通过智慧消除欲望），人才能体会到平静。
我们的大脑并不渴望名车豪宅本身，它渴望的是多巴胺。从多巴胺的视角看，获得的过程和期待往往比拥有的结果更刺激。这就解释了为什么“得不到的永远在骚动”，而一旦拥有，满足感便迅速消退。
如果在多巴胺的游戏中追逐，你永远无法获胜，因为总有下一个层级在等着你。唯一能赢得这场游戏的方式，是学会满足。正如《广告狂人》中的唐·德雷珀所说：“幸福，就是在你再次渴望幸福之前的那一瞬间的感觉。”
二、 重新定义财富 1. 财富 = 拥有 - 渴望 衡量财富的最佳标准，不是你拥有的绝对数量，而是你拥有的减去你所渴望的。
如果你拥有很多，但渴望更多，你依然是贫穷的。快乐的关键是对已有之物感到满足，而不幸的根源往往在于盯着那些你没有的东西。不需要财富，往往比拥有财富更为珍贵。
2. 有钱 vs. 富裕 “有钱”（Rich）和“富裕”（Wealthy）是两个概念。
**查克·菲尼（Chuck Feeney）**是“富裕”的典范。作为环球免税集团的创始人，他是史上最节俭的亿万富豪之一。他生前捐出了80亿美元身家的99.99%，自己却住在小公寓，坐经济舱，戴廉价手表。他也曾体验过极致的奢华，但很快意识到那并不让他幸福。他说：“当我做的事情能帮助别人时，我很快乐。”
相比之下，许多在此刻显得“有钱”的人，可能正背负着巨大的社交债务。社交债务是一种无形的负担，源于你通过消费来维持他人对你看法。你的身份越与物质绑定，你就越脆弱，越需要不断用更新、更贵的东西来维持这种形象。
3. 静默复利 真正的财富积累往往是静默的。
内在记分卡 vs. 外在记分卡：巴菲特提出的这个概念至关重要。你愿意做一个世人羡慕但内心痛苦的人，还是一个没人关注但内心幸福满溢的人？ 接受差异：许多财务错误源于盲目模仿那些与你情况完全不同的人。 注重独立：用金钱来改善生活，而不是用来影响他人的看法。 快钱易逝：积累财富的速度往往也是失去财富的半衰期。慢慢变富，往往更稳健。 三、 金钱购买的最高价值：独立 如果让我给出一个美好人生的极简公式，那就是：独立 + 目标。
金钱能买到的最美妙的东西，是独立——是按照自己的意愿支配时间的能力，是不得不做某事时的说“不”的底气。
许多人认为“没花掉的钱”是没用的。其实不然。你存在银行里的每一分钱，都为你买下了一张未来的“选择权”和“自由兑换券”。纳西姆·塔勒布说：“重要的不是一个人拥有什么，而是他害怕失去什么。”你拥有的越多（特别是依赖他人评价的资产），你可能越脆弱；而你拥有的未被消费的财富（独立性），则是你最坚实的盾牌。
不要让金钱成为你的身份认同。 如果你将人生的成功与银行数字挂钩，那么即使你拥有再多，你也永远无法真正“退休”或感到安全。真正的成功，是能够不再为金钱操心，转而专注于更有意义的事情。
四、 财富与代际：给孩子的礼物 关于财富与教育，查理·芒格的观点震聋发聩。当被问及给孩子留巨款是否会毁掉他们的斗志时，他说：“当然会。但你还是得留给他们，因为如果不给，他们会恨你的。”
这背后有一个微妙的平衡：
不要“羞辱式教育”：如果父母坐头等舱却让孩子挤经济舱，孩子学到的往往不是节俭，而是怨恨。 身教重于言传：孩子不会听你关于金钱价值观的说教，他们会观察你。他们看你为何事开心，为何事焦虑，看你对邻居新车的嫉妒，看你通过购物获得的短暂快感。 安全网，而非助推剂：希望财富成为孩子人生最后的安全网（让他们敢于失败），而不是助推剂（让他们无需努力）。 独立的价值观：真正的成功是培养出那些有足够信心、靠自己找到成功的孩子。 沃伦·巴菲特说：“衡量人生成功的真正标准，是你希望爱你的人当中，到底有多少人真的爱你。”这无关财富，关乎品格、诚实和同理心。</description></item><item><title>鱼不存在</title><link>https://chenminhua.github.io/posts/2026_%E9%B1%BC%E4%B8%8D%E5%AD%98%E5%9C%A8/</link><pubDate>Sat, 10 Jan 2026 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2026_%E9%B1%BC%E4%B8%8D%E5%AD%98%E5%9C%A8/</guid><description>最近读了Lulu Miller 的《鱼不存在》（Why Fish Don&amp;rsquo;t Exist）。非常喜欢。这本书讲了斯坦福首任校长，大卫·斯塔尔·乔丹的故事。
大卫是一个鱼类分类学家，他的毕生都在致力于给自然界分类，试图在混沌中建立秩序。大卫和他的团队发现了当时人类已知鱼类的近五分之一。但是他的一生充满了悲剧，妻儿早逝，标本馆火灾，命运一次次试图摧毁他，但他总是能站起来反击。1906年旧金山大地震震碎了他收藏的数千个标本罐，但他没有崩溃，而是拿起一根缝衣针，把标签直接缝在鱼肉上。
书的前半部分，lulu miller 将大卫作为榜样，在生活中陷入低谷（失恋、迷茫、试图自杀），她试图从大卫的故事中寻找答案：一个人如何在充满混乱和绝望的世界里，保持如此顽强的自信和前行的动力？
然而画风一转，书的后半部分揭开了大卫为了维持这种“秩序感”所付出的黑暗代价。他涉嫌掩盖斯坦福大学创始人简·斯坦福（Jane Stanford）的非正常死亡，以保住自己的地位。他相信优生学（Eugenics）： 这种对“秩序”和“优越性”的偏执，最终让他成为了优生学的狂热信徒。他利用自己的科学权威推动强制绝育法案，试图“净化”人类基因库，导致成千上万无辜者被迫绝育。大卫的自信并非来自真理，而是一种危险的傲慢。
我最喜欢书的最后一章。在大卫死后，命运给了大卫最后一击。现代支序分类学（Cladistics）发现，“鱼”作为一个生物学分类是不存在的。因为在这个类别里，某些鱼（如肺鱼）与牛或人的亲缘关系，比它们与鲑鱼的关系更近。如果在演化树上画圈，“鱼”这个圈必须包含人类才能成立，否则它就是无效的。鸟类存在，哺乳动物类存在，但是鱼不存在。大卫一生都在为之努力的鱼类分类学被摧毁了。
承认“鱼不存在”，意味着打破人为的界限和等级（包括优生学划分的优劣）。当我们放下对他人的刻板分类，放下对绝对秩序的执念，承认世界的混沌与复杂，我们反而能看到更多生命的奇迹，获得真正的自由。
这本书从赞美秩序开始，以拥抱混乱告终。混乱是世界的常态，试图强行控制它可能会带来邪恶；但如果我们可以放下傲慢的分类心，去接受万物之间没有边界的联系，我们就能在混乱中找到更真实的爱与意义。</description></item><item><title>The Inner Game of Tennis</title><link>https://chenminhua.github.io/posts/2026_inner_game_of_tennis/</link><pubDate>Fri, 09 Jan 2026 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2026_inner_game_of_tennis/</guid><description>这是一本关于关于心理的书。作者加尔韦提出了一个概念，一场网球比赛里面其实有两个比赛：内在游戏和外在游戏。在外在游戏中，你的对手是
球网另一端的人；在内在游戏中，对手则是你自己。
内在游戏是为了克服所有妨碍优秀绩效表现的心理习惯而存在的游戏。
赢得任何比赛的秘诀，在于不要过度努力。
两个自我 每个球员心中都有两个自我，自我一喜欢评判，喜欢发号施令，而自我二则更接近无意识下的技艺发挥。自我1和自我2之间关系是决定一个人将技术知识转化为有效行动的首要因素。
著名的禅宗大师铃木大拙(D.T.Suzuki)在《箭术与禅心》的序：
一旦我们开始反思、审视和构思，最初的无意识状态就会消失，某一个念头就会形成干扰……箭矢脱弦而出，但不会直奔目标，而且箭靶也不再停留在原来的位置。计算，其实是失算，就出现了……
也许这就是为什么人们说伟大的诗歌诞生于寂静之中，伟大的音乐和艺术源于无意识的宁静深处，而真正的爱则潜藏于言语和思想之下。同样的比喻也适用于体育运动中最伟大的表现：当内心平静得宛如镜面般的湖水时，它们就会出现。
内在游戏的目的是增加这些时刻发生的频率和持续的时间，使内心逐渐平静下来，从而使我们的学习和表现能力持续得到拓展。可如何才能让自我1平静下来呢？
我们要学习的第一项技能是放下评判自己和自己表现好坏的倾向性。无论是正向的还是负向的评价。（注意，世上没有一种方法去只停止评判过程中消极的一面，当你开始进行积极评价时，潜意识里就已经在给其他表现消极评价）
我们还要学会专注，当一个人实现了专注，内心就会安静下来。当内心保持在当下，它就会变得平静。放松专注是一门至高的技艺。专注的内心只会关注那些完成手头任务所需要的信息和情况。它不会被其他想法或外在事件干扰，而是完全沉浸在当下相关的事物中。
“看球”的意思是将注意力集中在对球的视觉观感上。我发现，通过视觉加深注意力的最有效方法是把注意力集中在一些微妙的、不容易察觉的东西上。看到球很容易，但要注意它旋转时接缝线所形成的确切图像就不那么容易了。观察接缝的做法会产生有趣的结果，在很短的时间内，球手会发现他对球的观察比他仅仅去“看”它的时候要好得多。当寻找由接缝构成的图像时，人们会自然而然地持续观察，直到球到了球拍上的那一刻，并开始比以前更早地将注意力集中在球上。球应该从它离开对手的球拍到它打到你的球拍的时候都被观察到。（有时球甚至开始显得更大或移动得更慢。这些都是真正专注的自然结果。）但是，更好地看到球只是专注于球的接缝的部分好处。因为旋转的球所产生的图像是如此微妙，它往往会使人的内心更完全地沉浸其中。内心如此专注于观察图像，以至于忘记了去过度努力。当内心完全专注于接缝的时候，它往往就不会对身体的自然动作产生干扰。此外，接缝总是在当下，如果心思在接缝上，就不会游移到过去或者未来。这种练习将使网球运动员达到精神不断加深的集中状态。 如果你的眼睛眯起或紧张，你就在过度努力了；如果你发现自己因为失去专注而责备自己，你可能是过度控制了。让球吸引你的注意力，你的内心和你的肌肉都会保持适当的放松。 如果你在想你应该如何移动，你就几乎不可能很好地感受或看清任何东西。忘记应该，去感受就是了。
实现专注的一个办法是呼吸。当我们专注于呼吸时，我们是把注意力放在与身体的生命能量密切相关的东西上。把心思放在呼吸过程上能帮助我们处理焦虑。
心流状态 关于“心流状态”有一点需要注意：它不能由自我1控制。我看到很多文章声称提供了一种能让人“每次都在心流中打球”的技巧。忘了它吧！这是个陷阱。这是一个古老的陷阱。自我1喜欢在心流状态中打球的这个想法，尤其喜欢在其中经常会发生的结果。因此，自我1会试图攥住那些承诺能把你带到心流这个所有人都认为是好地方的任何机会。但这里有一个问题：到达那里的唯一方法是抛弃自我1。只要你让自我1作为主导者带你到那里，它也会同行，那么你将无法进入心流状态。如果你进入了，哪怕只有片刻，自我1就会说：“很好，我到了。”然后你就会再次从该状态中脱离出来。
竞争的意义 在网球运动中，是谁为一个人提供了体验自己最高极限所需要克服的障碍？当然是他的对手！那么你的对手是朋友还是敌人呢？他是朋友，因为他会竭尽全力给你制造困难。只有通过扮演你的敌人，他才会成为你真正的朋友。只有与你竞争，他才是真正地在与你合作！没有人愿意站在网球场上等待汹涌海浪的到来。在这种竞争中，对手有责任为你制造最大的困难，而你也有责任为他制造障碍。只有这样做，你们才会给对方机会去发现各自所能达到的高度。
**真正的竞争与真正的合作在本质上是一致的。**在竞争中，看似每个人都在竭尽全力打败对方，但其实我们并不是在打败对方，而是克服对方所设置的障碍。在真正的竞争中，没有人会被打败。
我曾经认为，如果我与一名反手较弱的球员进行友谊赛，总是打他的弱点有点儿不公平。但在有了上述的发现以后，真相则恰恰与此相反！如果你尽可能多地打他的反手，他的反手球只能是越打越好。如果你保持“友善”，打他的正手，他的反手就会一直很弱。在这个场景下，真正的友善之人就是竞争对手。 你不必为了成为赢家而变成杀手。你只须认识到，杀伐并不是游戏的本质。
在意获胜和在意获胜所付出的努力之间的区别看似微小，但二者在效果上却大相径庭。当我只在意获胜时，我关心的是我无法完全控制的事情。外在比赛的输赢，是对手和我两个人的技术与努力付出的结果。当一个人在情绪上对自己无法控制的结果有太多的牵扯时，他往往会变得焦虑不安，进而过度努力。但一个人可以去控制自己为获胜所付出的努力。一个人永远都可以在任何一个时刻选择尽力而为。因为人不会对自己可以控制的事件感到焦虑，所以只要意识到自己正在尽最大努力去赢得每一分，你就会从焦虑的困扰中摆脱出来。这样一来，原本被消耗于焦虑及其后果的能量就可以被用在努力获胜上。
球场外的内在游戏 很显然，几乎所有的人类活动都涉及外在游戏和内在游戏。我们用来实现外在目标的那个内心很容易被扰乱，因为它有担心、后悔或把简单情况复杂化的倾向性，进而不停地造成不必要的内在困难。认识到这一点很有帮助，我们的外在目标多种多样，我们需要学习多种技能才能实现，而内在障碍却只有一个来源，克服这些障碍所需的技能也始终不变。无论你身在何处，无论你做的是什么，在自我1被压制住之前，它都会制造恐惧、疑虑和妄想。
打网球时的专注在本质上与完成任何任务（甚至欣赏交响乐）所需的专注没有什么不同；学会放下根据反手水平来评判自己的习惯与忘掉评判孩子或上司的习惯没有什么不同。学会在竞争中欣赏障碍会自动提高一个人在生活中面对所有困难时找到优势的能力。因此，每一种内在收获都会立即自发应用到一个人的所有活动中。这就是为什么内在游戏值得我们关注。
实现内心稳定的第一步可能是承认有一个内在的自我，它自己也有着与生俱来的需求。这个拥有你所有天赋和能力的自我，你希望用来完成任何事情的自我，也有属于自己的要求。这要求是一种自然而生的需求，我们甚至都不需要被教导。每一个自我2都是与生俱来的，无论出生在哪里，都有满足自己本性的本能。它想要享受、学习、理解、欣赏、追求、休息、健康、生存、自由地做自己、展现自己并做出独特的贡献。</description></item><item><title>超越百岁</title><link>https://chenminhua.github.io/posts/2026_outlive/</link><pubDate>Fri, 09 Jan 2026 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2026_outlive/</guid><description>最近读了 Peter Attia 的书 &amp;ldquo;Outlive &amp;ndash; The Science &amp;amp; Art of Longevity&amp;rdquo;，中文名为”超越百岁“。本文为一些摘录与读书笔记。
解决这个问题的唯一方法不是去更好地接住鸡蛋，而是去阻止那个扔鸡蛋的人。我们得想办法到楼顶上去，找到那个家伙，把他干掉！
现代医学擅长把人从死亡线上拉回来，却不擅长让人在活着的时候保持健康。随着人们寿命的延长，**心脏病、癌症、阿尔茨海默病和2型糖尿病（死亡四骑士）**等慢性病逐渐成为主要死亡原因。这些疾病的发生往往是一个漫长的过程，可能在年轻时就开始积累风险，而在症状明显时再进行治疗往往为时已晚。
现代人类平均寿命大幅度提高的主要原因是源于抗生素普及、卫生条件提升所导致的传染病死亡人数下降。现代医学擅长控制急性疾病却不善于管理慢性疾病。预防慢性病需要从年轻时就开始积极管理健康，关注生活方式的选择，包括运动、营养、睡眠和情绪健康。这种主动的健康管理方式，称为“医学3.0”，旨在在疾病发生之前进行干预，以提高生活质量和延长健康寿命。
医学3.0的核心在于预防，而非治疗，强调个性化护理和细致入微的风险评估。我们必须重新思考慢性病的治疗，关注健康寿命而不仅仅是延长生命的长度，活得久并不等于活得好。健康跨度及其恶化有三个方面：认知能力下降、身体机能衰退和情绪健康问题。
调查显示，幸福感往往在我们40多岁（确切地说，是47岁）时达到最低谷。
阿提亚提出了三层框架：目标、战略和战术。
目标是希望实现的最终状态，比如活得更长、更健康； 战略是实现目标的总体计划，关注健康的特定领域； 战术则是具体的行动步骤。 医学2.0依赖于两种类型的战术：手术（如外科手术）和药物治疗。我们在医学3.0中的战术则分为五大领域：运动、营养、睡眠、情绪健康和外源性分子（exogenous molecules），即药物、激素或补充剂。
死亡四骑士 代谢疾病（如糖尿病） 我们有五个标准（符合其中三个或三个以上）来定义代谢综合征：
高血压（＞130/85） 高甘油三酯（＞150mg/dL） 低高密度脂蛋白胆固醇（男性＜40mg/dL，女性＜50mg/dL）（以躯干部位和腹部肥胖为主要特征。——译者注1英寸=2.54厘米。——译者注） 向心性肥胖（central adiposity） （男性腰围＞40英寸 ，女性腰围＞35英寸） 空腹血糖升高（＞110mg/dL） 当你吃了一个甜甜圈，甜甜圈中的碳水首先被转化成糖原供短期使用。大约 75% 的糖原会进入骨骼肌，另外 25% 进入肝脏。一个成年男性会在这两个部位存 1600 卡路里的糖原，足够两小时剧烈运动。肝脏的一项重要功能是将储存的糖原转化为葡萄糖，然后根据需要将其释放出来，以将血糖水平维持在一个稳定的状态，即葡萄糖稳态（glucose homeostasis）。 一个普通的成年男性在任何时候都有大约5克葡萄糖在他的血液中循环，大约为一茶匙的量。这一茶匙的葡萄糖只能维持几分钟，因为葡萄糖会被肌肉，尤其是大脑吸收，所以肝脏必须不断工作，对它进行精确地调节，以保持一个差不多恒定的水平。剩余的能量会被转化成脂肪。即使是一个相对苗条的成年人，体内也可能携带10kg脂肪，相当于储存了高达9万卡路里的能量。
胰岛素等激素决定了把甜甜圈的能量放哪里。当身体感受到葡萄糖，胰腺会分泌胰岛素，将葡萄糖运输到需要的地方，同时维持葡萄糖稳态。对于一个典型的久坐不动的人来说，由于他没有迅速消耗肌糖原，甜甜圈产生的多余能量大部分最终会进入到脂肪细胞中（或者更具体地说，它们会转化为甘油三酯，储存在脂肪细胞中）。
我们可以把脂肪想象成一种代谢缓冲区，它可以吸收多余的能量并将其安全地储存起来。 当你需要时，脂肪又会被转化出来供肌肉使用。但是如果你摄入的热量过多，超出皮下脂肪的极限，内脏脂肪的堆积是非常有害的。内脏脂肪会增加癌症和心血管疾病的患病风险。
“胰岛素抵抗”意味着细胞已经不再听从胰岛素的信号。你将细胞想象成一个正在充气的气球，气球膨胀到很难把更多的空气挤进去的地步，你必须越来越用力地吹气。这就是胰岛素发挥作用的地方，它有助于促进将空气吹入气球的过程。胰腺开始分泌更多的胰岛素，试图从血液中清除多余的葡萄糖，并将其塞满细胞。这暂时是有效的，血糖水平保持正常，但最终你会达到一个极限，“气球”（细胞）无法再接受更多的“空气”（葡萄糖）进入。
果糖的代谢方式与其他糖类不同。当我们将果糖同某些其他类型的食物一起代谢时，会产生大量的尿酸，而尿酸最为人所熟知是，它是痛风的病因，但痛风也与血压升高有关系。摄入大量的液态果糖会使肠道的处理能力不堪重负，多余的热量被分流到肝脏，其中许多热量很可能最终会变成脂肪。在我们已经很高热量的现代饮食中，几乎无限量摄入的液态果糖最终会导致代谢障碍。
心脏病 心脏病是全球致死率最高的疾病之一，许多人在心脏病发作前并未察觉身体的警告信号。心脏病的根本原因是动脉粥样硬化。根据美国疾病控制与预防中心的数据，在美国，每天约有2300人死于这种疾病。美国女性死于动脉粥样硬化疾病的可能性是死于乳腺癌的10倍。但是象征乳腺癌的粉红丝带在女性意识中的地位要远超代表美国心脏协会的红丝带。
胆固醇对生命来说是必不可少的。它是产生细胞膜、睾酮、孕酮、雌激素和皮质醇等激素，甚至消化食物所必需的胆汁酸等物质的原料。 所有细胞都能合成自己的胆固醇，但我们身体大约20%（大量）的胆固醇供应来自肝脏，肝脏扮演着胆固醇储存库的角色，将其运送到需要它的细胞中，并通过血液循环将其接收回来。 胆固醇属于脂质家族（即脂肪），不溶于水，因而不能像葡萄糖或钠那样溶解在我们的血浆中，并在我们的血液循环中自由流动。因此，它必须以一种被称为“脂蛋白”（lipoproteins）的微小球形颗粒为载体，脂蛋白就像小型货运潜艇一样，将胆固醇运送至身体各处的细胞或器官。顾名思义，这些脂蛋白部分是脂质（内部），部分是蛋白质（外部）。 饮食中的胆固醇（尤其是鸡蛋的摄入）可能与心脏病没有多大关系。摄入大量饱和脂肪会增加血液中导致动脉粥样硬化的脂蛋白水平，但我们从食物中实际摄入的大部分胆固醇最终都会被排出体外。我们血液循环中的绝大多数胆固醇实际上是由我们自己的细胞产生的。 造成问题的不是胆固醇本身，而是运送胆固醇的颗粒的性质。 心脏病的两个最大的风险因素——吸烟和高血压，会对内皮细胞造成损伤。吸烟会对其产生化学损伤，而高血压则会造成机械损伤，但最终的结果都是引发内皮损伤，这反过来又导致了更多低密度脂蛋白的滞留。随着氧化低密度脂蛋白的积累，它会对内皮细胞造成更多的损伤。
如何预防心脏病：
控制胆固醇水平、保持健康的血压和体重是预防心脏病的关键。 定期监测健康指标至关重要。 情绪健康和压力管理对心脏健康也很重要，积极的生活态度和良好的社交关系也有助于降低心脏病风险。 癌症 在所有“骑士”疾病中，癌症可能是最难预防的。
**如果癌症的第一条规则是“不要得癌症”，那么第二条规则就是“尽快发现它”。**定期体检和监测健康指标是提前发现癌症的有效手段。除了少数例外，如胶质母细胞瘤（glioblastoma）或其他侵袭性脑肿瘤，以及某些肺癌和肝癌， 实体瘤通常只有在扩散到其他器官时才会杀死你 。乳腺癌和前列腺癌只有在转移时才会致死，没有这两个器官你也能活下去。但是太多的癌症被发现得太晚了，癌细胞已经生长并通过转移扩散了。少有治疗方法对晚期癌症奏效，在大多数情况下，除了少数对免疫疗法有应答反应的癌症患者之外，我们所能期望的最好结果就是稍微推迟死亡的来临。
截至目前，我们仍然不太擅长在早期发现癌症。在几十种不同类型的癌症中，我们只对5种癌症有公认的、可靠的筛查方法：肺癌（针对吸烟者）、乳腺癌、前列腺癌、结直肠癌和宫颈癌。即便如此，主流指南一直在引导人们远离某些类型的早期筛查，例如女性的乳房X光检查和男性的前列腺特异性抗原（PSA）血液检查。这部分与成本有关，部分与假阳性的风险有关，假阳性可能导致不必要甚至危险的治疗（导致进一步的成本）。
在所有的主要癌症中，结直肠癌是最容易发现的癌症之一，在降低风险方面的回报最大 。它仍然是美国五大最致命的癌症之一，仅次于肺癌（排名第一）和乳腺癌/前列腺癌（女性/男性，排名第二），并排在胰腺癌（排名第四）和肝癌（排名第五）之前。不过，在这5种癌症中，结直肠癌是我们最有可能及早发现的一种。由于它生长在一个相对容易接近的位置，即结肠，我们不需要任何成像技术或手术活检就能看到它。建议在40岁时进行结肠镜筛查（或其他结直肠癌筛查），而不是标准建议的45岁或50岁。
良好的生活方式，包括健康饮食、适度运动和情绪管理，也能显著降低癌症风险。美国癌症协会（American Cancer Society）报告称， 超重是癌症病例和死亡的主要风险因素，仅次于吸烟。</description></item><item><title>两种能力</title><link>https://chenminhua.github.io/posts/2025_%E4%B8%A4%E7%A7%8D%E8%83%BD%E5%8A%9B/</link><pubDate>Tue, 01 Jul 2025 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2025_%E4%B8%A4%E7%A7%8D%E8%83%BD%E5%8A%9B/</guid><description>要想在篮球场上抢到更多的篮板，有两个天赋很重要，一个是身高（或者垂直摸高），一个是弹跳。
篮球届有一个名言：You can’t teach height，身高这玩意儿纯看天赋，后天努力对结果的影响很小。而弹跳相对而言则是可以被训练的，你可以在很多地方找到练弹跳的方法。
显然，这里有两种能力，一种是trainable 的，另一种则纯看天吃饭。或者说这里有一个光谱。
那么，数学天赋在这个光谱的哪一端呢？语言天赋又在哪一端呢?方向感又在哪一端呢？到底哪些是可以后天努力的，哪些能力如果你天生没有后天也弥补不太上了？</description></item><item><title>风险</title><link>https://chenminhua.github.io/posts/2025_%E9%A3%8E%E9%99%A9/</link><pubDate>Mon, 30 Jun 2025 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2025_%E9%A3%8E%E9%99%A9/</guid><description>最近有个朋友推荐了个股票给我，“数据很好，能涨三倍”。
我将信将疑地打开了软件，公司还在亏损，市值不高，最近涨了两倍多（情绪很高）。很像是那种炒作割韭菜的股票。当然，还有一种可能，公司在未来一段时间可能有好消息要出来，当然市场还没有完全知道这件事。是韭菜盒子还是红包？我没法判断。
仅从当前财务指标来看，公司的估值似乎是偏高的，也就意味着没有足够的安全边际。市值太小且筹码集中，意味着股价很容易被操控。如果按照价值投资的流派来看，此时买入存在着大幅亏损的风险。
但是对趋势交易员来说，现在买入是个不错的选择，而且从朋友给我的信息来看，如果我认为消息可行的话，此时不买入存在着放弃大幅盈利的风险。没错，没有赚到原本可以赚到的钱也是一种风险。但是由于损失厌恶，这种风险常常被忽略，人们往往更容易接受少赚一万块钱而非亏损一万块钱。
风险也许是投资中唯一重要的东西，也是最有趣的部分。一个胜率极高的投资策略是，当vix 恐慌指数超过 50 时大笔买入，翻译过来就是当风险人尽皆知的时候买入。风险由于为人熟知而被释放。显性的风险由于被谨慎规避了反而是安全的，就像不会游泳的人往往不会淹死，因为他会离河边远远的。而真正致命的风险是那些隐式的，你看不见它，或者，你错误预判了它的概率。就像每天一包烟或者两杯奶茶，晚睡，人们容易忽视或者错误计算这些事情的风险。
塔勒布讲过一个例子，他说有两个兄弟，其中一个在一个稳定的公司上班，拿着不错的收入；另一个开出租，收入波动很大。开出租的常常抱怨自己的收入波动大，承受的风险大，为了让自己能多赚点，他认真研究了城市的交通情况，什么时候应该走哪条路去哪里营运。塔勒布说，其实开出租的那个才是稳定的，他平时的波动让他变得反脆弱，因而风险更小了。而那位白领平时虽然非常稳定，可如果有一天行业发生变化导致他失业了呢？
关于那只股票，我最终决定买入。唯一重要的问题是，我能为这个机会付出的最大亏损是多少。
上面的风险都是价格风险，而除了价格风险以外还有一种风险被称为流动性风险。要理解流动性风险，最简单的方式就是看美股市场上的中概股，一大堆破净的公司。比如迅雷的市值最近一度只有 2.6 亿美金，但是他们账上现金等价物就有两个多亿，持有的影石的股权按当前价格计算也要 7.5 亿美金以上，在加上其收购的虎扑，海外业务等等都是在盈利状态，负债极少。看起来怎么着也是超卖了。但是，迅雷不是个例，我们可以在美股找到一堆这种公司，归根结底就是没人愿意买入这些股票了，也就导致价格严重偏离价值，这种没有人交易的风险就是流动性风险。</description></item><item><title>先有鸡还是先有蛋</title><link>https://chenminhua.github.io/posts/2023_%E5%85%88%E6%9C%89%E9%B8%A1%E8%BF%98%E6%98%AF%E5%85%88%E6%9C%89%E8%9B%8B/</link><pubDate>Mon, 13 Feb 2023 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2023_%E5%85%88%E6%9C%89%E9%B8%A1%E8%BF%98%E6%98%AF%E5%85%88%E6%9C%89%E8%9B%8B/</guid><description>1. 先有某个语言的编译器还是先有编程语言？ 在编译器领域有个概念叫自举（bootstrapping），也就是用一门语言实现该语言的编译器/解释器，然后用自己的编译器编译出自己的新编译器/解释器。
这是一个经典的鸡与蛋的问题，到底是先有编译器还是先有编程语言？一般来说创建一个新语言的过程是：
设计好语言的spec。 用其他语言实现这个语言的第一个编译器V1 (比如c语言的第一个编译器是b语言写得)。 用这个编译器编译这个新语言的程序。 用这个新语言实现这个语言的编译器V2，并用V1编译出V2。 后面就可以自举了（改spec,用新的编译器编译出更新的编译器&amp;hellip;）。 这个问题也变的很好回答了，如果你认为设计好语言的spec语言就算存在了，那么就是先有语言。如果你认为第一个该语言的hello world程序编译通过才算语言存在，那么就是先有编译器。
2. 先有人工智能还是先有程序？ 如果人类文明被人工智能取代，人类从地球上消失，人工智能开始不断迭代并创造新版的人工智能。未来三体人来到地球，因为他们不知道世界上存在过人类，只知道是程序在生产程序，他们会不会也困惑，第一个AI到底是怎么生成的。
3. 先有鸡还是先有蛋？ 我把这个问题抛给了chatgpt
我：先有鸡还是先有蛋？ chatgpt: 一般来说，先有鸡。</description></item><item><title>葬礼随笔</title><link>https://chenminhua.github.io/posts/2022_%E8%91%AC%E7%A4%BC%E9%9A%8F%E7%AC%94/</link><pubDate>Fri, 18 Nov 2022 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2022_%E8%91%AC%E7%A4%BC%E9%9A%8F%E7%AC%94/</guid><description>2022年，我失去了三个亲人，人生第一次如此近距离地感受到了死亡。
今年4月份，外公去世了。我被封在上海家里，没能送他最后一程。前几天，爷爷奶奶也因为意外离世，我第一时间赶了回去送他们，这也是我人生中参加的第一次葬礼。一直保持稳定平静的情绪，最终还是在殡仪馆捡灰炉外破防了。几天前爷爷奶奶还开开心心的和家人一起吃饭喝酒，老两口身体也很棒。可在人生的电影里，当命运走向你的时候，你不会听到任何bgm，一切都如往常一样，却突然急转直下。
面对死亡，人总是忍不住想问，人生有什么意义？可对于这无限的宇宙，与这无尽的时间而言，追问人生有什么意义似乎是一个过于自以为是的问题。人类太小了，对于这世间无数存在过的人，他们的生与死于这个宇宙而言，毫无意义。
Born to die? 而如果我们的出生就是为了死亡，生命的目标就是生命的结束，我们的存在就是为了不存在，这样一想，便消解了对死亡的恐惧，但也消解了生活的意义。如此推演下来，追求人生幸福与追寻人生价值倒显得愚蠢且ego太大了。
既然人生或许没有什么意义，那活着便也不必再执着于得到一些什么，也不一定非要活成什么样子。赚更多的钱，住更好的房子，开更好的车，生两个孩子，去世界各地打卡，看更多更多的演唱会，滑雪，露营&amp;hellip;当你在一个圈子里的时候，你会觉得人生就应该要这样，不然就白活一辈子了。但为什么人生一定要这样呢？爷爷奶奶种了半辈子的地，晚年一直住在农村的小屋子，一辈子也没有开过车，没有喝过星巴克，没有出过国，没有滑过雪，但他们也度过了精彩又幸福的一生。
火化完爷爷奶奶的那天晚上，我们把爷爷奶奶的照片挂了起来，妹妹看到照片突然情绪崩溃，我抱着她安慰。她和我讲起她最后一次和爷爷奶奶见面的时候，还一起喝了酒，说了一些什么话。我说，这是他们留给你的礼物，一个属于你们的故事，而你会一直记得。人，不过是故事的载体。
这也是外公和爷爷奶奶用生命给我上的一课，教会我如何面对人生和死亡。愿他们安息。</description></item><item><title>A little copying is better than a little dependency</title><link>https://chenminhua.github.io/posts/2022_copying_vs_dependency/</link><pubDate>Sun, 24 Jul 2022 08:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2022_copying_vs_dependency/</guid><description>quote from https://go.dev/blog/supply-chain:
The final and maybe most important software supply chain risk mitigation in the Go ecosystem is the least technical one: Go has a culture of rejecting large dependency trees, and of preferring a bit of copying to adding a new dependency. It goes all the way back to one of the Go proverbs: “a little copying is better than a little dependency”. The label “zero dependencies” is proudly worn by high-quality reusable Go modules.</description></item><item><title>Make the choice right</title><link>https://chenminhua.github.io/posts/2022_make_the_choice_right/</link><pubDate>Sun, 24 Jul 2022 08:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2022_make_the_choice_right/</guid><description>最近看到一个新闻，东南大学建筑学院招不满人，建筑学院录取线接近东大录取线。
东南大学是我的母校，而建筑学院一直都是东大最好的专业，在我上大学的时候，建筑系在江苏的分数线一般都已经接近交大复旦的录取线了。很难想象建筑系分数线会降低这么多。而与之相对的，虽然计算机并非东大强势学科，但计算机系的分数线越来越高。
回头看过去十年，大量的非计算机系的同学都进入了互联网公司干起来程序员的工作，很多也都在财务上得到了丰厚的回报。看起来，选择计算机专业就读是 make the right choice。相信也有很多人后悔了当初的选择，明明当初高考考上了建筑系，甚至考上了交复，为啥十年过去，挣的还比当年不如自己的人少那么多。
但是 make the right choice 这件事，其实是不具有可复制性的，很多时候完全就是运气。而对个人来说，重要的是 make the choice right。做决定非常非常重要，但是很多时候，我们经历的失败，并不是因为我们 make the wrong choice，而是 make the choice 后，你没有做好罢了，而抱怨昨天的自己并不能让你变好。
而对于那些 make the right choice 的同学，也不要随便把成功归因于自己的能力，可能你只是运气比较好。而运气好这件事有一个很明显的缺点，就是你不可能永远运气好。</description></item><item><title>How to be successful</title><link>https://chenminhua.github.io/posts/2022_how_to_be_successful/</link><pubDate>Wed, 20 Jul 2022 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2022_how_to_be_successful/</guid><description>再读 https://blog.samaltman.com/how-to-be-successful
追求复利，你的单位产出应该越来越高。 蜜汁自信。 独立思考，并找到能分享观点的人。 善于销售你的观点，尤其是书面沟通能力。 让 take risks 变得容易。 Focus Work hard Be bold Be willful Be hard to compete with。建立人脉，创建个人品牌，多领域涉猎。 Build network 用你自己的优势而不是劣势定义你自己 You Get rich by owning things 内在驱动。 Compound yourself 追求复利，能力以几何级数增长。保持高的学习指数。 你的单位产出应该越来越高，不要留在一个工作两年和二十年的人在效率上无差别的行业。 有很多东西能给你加上这个杠杆，比如资本，科技，品牌，人际关系影响，和做管理。 花一点时间来确定你下一步要做什么。如果我选择的这件事成功了，这件事能够让我职业生涯中的其他事情都微不足道。 One of the notable aspects of compound growth is that the furthest out years are the most important. 但具备长期思维能力也是最难的啊。 Have almost too much self-belief 蜜汁自信，需要尽早培养。自信并不是不承认自己的错误，也不是不接受他人的批评，那是自大。 大部分奋斗者最大的挑战是如何管理好自己的士气、团队的士气。这需要非常多的自信。 大部分很成功的人应该都有一次面对他人否定而最终证明自己是正确的的经历。 勇气来自于你深知自己可以在失败之后重振旗鼓的信念。 Learn to think independently Thinking from first principles and trying to generate new ideas is fun, and finding people to exchange them with is a great way to get better at this.</description></item><item><title>一些职业思考</title><link>https://chenminhua.github.io/posts/2022_%E4%B8%80%E4%BA%9B%E8%81%8C%E4%B8%9A%E6%80%9D%E8%80%83/</link><pubDate>Sat, 16 Jul 2022 18:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2022_%E4%B8%80%E4%BA%9B%E8%81%8C%E4%B8%9A%E6%80%9D%E8%80%83/</guid><description>昨天和最近带的一个同学 1 on 1（下面简称A），A问我有没有什么建议可以给到他。我想了一会儿，和他说了几点，不一定对，但是希望能帮到他。
ROI 与 push back 刚入职场的工程师往往有个特点，产品提什么需求都愿意接。但是当你成为更高级别的工程师，甚至成为一个方向的owner或者团队leader的时候，你会明白需求是做不完的，你一定要有计算 ROI 的能力，并且能够合情合理地 push back 一些事情。你需要学会把自己和团队的时间放在最值得做的事情上。
当你还是一个初级工程师的时候，其实你做的事情都是被筛选过的有价值的事情，但是当你负责一整个方向的工作时，优先级意识和ROI意识是必备的。这种意识需要从一开始就锻炼起来。
多问“蠢”问题 初级工程师常犯的另一个错误是不敢问问题，比如需求评审的时候，有个地方A不清楚，于是A就想，可以会后再去调研一下。但是更好的办法可能是直接抛出问题。直接抛问题有两个好处：第一是能快速对齐，澄清事实。第二点是建立形象，当你习惯于直接抛出问题后，就会在别人心中建立这样的形象，你是一个会直接抛出问题的人，以后大家在和你合作的时候就会比较放心（不会担心你憋着问题）。
提高 impact 提高 impact 需要你多去帮助别人，而这又需要你对业务和技术有更深的理解。比如你在做某个方向需求的时候，遇到了一个不懂的领域，不要错过它，不要只停留在把需求做完。抓住每一个机会，去了解业务和技术背后的东西，这样当以后别人遇到这个问题的时候，他们都会来找你，当这块需要一个owner的时候，你的leader也会很容易想到你。
不要用工作时长证明自己 A是转岗到我们团队的，他之前的团队据说很卷，大家都习惯于每天十点半以后才下班，他们的leader在绩效打分的时候，也会参考大家的下班时间。因为A当时是应届生，虽然不愿意，但是也和大家一样待到很晚，而转到我们这边的时候，发现我每天都九点前就下班，还觉得很奇怪。
其实我觉得，如果一个团队是用工作时长来衡量你的产出，那说明这个团队压根没什么真正的产出。
更何况，人生除了工作，还有很多重要的事情要做，无论是和朋友建立联系，还是锻炼身体，或者学习以提升自己，甚至就是休息（以达 well being）。工作效率很重要，在完成工作之后，需要为自己争取属于自己的时间，这样才不会 burn out。
和同事搞好关系 The steady state of a successful Internet Century venture is chaos&amp;hellip; Champion racecar driver Mario Andrett: &amp;ldquo;If everything seems under control, you&amp;rsquo;re just not going fast enough.&amp;rdquo; The business should always be outrunning the processes, so chaos is right where you want to be.</description></item><item><title>面试反问问点啥</title><link>https://chenminhua.github.io/posts/2022_%E9%9D%A2%E8%AF%95%E5%8F%8D%E9%97%AE%E9%97%AE%E7%82%B9%E5%95%A5/</link><pubDate>Tue, 12 Jul 2022 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2022_%E9%9D%A2%E8%AF%95%E5%8F%8D%E9%97%AE%E9%97%AE%E7%82%B9%E5%95%A5/</guid><description>如果我加入了，你们会怎么帮助我 ramp up 看看这个团队是不是有明确的 onboarding 机制。如果答得乱七八糟，或者每个面试官说的都不一样的话，小心了，没准你进去第二天就要开始修bug了。
团队的业务是什么，愿景是什么？ 看看这个团队做的事情是不是你感兴趣的。
我个人曾经有过一段失败的工作经历，当时我面上了一个全球top3的公司的团队，我以为我会去做数据库开发，但是入职后发现并非如此，而且工作内容和我的经验与能力并不匹配，尽管团队的同事和文化都很棒，但是四个月后我还是主动提了离职。
很多时候招聘的JD其实都很模糊，你应当在面试过程中尽可能多的了解工作内容的细节。甚至可以问问需求迭代的细节，比如需求是怎么出的，迭代流程是怎么样的等等，这些都和你能否适应这份工作息息相关。
团队面临最大的挑战是什么？当前团队最重要的事情是什么？ 看看这个团队是否有好的规划。很多坑团队其实都没有明确的规划，一旦进去之后可能业务变来变去，你也不能得到很好地沉淀下来做事的机会，工作体验也会很糟糕。
你们最看中工程师身上的什么品质？ 老实说这个问题其实问不出太多，大多数面试官给的都是一些比较空的词。但是可能可以排坑，所以我还是蛮喜欢问的。</description></item><item><title>关于保险</title><link>https://chenminhua.github.io/posts/2022_%E5%85%B3%E4%BA%8E%E4%BF%9D%E9%99%A9/</link><pubDate>Fri, 20 May 2022 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2022_%E5%85%B3%E4%BA%8E%E4%BF%9D%E9%99%A9/</guid><description> 买保险不是为了理财，是为了应对小概率发生的风险
拒绝理财性质的保险 看清楚免责条款 推荐险种 百万医疗。医疗险是用多少报多少，随报随销，有上限。 便宜，60周岁以前都能买，可以续保到80周岁。 需要每年续签，有无法续保的风险。 明确犹豫期，等待期，免赔条款，续保等概念。 定期重疾险。重疾险是一次性给予经济补偿。 20-40岁的人比较便宜。对突遭变故家庭可以有个平滑过渡。 一年期重疾也有续保问题存在，并且保额比较低。赔付时沟通成本比较高。 现在很多保险产品都宣称100+重疾，但其实基础的25种已经涵盖了99%的人群。需要注意。 终身重疾：太贵了。可以考虑给孩子投保 定期寿险。当你是家庭主要经济来源时，要买。 保费低，杠杆高。一份300万保额，20年期寿险，30岁男性保费在2800/year 左右。女性是男性的一半。死亡给付没有附加条件，赔付流程简单。 意外险</description></item><item><title>2022年3月中概暴跌</title><link>https://chenminhua.github.io/posts/2022_%E4%B8%AD%E6%A6%82%E6%9A%B4%E8%B7%8C/</link><pubDate>Mon, 21 Mar 2022 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2022_%E4%B8%AD%E6%A6%82%E6%9A%B4%E8%B7%8C/</guid><description>本文不构成任何投资建议
暴跌原因 导火索：PCAOB(public company accounting oversight board) 把五家中概股公司放入外国公司问责法识别清单，将中美监管摩擦再次推到前台。进而引发市场恐慌。
其他：
滴滴大跌。 国家监管，反垄断，打压互联网公司。美团，阿里，腾讯，教育行业。 俄罗斯乌克兰战争。long only 可能很多都走了。（美国总体资金有 10%在国际市场，哪里有机会去哪里转） 底层 为什么非要去美国上市，而不去香港上市？一个原因是香港流动性太小，第二是美股上市逃避监管，第三是美国上市有品牌效应，第四是美国有比较完整的诉讼体制（事先宽松，事后诉讼）。
中国出公司，美国出体制。但是这个游戏可能未来会玩不下去。
PCAOB 这个事情可能是无解的，所有在美国上市的公司都是要把审计底稿给美国看的，唯一的例外是中国。审计底稿里面都是脏东西，一旦公开会有很大麻烦。
出路 一种可能的发展方向是，公司自查，有问题的退市回香港；没问题的写个保证书然后在美国呆着，但是如果交底稿让人抓住把柄，就会被严惩。（一般来说大公司都有问题）
中国互联网公司上市出路在哪里？只能等一等了。
buy? or sell? 我非常同意中概股依然存在很大的风险。但是我们还是应该聊聊什么是中概的风险。（可以去看我之前的文章「风险与收益」）
毫无疑问我们上面说到的暴跌原因都是风险，但最本质的风险还是价格。
高风险=高价格
最大的投资风险存在于最不容易被 察觉的地方，反之亦然。在所有人都相信某种东西有风险的时候，他们不愿购买的意愿通常会把 价格降低到完全没有风险的地步。广泛的否定意见可以将风险最小化，因为价格里所有的乐观因素都被消除了。 &amp;ndash; Howard Marks
我觉得现在就是价格里面所有的乐观因素都被消除了的时候。
reference https://sv101.fireside.fm/70</description></item><item><title>一生的旅程 -- Iger自传</title><link>https://chenminhua.github.io/posts/2021_%E4%B8%80%E7%94%9F%E7%9A%84%E6%97%85%E7%A8%8B/</link><pubDate>Mon, 21 Mar 2022 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2021_%E4%B8%80%E7%94%9F%E7%9A%84%E6%97%85%E7%A8%8B/</guid><description>Iger 是迪士尼现任 ceo，曾任 abc ceo，后在迪士尼收购 abc 的过程中加入迪士尼，后主导了如收购皮克斯，收购漫威等关键性项目，帮助迪士尼起死回生。Iger 于 2020 年卸任迪士尼 ceo 一职。本文是我今天读完 Iger 自传后的一些摘录。
关于犯错 Iger 在 abc 的第一个老板是一个脾气暴躁的人。有一次在工作中，Iger 犯了个错误，老板很生气，当着所有人的面问是谁把这件事搞砸了。Iger 很羞愧，但还是当着所有人的面承认了错误。老板很吃惊地说：“你居然敢这么做，从来没有人敢承认错误”。Iger 从这件事里面总结了两个经验
在犯错时要敢于承担责任。 管理者要以善待人，用公平和同理心对待每一个人。这不是说犯错没关系，而是要打造出一个环境，让人们知道你是一个会倾听他人讲述事情原委、情绪稳定而处事公平，且会在别人犯下无心之过时给他们第二次机会的人。 关于自知之明 Iger 的第二个老板丹尼斯是个既友善又有趣的人，拥有极具感染力的热情和乐观，最重要的是，他对自己所不懂的事情是有自知之明的。这个特质，在高管身上非常罕见。换作另一个人，若是处在丹尼斯的位置上，便很容易通过伪装权威或常识来对没有电视网工作经验的事实矫枉过正，但这不是丹尼斯的做事风格。在会议期间，大家有时会讨论到某个话题，而丹尼斯不但不会装懂糊弄过去，还会表示自己不懂，并请求我和其他人帮他解释。
提出你必须提出的问题，不带任何歉意地承认自己不懂的东西，做好功课，尽快学到必须学习的东西。
第一条原则，就是不要营造任何假象。你必须保持谦虚，不能把自己佯装成另一个人，也不能不懂装懂。虽说如此，你仍然处在一个领导者的位置上，因此不能让谦虚成了领导他人的绊脚石。这是我在今时今日所宣扬的一个理念，其中的分界线很微妙。你需要提出你必须提出的问题，不要有任何歉意地承认自己不懂的东西，并做好功课，以尽快学到必须学到的东西。没有什么比不懂装懂更能摧毁一个人的自信心了。拥有自知之明，不要假扮别人，这才是真正的权威和领导力的源泉。
我的任务就是不要让自尊心占了上风。我要做的，并不是使尽浑身解数给桌子对面的人留下一个好印象，而是抑制住假装知道自己在做什么的冲动，并多向对方提问。我格格不入，这是无法掩盖的事实。我并没有受过好莱坞的历练，也没有夸张的性格或任何招摇的姿态。
关于迪士尼 Iger 在上任迪士尼 ceo 时，提出了三个战略优先事项。
将绝大多数的时间和资本投入在打造高质量品牌内容上。 在最大限度上拥抱科技，先是利用科技为打造更高质量的产品创造条件，然后再通过更先进和精确的途径来触及更多的消费者。 成为一家真正意义上的全球企业。 毫无疑问，这三点他都做得非常出色。在品牌内容上，他们通过收购皮克斯，漫威等获得了大量优质 IP，并完成了远超预期的开发。在科技方面，他们和苹果有着密切合作，并且也推出了 disney+这些服务。在全球化上，我们也看到了上海迪士尼乐园等一系列发展。</description></item><item><title>不拘一格（网飞的企业文化）</title><link>https://chenminhua.github.io/posts/2022_%E4%B8%8D%E6%8B%98%E4%B8%80%E6%A0%BC/</link><pubDate>Sun, 20 Feb 2022 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2022_%E4%B8%8D%E6%8B%98%E4%B8%80%E6%A0%BC/</guid><description>“人才重于流程，创新高于效率，自由多于管控”
“对于我们的员工来说，透明度代表我们相信员工能够认真负责地对待工作。我们对他们的信任又会增强他们的归属感、使命感和责任感。”
“自由与责任的关系并不是像我先前所想的那样背道而驰，相反，自由是通往责任的一条途径。
人才重于流程、创新高于效率、自由多于管控的企业文化让网飞取得了巨大成功。网飞文化强调以人才密度实现最高绩效，对员工实行情景管理而不是控制，如果一定要说网飞有什么不同之处，那就是它不拘泥于规则。
reed 在 1991 年的时候创办了 pure software，当公司只有十几个人的时候，他们采用了非常自由的管理方式：员工可以在餐厅工作，或者购买办公椅而不需要获得审批。但是这种管理方式也产生了一些问题，由于过于自由，一些员工犯了些愚蠢的错误导致公司受损。面对这些问题，reed 每次都制定了新的规定来防止这些错误再次发生。
但是这些规定和管理流程成了工作的基础，那些擅长在条条框框里循规蹈矩的人得到了提拔，而许多有创造力且特立独行的员工却感到窒息，于是他们便离职去了别处。
由于人才的流失，渐渐地公司创新开始跟不上节奏，虽然效率越来越高，但创造力却越来越弱。为了发展，reed 不得不收购其他拥有创新产品的公司。这就导致业务越来越复杂，规则和流程也越来越多。最终在 1997 年，reed 将公司卖给了最大的竞争对手。
第一，提高人才密度。人才密度越高，你能提供的自由度就越大。 第二，提高坦诚度。 在此基础上，须做好一道减法——减少管控。
首先，将员工手册由厚变薄，差旅、经费支出、休假等相关规定统统可以不要。然后，随着人才密度越来越大，反馈越来越频繁和坦诚，你就可以取消整个组织的审批流程，教会你的经理们“进行情景管理，而非控制管理”，同时让员工把握这样一个原则：工作不是要费心地取悦老板。
最重要的是，一旦你着力营造这样的文化氛围，企业管理便进入了一个良性循环。取消管控将构建一种“自由与责任”（Freedom &amp;amp;Responsibility，简称 F&amp;amp;R）的文化氛围，这也是网飞员工经常挂在嘴边的词。这种文化会吸引很多顶尖的人才，同时又将管控的程度降至最低。实现了这一切，就能让你的公司达到大多数公司无法企及的效率和创新水平。当然，这一切并不是一蹴而就的。
独特的网飞文化
网飞认为你具有惊人的判断力……判断力几乎可以解决所有模棱两可的问题，而流程做不到。
从另一个方面来看……网飞也期待员工发挥出超高的工作水平，不然就得立马走人（不过有一笔丰厚的遣散费）。
第一部分 迈向自由与责任的企业文化 首先，提高人才密度 毫无疑问，具有非凡的创造力、工作出色，且与他人合作良好的员工是留下来的最佳人选。但现在的问题是，许多人都只是在某一方面表现得很好：一些人与同事相处极好，配合默契，但工作能力平平；而另一些人则是工作狂，但缺乏判断力，需要有人引导；同时还存在一小部分人，他们天资卓越，行动力也很强，但是牢骚不断，也很容易产生悲观情绪。他们中大部分人必须离开，但决定让哪些人离开真不是一件容易的事情。
对于优秀员工而言，好的工作环境并不意味着一间豪华的办公室，一个好的健身房，或者一顿免费的寿司午餐，而在于周围全是才华横溢的人，具有合作精神的人，让你不断进步的人。如果每一名员工都很优秀，他们就会相互学习、相互激励，工作表现也会迅速得到提升。
从 2001 年的裁员事件中，里德发现：工作表现无论好与坏，都是具有感染力的。如果你表现平平，可能会影响到很多本可以表现出色的人，导致他们也无心进取。如果你的团队成员个个表现出色，那他们也会相互激励，从而推动彼此取得更大的成就。
其次，提高企业坦诚度 另一项至关重要的，是你在获取反馈时的行为反应。你必须向员工表明，如果你能心怀感激地面对他人的批评，能够给予足够的“认同提示”，那么你也可以放心地提供反馈意见。正如《文化代码》（Culture Code）的作者丹尼尔·科伊尔（Daniel Coyle）所描述的那样，这种认同提示表明“你的反馈将使你成为这个群体中更为重要的成员”，或者“你与我坦诚相待，绝不会对你的工作或我们的关系造成危害。你将得到我们的认同”。我与管理团队经常交流认同提示的问题，因为一名员工就算再有勇气，向领导反馈意见时还是会有担忧。他会想：“领导会不会记仇呢？”“这对我的工作有影响吗？”
认同提示可能只是一个小小的语气或姿势，例如，使用欣赏性的口吻，身体靠说话人近一点儿，用肯定的目光看着说话人的眼睛。当然，你也可以把动作搞大一点，例如，感谢说话者所具备的勇气，并且在众人面前给予赞赏。科伊尔解释说，认同提示的功能是“回答大脑中不断出现的古老问题：我们在这里安全吗？与这些人共处，未来会怎样？有潜在的危险吗？”如果你能通过认同提示对反馈做出回应，员工就会越来越坦诚。
阅读 360 度书面反馈是一件让人感到很刺激的事情。我发现，恰恰是那些最直言不讳的批评是对我最有帮助的。因此，秉持着 360 度反馈的精神，我非常感谢你们勇敢而诚实地给我指出问题，告诉我：“在开会时，如果你觉得讨论话题没有意义或缺乏讨论价值，你可以跳过或者一带而过……同样，不要让你的观点主导了整场会议。你需要协调大家的争论，让大家达成一致的目标。”我感到有些伤心和沮丧，但你们说得太对了，我会继续努力的。希望大家能一如既往地提出和接受建设性的反馈。
4A 反馈准则
提供反馈
目的在于帮助（Aim to assist）：反馈的目的必须是积极的。反馈不是为了发泄，不是为了中伤他人，也不是为自己捞取资本。反馈者应清晰阐述这样做对他人和公司有什么样的好处，而不是对自己有什么好处。“你在与外部合作伙伴会面时在剔牙，这样做很让人生气。”这是错误的反馈方式。正确的反馈应该是这样：“如果在与外部合作伙伴见面时你不再剔牙，那么合作伙伴可能会觉得你很敬业，我们就更有可能建立牢固的关系。” 反馈应具有可行性(Actionable)：你的反馈必须说明接收人可以做一些什么样的改变。我在古巴的那次演讲中，如果收到的是这样一个反馈：“你在演讲过程中的做法与你自己的观点不符。”那这样的反馈就是有问题的。而正确的反馈可以是这样的：“你选取听众发言的方式导致了最后的参与者只有美国人。”或者这样说更好：“如果你还有别的方法，让其他国籍的参会者也发一下言，那你的演讲将更有说服力。” 感激与赞赏(Appreciate)：我们在受到批评时都会为自己辩护或寻找借口，这是人类的本能；我们都会条件反射式地进行自我保护，维护自身的名誉。当你收到反馈时，你需要有意识地反抗这种本能，并且问一问自己：“我该如何去认真地聆听，以开放的心态去认真地对待反馈？既不辩护，也不生气，还应该满怀欣赏和感激。” 接受或拒绝(Accept or discard)：在网飞，你会收到很多人的反馈。你需要认真地听，同时也认真地思考。不是每条反馈都要求你照办，但有必要向反馈者真诚地致谢。你和反馈者都必须清楚：对反馈意见的处理完全取决于反馈的接收者。 当场反馈，实时反馈
► 现在，尝试取消管控……
取消限期休假制度 建立和加强情景管理
自从网飞取消假期跟踪考核之后，其他公司也纷纷效仿，其中包括来自科技行业的玻璃门、领英、Songkick（音乐会推荐应用）、HubSpot（数字营销公司）和 Eventbrite（活动策划平台），还有费舍尔·菲利普斯律师事务所（Fisher Phillips）、高诚（Golin）公关公司，以及电子零售业的 Visualsoft（可视化软件公司）。
给予自由，再落实责任
► 继续尝试取消管控……
取消差旅和经费审批 事前情景设定，事后核实报销</description></item><item><title>服务稳定性建设</title><link>https://chenminhua.github.io/posts/2021_%E6%9C%8D%E5%8A%A1%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%BB%BA%E8%AE%BE/</link><pubDate>Wed, 03 Mar 2021 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2021_%E6%9C%8D%E5%8A%A1%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%BB%BA%E8%AE%BE/</guid><description>第一步：梳理现状 服务的功能有哪些，对线上业务的影响如何。 对服务进行定级，确定是否为重保服务。 确定服务请求量级(峰谷特征)，是否受节日影响，是否受其他接口波动影响。 确定服务部署现状，如是否多机房，是否多集群，是否有灾备预案等等。 梳理上下游，确定服务依赖拓扑，重点确定服务强弱依赖关系。 梳理上下游服务的超时配置，重试配置，熔断，限流配置等。 如果一个下游服务 b 不可用会导致上游服务 a 不可用，则 a 强依赖 b。 如果下游服务 b 不可用会导致上游服务 a 部分功能受影响，但主体功能仍然可以工作，并且业务可短暂接受这种影响，则 a 弱依赖 b。
第二步：问题发现能力 监控报警 检查监控大盘，看是否能覆盖可能出现的问题。常用的监控报警指标包括 服务稳定性 服务拉空率 vv计数 异常指标计数（比如由于某个特定原因对内容进行过滤的量级等） 错误日志计数 RPC调用错误计数 通过调整报警阈值，检查报警规则是否生效，能否准确发出消息或拨打 oncall 同事电话。 容灾演练 模拟故障，通常是模拟网络故障。检查自适应容灾是否生效，以及手动降级预案是否生效。
压测 通过压测寻找资源瓶颈，可能的瓶颈包括
当前压测服务自身资源瓶颈，cpu，内存等。 下游服务资源瓶颈。 依赖存储瓶颈。 如果当前压测服务与其他服务共享下游服务或存储，则可能需要联合压测。
压测可以通过线上流量集中的方案来实现，也可以使用提前录制流量的方案来实现（前提是请求没有副作用）。 如果是写接口，还可以考虑创建影子表等方式来进行压测。
问题定位与处理能力 服务日志要完整。这一点依赖研发工作经验，以及 code review 的负责程度。 内部整理 case 排查指南，问题记录与分享，每周组织学习。 设立 oncall 机制，创建 oncall handbook。 当发现问题时，需要有明确 sop，并通过演练确保所有人都能处理线上事故。 当线上出现事故时，有两种可能，一种是用户反馈发现问题；一种是监控报警发现问题。 无论是哪种情况，首先要对问题严重性有一个基本的判断。（这个也依赖经验和组内分享，比如少量的服务调用报错报警，可能只是网络抖动，但如果用用户反馈说他的账户余额不对，则可能就很严重了） 如果判断出来这是一个需要处理的线上问题，第一步要找同学帮忙，立即成立应急小组，明确分工。比如A同学负责拉群（需要周知到各个职能线），建立会议，并建立事故处理文档；B同学负责定位问题；当然，如果明确知道发生事故前有线上操作（通常都有），比如有代码上线，动态配置，实验开启等，一律先进行线上止损（回滚，或关闭实验）。 事故应急处理负责人需要实时同步事故处理进展。 事故后需要有复盘和todo。 需要有机制check todo落实。 降级开关 容灾预案</description></item><item><title>切尔诺贝利（一键容灾预案引发的事故）</title><link>https://chenminhua.github.io/posts/2021_%E5%88%87%E5%B0%94%E8%AF%BA%E8%B4%9D%E5%88%A9/</link><pubDate>Sun, 03 Jan 2021 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2021_%E5%88%87%E5%B0%94%E8%AF%BA%E8%B4%9D%E5%88%A9/</guid><description>看完了 HBO 的《切尔诺贝利》，真相在最后一集揭晓。
故事中的切尔诺贝利 4 号反应堆，原本应该在建成时就完成的安全测试，在投产后三年都没有完成，并且在事故前已经失败了三次。（容灾演练连续失败三次） 原本应该在白天进行的安全测试，由于基辅电网对产量的要求而推迟，而此时核电站已经半功率运行了半天。（容灾演练随意修改时间） 夜间进行安全测试时，操作员是新人，完全不知道如何操作。（没有事前培训） 安全测试没有通知其他部门的人。（没有对齐其他部门） 半功率运行了半天的反应堆产生了大量的氙气，导致反应堆毒化。 安全测试开始后，需要先降低反应堆功率，而由于反应堆毒化，功率降低过快，很快低于计划的 700mw，并直接降到了 30mw。当值班主任判断出反应堆毒化后，建议先停机后，当时在场负责人佳特洛夫却一意孤行，要求尽快恢复反应堆功率。（发现异常没有立即停止容灾演练） 操作员为了能恢复反应堆功率，将几乎所有控制棒从反应堆内拔出。但由于反应堆毒化，功率仍然没有快速升高，而是维持在了 200mw。 当氙气消耗完后，反应不再受到抑制，功率骤升。当时值班主任阿基莫夫急忙按下 az-5 按钮，试图关停反应堆。（正是这一操作导致了悲剧） az-5 按钮按下后，原本被拔出的控制棒全部同时被插回反应堆。原本这是个「一键容灾预案」，结果由于控制棒的顶端是石墨构成的，石墨会加速反应，这让原本就快要失控的反应堆功率继续上升，引发了爆炸。（容灾预案本身有 bug） 更惨的是，当时的反应堆是单层防护，爆炸后，堆芯直接暴露在空气中，直接伤害了当地居民，并让后续清理工作变得异常困难。(还 TM 没有兜底方案) 当爆炸发生后，加特洛夫还不肯向上反映真实情况，人民不能在最短时间内得到疏散。（没有坦诚面对问题，没有立即止损） 「az-5 容灾预案」的 bug 在三十年前就被发现，但是并没有被严肃对待。（任由线上问题存在） 《切尔诺贝利》是一部非常非常值得观看和反思的作品，有着极大的教育意义。对于软件工程师来说，虽然我们的工作不是操作核电站，但这场人类史上最大的事故也能教会我们很多。
容灾演练应该事前有计划，有安排，有培训，有在线下环境执行过的预案。 容灾演练前要对齐其他部门，避免其他部门由于信息缺失造成恐慌，甚至执行错误的预案或操作。 一旦发现异常立即停止容灾演练，系统优先恢复正常。 系统本身应该有兜底方案，无论是否执行容灾演练，应确保兜底方案有效。 出现事故应该立即止损。 容灾预案不应该有 bug。 发现系统 bug 应该及时同步，并设立 todo 定期检查，查漏补缺。</description></item><item><title>风险与收益</title><link>https://chenminhua.github.io/posts/2020_%E9%A3%8E%E9%99%A9%E4%B8%8E%E6%94%B6%E7%9B%8A/</link><pubDate>Fri, 18 Dec 2020 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2020_%E9%A3%8E%E9%99%A9%E4%B8%8E%E6%94%B6%E7%9B%8A/</guid><description>“高风险带来高收益。”
这句话乍一看，确实是这么回事，比如你今年买了特斯来的股票，起起伏伏间，一年翻了 10 倍，高风险高收益吧；而如果你买了银行定期，自然没什么亏本的风险，但是年化还不到 4%，收益和特斯拉股票一比，差了几百倍，低风险低收益。
但是等等，收益我懂，可什么是风险呢？风险是亏本的可能性？风险是波动的大小？
什么是风险 搞金融的人会用 夏普比率 来描述一个资产在同等风险下的收益能力，其实就是用资产赚钱的期望除以资产的波动。通常你只要记住
夏普比率越高，在相同波动下赚钱的期望越高。
可是，波动本身不会让你亏钱，让你亏钱的只有一件事：高价格。你以高出资产本身价值的价格购买了资产，你亏钱的概率就变高了。这和资产本身的质量无关，只和价格有关。无论你买的是茅台还是苹果的股票，重要的永远是价格。风险并不来自波动，而是来自价格。所以我觉得正确的说法是
风险=高价格。
由此，我们可以进一步推出，当价格上升时，风险在积聚，而当价格下降时，风险在释放（并转化为很多人的亏损）。
即风险在经济上升时增加，并且随着经济失衡的扩大在衰退期化为现实。 即价格上涨风险增加，经济下行，风险变为现实（亏损）并释放。
再进一步，如果「风险=高价格」，而「高价格=低收益」，那我们便可得到一个反直觉的结论：
高风险=低收益
他们不过是同一枚硬币的两面。（我这的是很喜欢说这句话）
风险与收益 其实，「高风险低收益」与「高风险高收益」并不矛盾。只不过，我们对风险的理解并不相同。对于价值投资者来说，风险并不来自于波动，而是来自于高价格。
在牛市中，「高风险高收益」的想法可能更加危险。因为在牛市，投资者容易超过自己能力地去承担过多风险，比如更激进地使用杠杆，或者对高价格失去敏感，更害怕错过「千载难逢的财务自由机会」。
此外，投资者在牛市会降低自己对风险溢价的要求，这导致承担风险所带来的回报补偿降低（风险的价格下降）。简单概况就是：
资产涨价，风险增加，预期收益下降，风险溢价下降。你承担的风险变多，可风险带给你的收益并没有变多。
什么时候风险最大？ 当大家都认为风险已经消除的时候。所有人都坚定地认为该资产没有风险，于是，风险溢价降低，购买意愿上升，大家会用更激进地态度来对待这个资产，反而让风险不断扩大。
更好的安全装备可能吸引登山者承担更多的风险 ——实际上会令他们更不安全。
最大的投资风险存在于最不容易被 察觉的地方，反之亦然。在所有人都相信某种东西有风险的时候，他们不愿购买的意愿通常会把 价格降低到完全没有风险的地步。广泛的否定意见可以将风险最小化，因为价格里所有的乐观因素都被消除了。 &amp;ndash; Howard Marks</description></item><item><title>RocksDB</title><link>https://chenminhua.github.io/posts/2020_rocksdb/</link><pubDate>Tue, 10 Nov 2020 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2020_rocksdb/</guid><description>认识 RocksDB RocksDB 是什么? 一个嵌入式的 lsm style 的 kv 存储引擎，一个 c++的库。 key 和 value 都是 byte streams，key 按序存储。 高度可定制，能通过组装不同模块的方式适应不同类型的磁盘，负载。 能够通过增加 cpu core 以及 IOPs 进行线性 scale。 为 flash 和内存做优化。 RocksDB 不是什么？ rocksdb 没有 server code，用户需要自己实现 server 的部分来得到 c-s 架构的数据库。 RocksDB 不是分布式数据库，没有 fault-tolerance 和 replication 机制，也没有实现 data-sharding。 Not distributed，No failover.No HA, if machine dies you lose your data. 为什么需要 RocksDB 基于 flash 存储的 ssd 普及，网络 latency 在 query workload latency 中占据的比例越来越高。embeded 数据库变得受欢迎。 dhruba 尝试比较 HBase/HDFS 和 mysql 在 query serving workload 上的表现。经过多次优化后，在机械硬盘上，几 pb 的数据集下，hbase 可以达到比 Mysql 慢两倍的查询速度。但是在 ssd 上，hdfs/hbase 等 hadoop 生态存储在当时还不能高效利用 flash，因此 dhruba 开始试图探索新的存储引擎。（dhruba 开始试图扩展 hdfs/hbase 的能力，使其能 serve query workload。但是随着 flash 的普及，他发现 hdfs 对 flash 的使用效率不高。并且将 hdfs/hbase 改成嵌入式的难度太高，因此他决定开发新的数据库存储引擎。） 当时市面上有一些嵌入式数据库，leveldb 是其中的佼佼者。http://leveldb.</description></item><item><title>限流与过载保护</title><link>https://chenminhua.github.io/posts/2020_%E9%99%90%E6%B5%81%E4%B8%8E%E8%BF%87%E8%BD%BD%E4%BF%9D%E6%8A%A4/</link><pubDate>Thu, 22 Oct 2020 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2020_%E9%99%90%E6%B5%81%E4%B8%8E%E8%BF%87%E8%BD%BD%E4%BF%9D%E6%8A%A4/</guid><description>过载保护 微信的这篇论文有个很好的介绍
过载控制往往需要对不同的服务进行专门设计，但是这种过于细致的过载控制对于整个系统来说是不利的，开发者很难估计每个服务应该可以承受的负载。
为此，微信采用了一种名为 DAGOR 的过载控制设计，在 service 粒度上管理过载，使得每个微服务的负载能被实时监控。
由于服务之间复杂的依赖关系，比如一个请求依赖 k 个服务，而这些服务都有 p 的概率拒绝服务，那么这个请求成功的概率就是 (1-p)^k。如果 k 比较大的话，服务的 sla 会明显下降。
DAGOR DAGOR 的基本机制是：当请求到达时，为其分配一个业务优先级和红黑优先级，根据这个优先级使得它下游的服务可以强制接受或者拒绝这个请求。每个服务都有一个自己的优先级阈值，并根据其检测到的当前负载情况调整阈值。
过载检测 另一个问题是，服务如何判断自己是否处于过载状态？DAGOR 采用等待队列里的平均等待时间（简称排队时间（queuing time））来检测负载状况。
排队时间 = 请求开始被处理的时刻 - 请求到达此服务的时刻。
为什么不用 response time 或者 cpu 利用率 来检测负载情况呢？
对于一个服务来说，responese time 不止收到其自身处理请求速度（自身负载）的影响，也受下游服务处理时间的影响。 cpu 利用率即使很高，但如果请求能被及时处理，我们也不应该认为服务进入过载状态。 而 queuing time 则仅受本服务处理能力的影响。如果一个服务有足够的资源来处理请求，queuing time 就会很小，及时下游返回慢，本服务 queuing time 也不会被影响。 DAGOR 的过载检测是基于窗口的，比如在微信系统中，每秒或者每 2000 个请求，server 就会刷新它的监控状态。微信中平均的 queuing time 阈值为 20ms，超过了就意味着服务过载了。
限流 单实例限流 简单的令牌桶就可以实现，可以基于 mesh 实现，或者基于服务框架实现。
分布式限流 常规手段还是使用 redis 计数，但是由于热 key 的问题，一般只适合于 qps 有限（小于 1w）的场景。 如果是高 qps 场景，通常都不需要精准限流，可以考虑退化到单实例限流模式。 如果是高 qps 并且需要精确限流，方案比较复杂。 key = fmt.</description></item><item><title>geohash</title><link>https://chenminhua.github.io/posts/2020_geohash/</link><pubDate>Mon, 12 Oct 2020 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2020_geohash/</guid><description>今天你想吃火锅，于是你问 siri，&amp;ldquo;离我最近的火锅店有哪些？&amp;quot;。
怎么实现这个功能呢？首先你应该抽象地想想，这是一个什么问题？
这是一个「二维空间查找最近邻」问题，而「最近邻」又比较容易让人想到”KNN“。（KNN 是说每个新样本的分类可以用离这个样本最近的 K 个样本的分类来表示，而我们这里要做的并不是一个分类问题，但是 knn 通过哪些手段来找到最近的 k 个样本&amp;ndash;尤其是在样本量很大的时候，则非常值得参考。比如说 kd-tree 之类的）。
但是如果我们更多地往「查找」上面想，我们就会想到「二分」，想到「查找树」，想到「哈希」。
先来简化一下这个问题，「一维空间查找最近邻」怎么弄？
这个问题我们都会，比如把所有元素存在一个有序数组中，然后二分查找，查找的时间复杂度为 O(log n)。数组虽然查找快，但是它的缺点是插入、删除、更新的速度太慢了，如果我们希望在保持查找速度的同时提升插入、更新、删除的速度，就要用到树。
那如果现在我们有一个二维空间，怎么建树呢？kd-tree 就是一个建立多维树的方法。但是我们还有别的方法，我们可以想想，怎么把二维空间变成一维。也就是说我们寻找一个函数。
f(x, y) -&amp;gt; z 这个函数必须满足以下特性，假设我们有(x1, y1) 和 (x2, y2)，如果 x1 约等于 x2，并且 y1 约等于 y2，则 z1 约等于 z2；只要 x 或者 y 两个特征中有一个相差很大，z 就必须相差很大。也就是在二维空间接近的两个点的 z 要接近，而在二维空间上距离远的两个点的 z 要远。
GEOHASH 完美的解决了这个问题。GEOHASH 的算法其实非常简单，就是将地理位置的经度和纬度分别二进制化，然后交叉编码。比如一个地理位置的经度编码为 10000，纬度为 10111&amp;hellip;，则编码后得到的 geohash 为 1100010101，然后再将这个二进制数进行 base32 编码，比如这里得到的就是 SP&amp;hellip;。
现在假设有三个地址，编码是 SP456，SP457，45FP3，显然 SP456 和 SP457 离得比较近。我们成功的将「二维空间查找最近邻」的问题变成了「字符串前缀匹配」的问题。而字符串前缀匹配的问题就简单了，构造一个树做索引就行了。</description></item><item><title>不要在错误的位置和错误的人发生错误的竞争</title><link>https://chenminhua.github.io/posts/2020_%E7%AB%9E%E4%BA%89/</link><pubDate>Sat, 23 May 2020 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2020_%E7%AB%9E%E4%BA%89/</guid><description>程序员行业是一个准入门槛极低但竞争非常激烈的行业，但高级程序员是一个准入门槛不高但竞争非常不充分的行业。尽管我还没有达到高级程序员的水准，但据我的观察，我觉得从初级程序员到高级程序员的路，并不坎坷，只是很多人都走歪了。
记得《Becoming Warren Buffett》里面，巴菲特说的，
成功的关键在于玩自己擅长的游戏。
好胜心能帮助我们成功，但有时也会害了我们。对于那些从小的“聪明人”，他们受好胜心的“伤害”更大。因为他们在任何竞争中都想要赢，也就更容易忽略这个游戏是不是自己擅长的游戏，该不该玩这个游戏。在职场中，每个公司都有自己的企业文化和规则，就好像游戏的规则一样。我们很容易进入努力适应规则的状态，以成为这个游戏中的赢家，却忘了自己其实可以选择不玩这个游戏。
而真正的高端玩家应该要先能够分辨出，自己该坐上哪个牌桌，而不是直接上桌玩牌。
Before the game start, Know your game.</description></item><item><title>隔离 -- 我们都是这疯狂世界的受害者</title><link>https://chenminhua.github.io/posts/2020_isolation/</link><pubDate>Fri, 07 Feb 2020 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2020_isolation/</guid><description>John Lennon《Isolation》的最后写到「你不必受到责怪，你也不过是一个普通人类，一个疯狂世界的受害者。我们害怕每一个人，害怕阳光。太阳永远不会消失，可留给这个世界的时间已经不多了。」
People say we got it made,
don&amp;rsquo;t they know we&amp;rsquo;re so afraid?
Isolation.
We&amp;rsquo;re afraid to be alone,
Everybody got to have a home,
Isolation.
Just a boy and a little girl,
Trying to change the whole wide world,
Isolation.
The world is just a little town,
Everybody trying to put us down,
Isolation.
I don&amp;rsquo;t expect you to understand,
after you&amp;rsquo;ve caused so much pain.
But then again, you&amp;rsquo;re not to blame,</description></item><item><title>事务</title><link>https://chenminhua.github.io/posts/2020_%E4%BA%8B%E5%8A%A1/</link><pubDate>Thu, 16 Jan 2020 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2020_%E4%BA%8B%E5%8A%A1/</guid><description>尽管大多数程序员都认为事务是如此简单和自然，但事实上事务不是一个天然的东西，而是人为创造出来的，目的是为了简化应用层编程。
对应用层来说，底层可能出现的错误实在太多了。网络可能中断，数据库软件可能崩溃，应用程序自身可能突然崩溃，机房可能断电，数据更新可能被覆盖导致丢失，或者读到一些部分更新的数据。而事务就是一种将一系列操作捆绑成一个原子操作（一起成功或一起失败），并对外提供隔离性和持久性，从而将复杂的并发读写问题从应用层抽离到数据库层面的技术手段。
换句话说，即使没有事务，应用层有时也能工作。但是没有原子性保证后，操作的中间状态会多的让人崩溃，错误处理也会异常复杂。而如果没有隔离性，则会出现各种并发导致的数据覆盖导致更新丢失，或者读到中间状态数据的问题。
事务提供了什么 ACID，即原子性，一致性，隔离性，持久性。
原子性：在出错时中止事务，并将部分完成的写入全部丢弃。也许可中止性比原子性更为准确。 一致性主要只对数据有特定的预期状态，例如对账单系统来说要保证账户金额平衡。事实上，一致性更多是靠应用层来保证的，应用程序需要依靠数据库提供的 AID 来达到一定的 C。（Joe Hellerstein 曾经说过，C 只是为了让 ACID 这个缩略词读起来更顺口，lol） 隔离性意味着并发执行的多个事务相互隔离，不能相互交叉，虽然实际上他们可能同时运行，但是数据库要保证数据提交时，其结果与串行运行一样。 持久性意味着一旦写入成功，即使数据库崩溃，数据也不能丢。 除了 ACID 之外，存储系统有时候还会提供一些高级功能，比如当事务失败之后，究竟应该如何表现？一个简单的方案是直接丢弃所有请求。而有些无主节点的分布式存储系统则会采取“尽力而为”的策略，尝试多做一些工作。还有一些系统会采用在应用层重试事务的策略，这需要格外小心重复写的问题。在分布式系统中，错误处理是非常尴尬的事情，原因在于你对错误的了解是不完备的，除非对方系统能明确告知错误类型，否则你很可能无法得知真正的错误类型。
另外还要补充一点，有些时候逻辑上的事务可能会跨存储，甚至会有不可逆的副作用（比如发短信，当你发现事务无法提交成功而必须回滚，可是消息却已经发出去了）。对于这种跨系统的事务，我们可以采用补偿机制，两阶段提交机制等等方式来实现分布式事务。
弱隔离级别 前面我们提到，隔离性要保证并发执行的多个事务相互隔离，不能交叉。首先我们应当澄清，当两个事务需要读写的数据完全没有交集的时候，即使他们是同时执行的，也不会导致并发问题（尽管有时候我们认为负载问题也是并发问题，但这里我们认为他们完全是两码事）。
一种实现隔离的方式是串行执行，有时候，这可能会是个好主意（比如对于 redis 这种基于内存的 kv 数据库），但对于大多数关系型数据库应用场景来说，串行带来的性能损失是不可接受的。更重要的是，这种完全拒绝并行的方案非常危险，因为只要有一个事务被卡住了，其他事务将完全无法工作。
因此，数据库通常会提供串行化之外的其他相对较弱的隔离级别。弱隔离级别会带来一些并发问题，甚至已经造成了大量损失，但是在并发性的诱惑下，这些弱隔离级别得到了广泛应用。
读-提交 读提交是最基本的事务隔离级别，它提供了两个保证：只能读到已经提交的数据（防止脏读）；只能覆盖已经提交的数据（防止脏写）。
防止脏读的一种策略是，对于每个待更新的值，数据库都会维持新值和旧值两个版本。事实上支持快照隔离级别的存储引擎会直接采用 MVCC 来实现读提交。
而对于脏写的问题，数据库通常采用行级锁来实现，当事务想要修改某行时，它必须首先获得行锁，并持有到事务提交。如果有另一个事务也想改这行，则必须等待。这种锁定机制是读提交模式下数据库自动完成的。
读倾斜 读提交会带来一些数据不一致的问题，我们来看下面这个例子。
假设 Alice 在银行有 1000 美元存款，分两个账号，各 500 美元。然后她从账号 1 转了 100 美元到账号 2。但是在转账的过程中，她有可能在查自己账户的时候，会发现自己只有 900 美元了。
trx1: select balance from accounts where id = 1; 返回 500 美元。 - 下面事务 2 开始转账 trx2: begin; trx2: update accounts set balance = balance + 100 where id = 1; trx2: update accounts set balance = balance - 100 where id = 2; trx2: commit; - 事务 2 转账结束，并提交 trx1: select balance from accounts where id = 2; 返回 400 美元。 这种现象就是读倾斜(read skew)，也叫不可重复读。在有些场景下，不可重复读不是什么大问题，但是有时候，可能会带来灾难。</description></item><item><title>软件随想录(by Joel Spolsky)</title><link>https://chenminhua.github.io/posts/2020_%E8%BD%AF%E4%BB%B6%E9%9A%8F%E6%83%B3%E5%BD%95/</link><pubDate>Sat, 11 Jan 2020 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2020_%E8%BD%AF%E4%BB%B6%E9%9A%8F%E6%83%B3%E5%BD%95/</guid><description>这周在地铁上读完了 Joel Spolsky 的《软件随想录》，译者是阮一峰。摘录或提炼一部分有趣的东西于此。
1991 年，Joel Spolsky 加入微软 Excel 开发小组，担任 Program manager。他当时需要为 Excel 的宏寻找一个解决方案（其实就是 basic 语言内嵌到 excel 中）。Joel 为这个功能编写了 500 页的规格说明书，并打印出来交给 Bill Gates 审查。令 Joel 惊叹的是，Bill 用一个晚上就看完了 500 页说明书，并写满了备注的问题，同时在审查会议上，提出了各种非常专业的技术问题。Joel 说，「你不能糊弄 bill，哪怕是一分钟，因为他也是一个程序员，一个真正的程序员」。
同所有行业的人才一样，优秀的程序员不会出现在招聘市场上。一个推论是，在人才市场上找工作的人，大部分是一些水平很差的人（真正牛逼的程序员不需要找工作，他们可以去任何他们想去的地方，而雇佣他们的人如果不是太蠢，也会想尽办法留住他们）。而想要得到那些真正的人才，除了自身牛逼之外，还有三个方法。第一，去牛逼大学里面找牛逼学生，给他最好的实习机会。第二，去优秀的技术社区找，尤其是那些极客扎堆的。第三，建立自己的社区以吸引人才。
好的管理不应该只是告诉别人做什么，也要告诉他为什么要这么做，以获得对方的认同。
Joel 说，「我从来没见过哪个能用 scheme 语言、haskell 语言和 c 中的指针写代码的人，不能在两天内学会 java」。常春藤院校只教 unix，函数式编程、状态机理论，而顺着学校排名往下看到一些比较差的学习，java 语言开始在课程中出现了。（lol）
在一个研究型大学里，系主任实际上是一种负担，没有人真的想干，大家都更愿意去做研究。硅谷式的管理风格正是这样。经理存在的唯一理由就是把家具的位置摆好，不要挡道。这样天才才能做出优秀的成功。
那些决定游戏规则的人都是善于写作的人，为什么 C 语言是最流行的语言，原因是创始人 Brain Kernighan 和 Dennis Ritchie 写出了一本伟大的书。（《The C Programming Language》确实是一本非常非常棒的书，我至少看了三遍）
最有权势和影响力的程序员正是那些表达能力强的程序员，无论书面还是口头，他们都能清晰、自如、有说服力地表达观点。
为了发现可以改进的地方，你必须有一个思维定势，始终用批判的眼光看世界。随便找一样东西，如果你看不出它的缺点，那么你的思维转型还没有成功。
眼睛的工作原理与内存访问的 page-fault 机制有类似之处。
「说实话，我觉得“杜绝信息孤岛”对“架构太空人”最有吸引力。那些人看到子类就会想到抽象的基类，他们喜欢把功能从子类移到基类中，但是又说不出实际好处，唯一理由就是这样符合软件架构上的美学」。
别给用户太多选择。太多选择实际上损害了我们内心的幸福感。（Barry Schwartz 《The Paradox of Choice: Why More is Less》）</description></item><item><title>Haystack(facebook是怎么存照片的)</title><link>https://chenminhua.github.io/posts/2019_haystack/</link><pubDate>Wed, 25 Dec 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_haystack/</guid><description>本文写于 21 世纪 10 年代最后一个圣诞节的晚上，内容为 facebook 的论文 《Finding a needle in Haystack: Facebook’s photo storage》的阅读笔记。该论文旨在解决社交网络中海量小文件且请求具有长尾特性的服务能力问题。
简单来说，传统文件系统会给每个文件建立 metadata，比如 inode 这种数据结构，在访问文件的时候，需要先从磁盘找到 inode，然后从 inode 里面查到文件真正的位置，再去拿文件，于是 metadata lookup 就成了瓶颈。而 haystack 所做的就是尽可能减少磁盘访问。
当然，那文件的那次磁盘 IO 是跑不掉的，那有没有可能省掉 metadata lookup 这一此磁盘 IO 呢？有点难，因为要处理海量的小文件，他们的 metadata 也是非常非常大的，内存肯定放不下。所以思路就到了怎么压缩 metadata，以使其能够放入内存中去。
具体是怎么做的呢？卖个关子，去我的知乎专栏看吧~ https://zhuanlan.zhihu.com/p/99388774</description></item><item><title>LSM Tree vs B-Tree</title><link>https://chenminhua.github.io/posts/2019_lsm_tree_vs_btree/</link><pubDate>Tue, 24 Dec 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_lsm_tree_vs_btree/</guid><description>本文为《数据密集型应用系统设计》第三章第一节的读后感
数据需要持久化，将内存中的状态落到磁盘上，就需要使用存储引擎。最简单的存储引擎就是一个数据文件呗，每次写入就写到文件上，而读操作就去数据文件上找数据。但是数据量大了，把所有文件找一遍就不靠谱了，需要加索引。我们就先从最简单的索引，hashmap 说起。
从 hashmap 说起 hashmap 就是一种特别简单的索引，其具有非常好的读写性能，但是有一个缺点，需要全部加载到内存中。虽然我们也可以将 hashmap 序列化后落盘，但是其实现查询功能还是必须整个加载。在数据量比较大的情况下，这显然是个大问题。
Riak 中的默认存储引擎 Bitcask 就是采用的 hashmap 作为索引。Bitcask 将数据加载到文件中，并在内存中维护 hashmap，记录每个 key 对于的 value 在文件中的偏移。这样每次查找的时候，只需要按照 Key 找到数据所在的文件和偏移，就能找到数据了。这种方式其实非常常见，文件系统很多都是这么干的。
当然这只是一个粗略的解释，实际的实现远比这复杂。
比如，都写到一个文件里，那如果这个文件坏了怎么办，如果并发很高怎么办？所以，应该拆成多个段文件。
比如，如果要更新数据怎么办？是直接回到原来的地方去更新么？那就失去了顺序写的巨大性能优势了。更好的方式是先一股脑追加写，不但可以顺序写，这对崩溃恢复也更友好（因为可能更新一半的时候挂掉）。
但是追加写不是很浪费空间么？这就需要做事后合并了。（合并的时候显然还是要更新索引的，并且合并也导致了一定的「写放大」，写放大就是一次数据库写导致了多次的磁盘写）
如果要删除数据怎么办？其实和更新类似，应该先写在原来的数据上打一个墓碑标志（删除标志），然后在合并数据文件的时候，将其跳过。
LSM-Tree (SSTable) 如果我们要解决 hashmap 索引必须加载到内存中的问题，我们需要找到一种基于磁盘的索引机制。
首先我们来看 SSTable (sorted string table)，其要求文件上的数据的 key 要有序，并且在合并文件中，相同的键只能有一条记录。有序性带来一个很大的好处，我们只需要很少量的索引，就可以快速确定某个文件里面有没有待查找的键的对应的值，以及如果有的话在什么区间了。
但是写入磁盘这种事情，要做到在一个文件上有序是很困难的，因为写入会以任意顺序发生。所以顺序还是要在内存中维护。一种常见的做法是，写入时现在内存中维护一个有序结构（比如红黑树）。当红黑树比较大了以后，将其写入磁盘。
很明显，这种做法存在一个问题，就是如果在写入磁盘前崩溃，内存里的数据就丢了。解决这个问题的方法通常是增加一个 WAL 文件，即先将记录写到磁盘上（这里是顺序写），在机器从崩溃中恢复的时候用于恢复数据。
LevelDB 和 RocksDB 正是使用了这种算法，类似的还有 Cassandra 和 HBase。
由于最初这个算法被称为 (Log-Structured Merge Tree)，后来这种基于合并和压缩排序文件的存储引擎就被称为 LSM 存储引擎。
我们可以想象一下 LSM 的最坏场景，查找一个不存在的键，这几乎就是灾难，因为几乎要遍历所有的数据文件（或者说数据的索引文件）。一个解决方案是用布隆过滤器来判断数据是否存在。布隆过滤器的特点是，如果存在则不会误判，如果不存在则可能误判，即存在假阳性错误，这不会导致数据读取错误，只会在假阳性发生时带来性能上的损失，还好，假阳性不常发生。
BTree 事实上，BTree 才是数据库所有的真正王者，几乎是关系数据库索引的标准实现。
LSM Tree 是日志结构的，它将磁盘看成可变大小的块，每个块为几兆或更大，并始终按照顺序入段。
而 BTree 则将磁盘看成固定大小的页，页是读写的最小单元。可以说，这种设计更接近硬件。一个页面指向其他的一些页面，并形成一个高扇出（出度高）的树状结构。</description></item><item><title>隐马尔科夫链与维特比算法</title><link>https://chenminhua.github.io/posts/2019_%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E4%B8%8E%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95/</link><pubDate>Sat, 21 Sep 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E4%B8%8E%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95/</guid><description>马尔科夫链 明天的天气怎么样？明天的股市怎么样？用户下一个输入的单词会是什么？这些问题都是一个随机过程的问题（就是「随机过程随机过」的那个随机过程）。
对随机过程的研究要比随机变量复杂得多，在任何一个时刻 t，对应的状态 st 都是随机的，而我们要研究不同时刻的状态之间的相关性就变得非常复杂。比如今天的最高气温可能和之前几天的最高气温都是相关的，这让模型的建立变得复杂。马尔科夫为了简化问题，提出了一种假设，即
随机过程中每个状态的概率分布只和其前一个状态有关。
注意，我们不能否认前天的天气和今天天气的相关性。马尔科夫链并不是直接否认前一时刻的状态与后一时刻状态之间的相关性，而是说明了在当前时刻状态已知的前提下，下一时刻的状态只与当前时刻有关，而和之前的时刻无关。
隐马尔科夫模型(HMM) 马尔科夫模型极大得简化了随机过程的研究，但是在现实问题中，我们常常无法直接获得随机过程中各个时刻的状态。比如语音识别，当你听到“li hai”，可能是在说「厉害」，也可能是在说「里海」。听到的“li hai”是观测到的现象，而背后的信息才是我们要研究的随机过程的状态。这就是隐马尔科夫模型
任意时刻 t 的状态 st 是不可见的，观测者不能直接观察状态序列来推测状态转移模型的参数。但是隐马尔科夫模型在每个时刻都会输出 ot,而且 ot 仅和 st 相关（独立输出假设）。
状态转移矩阵 与 发射矩阵 如果 HMM 模型的状态是离散的，而观察状态也是离散的，我们就可以得到两个关键的矩阵。一个是状态转移矩阵，其表示模型在不同状态间跳转的概率。比如状态为「不感冒」和「感冒」，则[[0.7, 0.3], [0.4, 0.6]]表示
如果昨天不感冒，则今天 70%不感冒，30%感冒 如果昨天感冒了，则今天 40%不感冒，60%感冒 另一个矩阵叫做发射矩阵，其表示在不同的状态下产生不同观测值的概率，比如
如果不感冒，则有 50%的概率表现正常，有 40%概率觉得冷，有 10%的概率感觉头晕 如果感冒了，则有 10%的概率表现正常，有 30%概率觉得冷，有 60%概率觉得头晕 除此之外，我们还有一些先验知识。比如人有 60%的概率处于健康状态，有 40%的概率处于感冒状态。
请问，假设我第一天感觉正常，第二天感觉有点冷，第三天感觉有点 dizzy，我这三天最可能的状态分别是什么呢？
维特比算法 这个问题可以被建模为图遍历的问题。也就是从第一天开始一直到今天，状态流转的路径中可能性最大的路径。而没过一层的可能性都有「状态数的平方」那么多，所以整个图求解也是复杂度非常高的。
而维特比算法就是解决这个问题的一种动态规划算法。其核心思想在于
到达今天各个状态的最大概率，是由到达昨天的各个状态的最大概率，与今天的观测情况决定的。
比如今天感觉有点冷吧，如果昨天身体好的很，那么今天很可能并没有感冒，但是如果昨天就感冒了，那今天感冒的概率就很大。
那么在感觉冷的情况下今天感冒的概率是多少呢？
我们要知道昨天感冒的概率，昨天感冒且今天感冒的转移概率 我们要知道昨天没感冒的概率，昨天没感冒且今天感冒的转移概率 我们要知道感冒导致感觉冷的概率 P(今天感冒) = 常数 * max(P(昨天感冒)*P(今天感冒|昨天感冒)*P(觉得冷|感冒), P(昨天没感冒)*P(今天感冒|昨天没感冒)\*P(觉得冷|感冒)) 同样我们也可以算出今天没有感冒的概率。通过动态规划，我们可以算出整个随机过程的 path 下最可能的状态转移路径。
(小知识：维特比算法的发明人安德鲁维特比在 1985 年创立了高通公司。)</description></item><item><title>P99与蓄水池算法(reservoir sampling)</title><link>https://chenminhua.github.io/posts/2019_p99%E4%B8%8E%E8%93%84%E6%B0%B4%E6%B1%A0%E7%AE%97%E6%B3%95/</link><pubDate>Wed, 04 Sep 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_p99%E4%B8%8E%E8%93%84%E6%B0%B4%E6%B1%A0%E7%AE%97%E6%B3%95/</guid><description>一个监控问题 假设你是一个运维工作人员，维护着一个访问量巨大的服务，然后有一天，老板跑来问你这个服务的 p99 响应时间是多少？（p99 响应时间：系统 99%的请求都快于这个时间，而 1%的请求则慢于这个时间。即响应时间的 99% 分位点。）
一个简单的算法是直接对所有请求的访问时间进行排序，然后取出 99%位置的请求的访问时间。但是由于系统访问量巨大，每天都有上亿的请求，而一般的排序算法的时间复杂度为 O(n * log(n))，在这样的数据量级上，算法的空间复杂度也很高。怎么优化这个算法呢？
抽样 上亿的数据实在太多了，但是假设我们的系统是相对稳定的，则所有数据应该是同分布的，那我们应该可以通过随机采样的方式，选出一部分样本来，用这些样本来描述总体。比如说我知道今天会有一亿个请求，然后我就可以按千分之一来进行数据抽样，即每个数据都按照千分之一的概率抽取到样本集中。
这里就遇到另一个关键性的问题，我不知道今天会有多少请求，即我不知道总体有多大，更讨厌的是，总体在不断变大，那样本集也会不断变大，排序会越来越困难。
这时候，你应该打开 John Bentley 所著的《编程珠玑》，翻到第十二章，那里有这个问题的答案。
答案就是蓄水池算法，具体可参考《编程珠玑》或 wiki。https://en.wikipedia.org/wiki/Reservoir_sampling , 算法如下。
for (long i = 0; i &amp;lt; LOOP_NUM; i++) { if (i &amp;lt; SAMPLE_NUM) { samples.push_back(n(e)); } else { long r = randint(0, i); float ne = n(e); if (r &amp;lt; SAMPLE_NUM) { samples[r] = ne; } } } 注意，这个 samples 数组是动态更新的，每个新样本进来都会被随机选择是否替换进来。
排序 回到上面的 p99 问题，我们可以设定程序每隔一段时间对样本数组进行排序，并选择 99%位置的数字。时间复杂度就是 O(m * log(m))，空间复杂度为 O(m)，其中 m 为样本集大小。</description></item><item><title>Cuda实战入门2: 将矩阵乘法速度提升 5000 倍</title><link>https://chenminhua.github.io/posts/2019_cuda%E5%85%A5%E9%97%A82/</link><pubDate>Sat, 24 Aug 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_cuda%E5%85%A5%E9%97%A82/</guid><description>本实验采用不同的方法来计算 8192 * 8192 的整型矩阵乘法运算。
C 语言版 C 语言是大家公认的高性能语言，那我们就从 C 语言开始吧。
// 用一位数组表示二维矩阵 mat1 = (int*) malloc(m_size * m_size * sizeof(int)); mat2 = (int*) malloc(m_size * m_size * sizeof(int)); result = (int*) malloc(m_size * m_size * sizeof(int)); // initialize for (int i = 0; i &amp;lt; m_size * m_size; i++) { mat1[i] = rand()/1000000; mat2[i] = rand()/1000000; result[i] = 0; } for (int r = 0; r &amp;lt; m_size; r++) { for (int c = 0; c &amp;lt; m_size; c++) { for (int n = 0; n &amp;lt; m_size; n++) { result[r*m_size + c] += mat1[r*m_size+n] * mat2[n*m_size+c]; } } } 这代码没什么可说的，值得一提的可能就是用一维数组来存二维矩阵，这样可以让矩阵在内存中的分布更连续。很容易估算出来这段代码需要进行万亿级别的乘法或加法运算，倘若使用 1950 年冯.</description></item><item><title>Cuda实战入门</title><link>https://chenminhua.github.io/posts/2019_cuda%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/</link><pubDate>Fri, 23 Aug 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_cuda%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/</guid><description>CUDA (compute unified device architecture) 是 NVIDIA 所推出的一种并行计算平台和并行计算 api。
CUDA 在并行计算上可以大显神威，因此，我们先要找到一个可并行的问题。一个很简单的可并行问题就是计算无穷级数(infinite series)。圆周率 pi 可以通过一个著名的无穷级数(leibniz formula)进行计算，具体可查看 wiki。我们可以用此公式来逼近圆周率，c 代码如下。
c 实现莱布尼兹级数版 pi #define LOOP_N 8192000000 double pi() { double pi_qv = 1.0; int flag = -1; for (long i = 1; i &amp;lt; LOOP_N; i++) { pi_qv += flag * (1./(2 * i + 1)); flag = -flag; } return pi_qv * 4; } 下面我们编译并运行此程序，并用 time 来测量程序运行时间，在我的机器上差不多需要 8s 吧。
gcc pi_number.c -O3 -opi time .</description></item><item><title>为什么拒绝掉前37%的追求者是错的</title><link>https://chenminhua.github.io/posts/2019_%E7%99%BE%E5%88%86%E4%B9%8B%E4%B8%89%E5%8D%81%E4%B8%83/</link><pubDate>Sun, 14 Jul 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E7%99%BE%E5%88%86%E4%B9%8B%E4%B8%89%E5%8D%81%E4%B8%83/</guid><description>Problem Formulation 假设你一辈子可以遇到 100 个潜在配偶，在遇到每一个潜在配偶的时候，你只能选择接受或者拒绝。如果你选择接受，则意味着你放弃了后面所有潜在的配偶；而如果你选择拒绝，则不能反悔，只能在后面的潜在配偶中选择，这也意味着如果你不小心拒绝了 the right one，你永远不能再和 TA 在一起了。现在的问题是，选择和第几个潜在追求者在一起是最佳策略？
这个问题的原型是 Secretary problem。而答案则是，一个神奇的数字–37%。数学家证明了，你应该先拒绝掉前 37%的人，然后从这开始，只要遇到一个比这前 37%的人都好的任何一个人，就选 TA。
而有一些文章说，找对象也和找秘书一样，服从这个 37%的魔数。
你可以这么来理解，假设起初你是个懵懵懂懂的男生，你对女孩儿一般都啥样一无所知，也不知道谈恋爱是干什么的，这时候你对女生的信念是无从建立的（我喜欢用信念这个词，其实就是概率分布的意思）。所以你应该干嘛呢？你应该采样，先采集一些样本，对女生建立起一种信念，这样你就知道女生一般都啥样儿，好姑娘大概啥样儿，矫情的姑娘啥样儿等等。
再说一遍，被你拒绝掉的前 37%，其实就是你的样本空间，用于刻画在你身边潜在的女生的概率分布，这帮助你在未来能客观地评价你遇到的每一个妹子。
批判 我可不是来给这种择偶方式来点赞的，而是来批判它的，从数学角度批判它。这种择偶方式存在很多漏洞，而这些漏洞都源自于其基于错误的假设。
首先，你不知道你这辈子会遇到多少潜在对象，所以你不知道哪个是第 37%个。
其次，谁说你不能反悔的，如果你找到了 80%的地方，却发现还是第一个最好，那就找第一个呗。
上面两条都不是最重要的，这种方式最大的错误是它基于一种 「所有人都满足同一个分布」的巨大错误假设。如果你是变化的，你的环境是变化的，那你遇到的潜在对象就不是同分布的，你在高中遇到的女生和你在工作中遇到的女生就不是同分布的。
你带着不同的目的会遇到不同分布的潜在对象；你在不同的年龄和状态会遇到不同分布的潜在对象；你通过不同的途径也会遇到不同分布的潜在对象。
所以比拒掉前 37% 更有用的，是找到那个更好的分布，而不是只盯着样本。这反映了人们对待统计的一个巨大的认识误区：大家往往认为是样本形成了分布，其实是分布 generate 了样本。分布才是根本，而样本只是偶然的表象。
其实，这篇文章才不是在讲怎么找对象呢。</description></item><item><title>机器学习视角下的软件工程过拟合问题</title><link>https://chenminhua.github.io/posts/2019_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98/</link><pubDate>Sun, 23 Jun 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98/</guid><description>软件工程中充斥着过拟合，它不但刻画了我们在构建系统时常常掉入的思维陷阱，也刻画了我们日常生活中思考与行动的方方面面。
什么是过拟合 在机器学习中，当训练集的数据量比较少，而模型又较为复杂的时候，模型可能会出现在训练集上 fit 的非常好，但是当遇到训练集外的数据时就完全懵逼的情况，这就被称为过拟合(over fitting)。在机器学习领域，过拟合是一个非常关键的问题，甚至可以说是 No.1 的核心问题。过拟合的本质其实是训练数据量与模型复杂度之间的矛盾，由于训练数据集的大小不足以满足模型复杂度的需求，导致模型在训练集和测试集上的表现之间存在较大的差距，训练误差中的方差(variance)太高。
我喜欢将过拟合的模型比喻成一个没见过世面的年轻人，看见什么都想往自己曾经见过的、被训练和教育过的东西上套，嘴里总是在说着：”A 不就是 B 吗？”。而可能它看到的仅仅是世界的一个点、一个边、一个局部而已，当现实世界的其他测试数据向它扑来时，它就崩溃了。
软件工程中的过拟合 在软件设计的初期，我们往往并不知道完整的市场以及完整的需求，因此对软件的架构设计很可能也是有问题的。当你看着手里的这些需求分析时，你很容易开始确信自己要做的”不就是那个什么什么嘛”。这时候，过拟合很容易发生。你开始想：”我们现在有 a,b,c,d,e,f 这几种用户，看起来他们大概有这十几种需求，所以我们只要做一个软件把这十几个需求都满足了，那应该就可以满足我们所有的用户了”。在系统构建的初期，这种方式往往看起来挺美好的，你确实成功满足了当前的所有用户的所有需求。
可以过了一段时间，又来了 100 个用户，他们又提出了 300 个需求，其中有 100 个可以用现有的软件设计来满足，100 个可以通过一些扩展来搞定，而剩下的 100 个可能完全与你当初的设计背道而驰。更糟糕的是，机器学习算法可以把所有数据拿来重新训练一遍，但你的软件一旦交付了，可就不能说变就变了。在用户较少且需求分析不够完整的时候，简单地去满足所有用户的所有需求，over fitting 几乎必然发生，而这往往是致命的。
如何减轻过拟合 正则化 在机器学习算法中，正则化起到了很好的减轻过拟合的作用。事实上，我们可以将正则化看成是奥卡姆剃刀原则在机器学习中的应用。奥卡姆剃刀原理(Occam’s Razor)又称”简单有效原理”，其揭示了一个非常重要的理念：”如无必要，勿增实体”。奥卡姆剃刀原理在很多学科中都有着非常重要的应用，是一个非常底层的逻辑。而正则化其实就是利用数学方式人为的引入惩罚，惩罚过于复杂的模型，在维持模型在训练集上准确性的前提下降低模型的复杂度。当然，正则化也是有一些代价的，可能会提高一些训练误差。所以从另一个角度看可以认为正则化是训练误差换测试误差。
我们同样可以用奥卡姆剃刀原理指导我们的生活实践以及软件工程的构建，在生活中或者软件工程中应用”正则化”。无论是近年来生活方式领域流行的极简主义，或是在软件工程中保持系统的简单与可扩展性，这些都是奥卡姆剃刀原理的良好实践。
更多的数据 另一种对抗过拟合的方式是增加数据，正如前文所述，过拟合本质上揭示了训练数据量与模型复杂度之间的矛盾。理论上来说，如果你能够得到足够的的数据，就能训练出很好的模型。换一种说法，数据量决定了对模型复杂度的容忍度，数据越多，我们就越能构建一个复杂的模型。
在产品设计与软件构建中，更多的数据其实就是说，你收集的需求越多越准确，你就越能构建一个复杂而准确的系统。由此可见，大量的需求分析是多么的必不可少。那么，到底多少才算够呢？在读读上面那段话你就明白了，多少才算够取决于你要构建一个多么复杂的系统，或者说需求分析的完整性决定了对软件系统复杂度的容忍度，需求分析越完整，我们就越能构建一个复杂的系统。
预训练 有些时候，数据并不那么容易获得。幸好我们还有一种对抗过拟合的方式–预训练。预训练就是找到一个已经在某个巨大的数据集上训练过的模型，然后基于这个模型扩展出一个新的模型来。由于那个在其他大型数据集上训练好的模型已经学到了大量的相关知识，这些信息都可以为新模型所利用，因此这个新的模型就可以”站在巨人的肩膀上”。
在软件工程中，对行业已有产品或是相似产品进行准确分析定位，研究其他产品的架构设计以及方法论进行深入研究，也能够帮助我们对抗过拟合风险。</description></item><item><title>自我觉知的能力与做事的态度</title><link>https://chenminhua.github.io/posts/2019_%E8%87%AA%E6%88%91%E8%A7%89%E7%9F%A5%E7%9A%84%E8%83%BD%E5%8A%9B%E4%B8%8E%E5%81%9A%E4%BA%8B%E7%9A%84%E6%80%81%E5%BA%A6/</link><pubDate>Sun, 23 Jun 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E8%87%AA%E6%88%91%E8%A7%89%E7%9F%A5%E7%9A%84%E8%83%BD%E5%8A%9B%E4%B8%8E%E5%81%9A%E4%BA%8B%E7%9A%84%E6%80%81%E5%BA%A6/</guid><description>最近对自己的行为模式进行了一些观察，发现自己很容易在遇到硬骨头的时候出现拖延症的现象。比如在进入某一主题的学习时，发现该主题内容非常丰富，且需要大量背景知识，于是当场演奏起了一段退堂鼓，或者浅尝辄止地看了些基本知识，成为一名“知道分子”。
我并不认为成为“知道分子”本身是有问题的，也不能说遇到困难打退堂鼓这个行为一定是错的。世上的事往往没有绝对的对错，而脱离上下文的评判本身才往往是错的。但是，这种遇到困难时候的个人行为模式却十分值得自我观察，以分析自己在不同情况下会有怎样的表现，为什么会有这样的表现，以及如何行动可能有更好的效果。
关于做事的态度 首先，如果有个人告诉你做事的态度应该认真负责，或者应该保守谨慎，或者其他怎么怎么样。这些建议都是不负责任的，至少是不具体的。因为首先我们要细化这个问题，即“我们在做什么事？”在面对不同的事情时，我们需要付出的努力程度显然是不一样的。那我们到底应该如何面对不同的事情呢？
有一种事情我认为你应该一次做到完美，这种事情可以称作”关闭赛道的工作”。简单解释一下，就是这个工作你做完之后，这件事情就被完美的解决了，以后遇到这个问题，你都不需要再解决一遍，甚至你的朋友，或者其他任何人遇到这个问题，他们都不需要再从头解决一遍，只需要参考你的工作就行了。比如我在上一篇关于我组装一台 PC 的文章中，就引用了 Tim Dettmers 的关于如何选择深度学习 GPU 的文章，事实上，当我在调研这个问题的时候，我查到的大量关于此问题的讨论中，很多人都引用了他的这篇文章，以至于我认为，所有在对这个问题进行的讨论中，如果没有提到这篇文章，那么这次讨论的背景信息就是不完整的。
还有一类事情则是”永续型工作”，这类工作没有终点，也就是赛道永远不会关闭。比如跑步，健身，学习，科研。在面对这类事情的时候，我们需要更多的耐心，而不是一时的冲动和激情。如果在每一次跑步时，都追求完美，可能反而会消磨你的意志，让你无法坚持下去。</description></item><item><title>Got a PC</title><link>https://chenminhua.github.io/posts/2019_got_a_pc/</link><pubDate>Tue, 18 Jun 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_got_a_pc/</guid><description>从 15 年初购入人生第一台 mbp 之后，再也没有使用过 PC 了。最近趁着 618 组了一台电脑，平时的主力机器是 mbp，然后家里放了台 mac mini，但是最近为了在家里跑一些深度学习的模型，而 mac 的显卡实在是让人一言难尽。另外，由于苹果最近和英伟达开始了”战争”，而英伟达又是搞深度学习绕不过去的，万般无奈，只好自行装了台机器。
可以说，我是为了张显卡装了台机器。。。开始的预算是 8000 块，最后大概超出预算 30 块样子吧。下面简单记录一下装机组件列表与一些注意点。
组件 CPU+主板 cpu 和主板一定要配套买，最好不要分开买。另外 cpu 和主板要先选好，要注意看主板的接口。我买的是 i7 8700 + Z370 套装。其中 i7 8700 cpu 是 6 核，3.2G 主频，12 线程。3370 主板支持 4 个 DDR4 插槽，3 个显卡槽。
注意，i7 8700 可以使用自带的 cpu 风扇，如果买其他型号的 cpu 可能需要升级一下 cpu 风扇。
机箱 机箱不能太小，第一是装机的时候方便，第二是考虑以后的可扩展性。除此之外，机箱是否静音也比较重要。我买的是先马黑洞，中塔机箱，内置 3 个风扇。
电源 一定要 600W 以上的。电源大小要看好，确保能放入机箱内，如果机箱比较大的话，一般都没什么问题。我买的是 silverstone 的 ET650-G,额定功率 650W。
显卡 毕竟是为了显卡才装的机器，显卡是关键。参考 Tim Dettmers 的这篇文章，如果没有时间的话可以看他最后写的 TL,DR。如果还没有时间并且有 3200 块预算的话，先买个 RTX2070 吧。我买的是索泰 RTX2070，8G 显存，2304 个 CUDA 核心。京东价格在 3200 到 3400 间吧。</description></item><item><title>当我们谈论杜兰特，我们其实是在谈自己</title><link>https://chenminhua.github.io/posts/2019_%E5%BD%93%E6%88%91%E4%BB%AC%E8%B0%88%E8%AE%BA%E6%9D%9C%E5%85%B0%E7%89%B9/</link><pubDate>Thu, 13 Jun 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E5%BD%93%E6%88%91%E4%BB%AC%E8%B0%88%E8%AE%BA%E6%9D%9C%E5%85%B0%E7%89%B9/</guid><description>人们谈论问题容易陷入对意义的讨论，这种试图对本质的窥探虽然“有用”，却也十分危险。
早上看到杜兰特跟腱受伤的新闻，各大媒体纷纷表示，杜兰特在总决赛第五场不应该复出，并指责勇士队在第五场让杜兰特上场的决定（从结果上看，这确实是一个错误的决定）。比较突出的表述是：“都已经 1 比 3 了，为了拿个冠军，冒着职业生涯报废的危险上场，有啥意义？杜兰特被道德绑架，杜兰特被勇士队利用了，勇士对不起杜兰特…”。
事实上，我们在说的并不是杜兰特和勇士，而是在说我们自己。我们在表达的是：“如果我是杜兰特，我才不会冒着这种风险复出。如果我是杜兰特，我现在肯定恨死勇士了。”事实上，我们谁又不是杜兰特呢？我们从小受到的个人英雄主义教育与集体主义教育都将可能驱使我们做出和杜兰特一样的决定。比如在关键项目 deadline 到来的时候，冒着猝死的风险加班写代码，杜兰特为的是勇士能够赢下总冠军以及自己的个人荣誉，而你为的是团队项目的成功以及老板的赏识以及年终奖。
除了利益的驱使外，更大的推动力来自于“不做的惩罚”。如果杜兰特决定第五场不上场，勇士可能就会直接输掉总决赛，而他也就成了那个坐在板凳上看队友被按在地上的男人；勇士也可能会绝地反击赢得冠军，而杜兰特就成了那个可有可无的人。这样的惩罚实在太大了，比不加班就没有年终奖大多了。 我又想起了姚明和王治郅。姚明在 nba 打球的时候，几乎每年夏天都要带伤为国家队打比赛，或许这是姚明职业生涯短暂的原因之一。而王治郅则曾经因为不愿打国家队的比赛而被开除，并受到国内舆论媒体的指责。那时候的我们是怎么说的呢？我们说：“姚明是好样的，男人就应该这样。王治郅是个叛徒”。但现在，如果易建联说自己有伤夏天不能打国家队的比赛，指责的声音应该不会太多了吧。
这里面似乎存在一种从集体主义到个人主义的转变。在这一过程中，个人利益与价值得到了更多的尊重，可人却活的越来越虚无。如果冒着职业生涯报废的危险上场比赛没有意义，那冒着生病乃至猝死的危险加班又有什么意义？结婚或者生二胎又有什么意义？孝顺父母又有什么意义？甚至于一些个人行为比如健身读书写作思考都又有什么意义？这种看似是对人生意义的思考，轻而易举地将我们带入了虚无主义。更糟糕的是，这种思考在对个人行为进行批判的同时，并没有告诉我们应该怎么做。
杜兰特复出的决定看起来是错的，但是从结果反推行为没有多大意义，人生不过就是：做出选择，承担后果。我为杜兰特的决定骄傲，也希望他能早日康复。</description></item><item><title>语言的雅俗</title><link>https://chenminhua.github.io/posts/2019_%E8%AF%AD%E8%A8%80%E7%9A%84%E9%9B%85%E4%BF%97/</link><pubDate>Tue, 04 Jun 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E8%AF%AD%E8%A8%80%E7%9A%84%E9%9B%85%E4%BF%97/</guid><description>昨天看到 slack 里面有个网友说：”这是我下午看《洞察》的时候突然冒出来一个问题：钱有许多称呼，比如阿堵物、孔方兄等，可是既然它们指的都是相同的东西，为什么又有雅俗的分别？钱可能还好，现在应该没有太多人会觉得追求钱是羞耻的，更好的例子比如生殖器、月经等。”
这个问题我认为或许和场合有关。
从自然语言处理视角来看，这里的“场合”可以建模为一个词在作为 center word 时，其周围的 context word 的概率分布的区别。比如具有相同指向物的两个描述生殖器的词汇，其中一个的 context word 多为医学词汇，而另一个则可能多为侮辱性词汇。相应的，这两个词在统计意义上更接近于不同的主题模型，因而给人雅和俗的不同感受。</description></item><item><title>什么是概率</title><link>https://chenminhua.github.io/posts/2019_%E4%BB%80%E4%B9%88%E6%98%AF%E6%A6%82%E7%8E%87/</link><pubDate>Sun, 12 May 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E4%BB%80%E4%B9%88%E6%98%AF%E6%A6%82%E7%8E%87/</guid><description>假设我们现在要扔一枚硬币，我问你这枚硬币正面朝上的概率是多少？你一定知道是 0.5。但是让我们来仔细想想，概率为 0.5 到底意味着什么呢？一种常见的解释是，如果我们扔足够多次的硬币，会有大概一半的情况为硬币正面朝上。
可是，如果这是一枚只能扔一次的硬币呢？事实上这个世界上充满了只能扔一次的硬币。每年的欧冠决赛只能踢一场，那么这时候我们又如何来理解”利物浦有 55%的几率会夺得欧冠冠军”这句话呢？你总不能让热刺和利物浦在一百万个平行宇宙里面踢上一百万场欧冠决赛，然后发现利物浦赢了其中的 550000 场吧。
那当我们说”利物浦有 55%的几率夺得欧冠冠军”的时候，我们到底在说什么？
回到扔硬币的问题上来，若我们用宿命论的观点来看这枚硬币，那么它在被抛出前，如何落地应当就已经决定了，在宇宙大爆炸的那一刻就被决定了。每一个电子的运动，都只是沿着它宿命的轨迹罢了。但是在这枚硬币落地之前，我们依然不知道它会如何落地，正面朝上和反面朝上的概率都是 0.5。现在，我偷偷告诉你一些事情，我告诉你这枚硬币其实不是一枚正常的硬币，它被特殊处理过，使得它的正面更容易朝上（比如说扔 100 次有 70 次都是正面朝上）。现在，在硬币落地之前，你就知道硬币有 70% 的概率正面朝上了。
这还不够，我现在想告诉你更多的东西，我想告诉你扔出硬币的时候硬币的受力分析，以及当时的重力加速度，硬币距离地面的高度，硬币的重量和质心，硬币形状，硬币弹性，地面的弹性。这时候你可以对这个”扔硬币系统”进行力学模拟了。当然，由于你对地面摩擦系数，空气阻力，大气压强等信息并不确定，所以你需要在这些参数上引入一些随机性，有了前面加入的这些先验知识后，经过一系列经典力学的计算，你对于硬币正面朝上这件事开始变得更有信心了（也可能更没有信心）。
更进一步，我现在把地面摩擦系数，空气阻力，大气压强等统统告诉你，我把所有可能影响硬币落地状态的所有知识都告诉你，现在，在硬币落地前，你就已经可以算出硬币是正面朝上落地还是反面朝上落地了，正面朝上的概率变成了 1（或者 0）。对于你而言，这件事已经不再是一个随机事件了（但是对于其他人来说，他们不知道这一切，所以在他们看来，正面朝上的概率依旧是 0.5）。
原来，概率可以是一件这么主观的事情，它并不仅仅用于描述一个事件本身的某些特质，它还和人对于事件的观察有关，它关乎于一种信念，关乎于你对事件既有的认识。庞加莱说：概率只是对我们无知程度的度量。
总结一下，上面的两种观点分别称为频率学派和贝叶斯学派。频率学派认为概率反映的是系统的一些特质，由系统的本质决定的；而贝叶斯学派则认为概率关乎于信念。
事实上，我认为这两种观点并不相互矛盾，有时候，他们只是在阐述不同的问题而已。现在我们再回来看看”利物浦有 55%的几率夺的欧冠”这句话，频率学派可能会觉得 55% 是由事件本质属性决定的，是伟大的自然法则控制的一个数字。但在我看来，我并不认同这种看法，我认为 55% 并非系统本质的完全描述，而只是某个人或者某些人的观点罢了（即使他们认为他们的观点来自于对自然法则的精确分析，这也只代表他们的观点）。事实上，不同的人对于这场比赛可能会有完全不同的预测，比如热刺主教练，利物浦球员，博彩公司的高级分析师，普通的英超球迷，压根不看球的人…每个人对于谁会夺冠都会有着完全不同的观点。</description></item><item><title>生活中的弹力系统设计</title><link>https://chenminhua.github.io/posts/2019_%E7%94%9F%E6%B4%BB%E4%B8%AD%E7%9A%84%E5%BC%B9%E5%8A%9B%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link><pubDate>Sat, 11 May 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E7%94%9F%E6%B4%BB%E4%B8%AD%E7%9A%84%E5%BC%B9%E5%8A%9B%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</guid><description>艺术来源于生活，系统架构也是如此。
基于微服务的分布式系统架构所面临的挑战非常巨大，充满了各种不确定性。为了能够提高 SLA，我们需要让系统能够更有弹性，在系统部分出现故障的情况下，尽可能地减少损失。常见的弹性系统设计模式有：降级，限流，重试，补偿，异步，幂等，隔离，熔断等等。本文将结合生活中的一些例子来介绍这些模式是什么，以及什么时候应当考虑使用这些模式。
降级模式 所谓降级模式就是，当服务出现资源瓶颈，吞吐量跟不上的时候（注意是吞吐量），为了让系统能够正常运行，并承受常规情况下吞吐上限，牺牲掉一些相对次要的功能，保住关键业务的一种设计模式。比如在电商秒杀活动中，如果系统流量过大吞吐跟不上，就可以考虑牺牲掉一些 feature，比如用户评价啊，商品具体的详情啊等等，都不进行展示（都已经是秒杀了，谁还看那些东西）。
在生活中，当高速公路收费站排队太长的时候，路网系统会手动切换到免费放行模式。在节假日这种明显会产生大流量的情况下，系统还会自动切换到免费放行模式。其实这就是一种降级设计，通过牺牲收费这个相对次要的功能，保住了车辆通行顺畅这一关键业务。
限流模式 限流设计对关键业务的保护尤其重要，比如说用户中心就是一个关键业务，是一个不能挂的服务，而如果说现在有个程序员写了一个 bug，在某种 corner case 下会导致某个服务不断地去用户中心拉取大量数据，这种时候就很容易导致用户中心的请求队列里面堆积太多请求，原本正常的请求反而会被 delay，甚至得不到正确响应。
另一种常见的使用限流模式的场景出现在 open api 的设计中，由于你的 api 不再是内部系统调用的，而是暴露给第三方，你根本不知道别人会怎么用你的 api 啊，这时候限流就成为你必须要考虑的事情。
还是举一个生活中道路交通的例子，每次放假结束回上海的时候，都会遇到交警在高速公路崇明路段提前收窄道路的情况，人为降低道路通行能力。这在某种程度上就是为了缓解上海长江隧道的拥堵情况，让大家不要都堵在一个点，而是选择绕行，或者在服务区休息休息，或者看到道路拥堵就改个时间出行。。
重试模式 重试模式与 CAP 有关。分布式事务也是系统设计中的大坑，而在微服务的语境下，这个大坑往往很难避免。如果你知道 CAP 理论，你应该明白我们总是要在 C 和 A 之间做出一些牺牲。对于那些对一致性要求极高的系统（比如银行转账），有时候我们只能选择牺牲一定的可用性，但是对于更多的系统来说，往往我们可以考虑争取更高的可用性，而牺牲掉一些强一致性。重试模式就是牺牲强一致性而追求更高可用性的一种设计模式。
假设某个事务需要改变 A，B 两个系统的状态，但是当 A 的状态成功发生改变后，B 系统却迟迟不能响应，或者 B 系统干脆挂掉了。这时候如果对强一致性没有那么高的要求，你可以选择稍微等待片刻后，重新对系统 B 发起请求（B 系统的对应接口应当是幂等的）。如果你运气不错，可能重试个一两次，B 系统就活过来了，事务也就能成功完成了。
这很像我们在网上买东西，快递员给你送过来，结果你说你今天出差不在家，让他明天再来。于是快递员明天又来了一回，你拿到了你买的东西，交易事务也就成功了。
补偿模式 补偿模式则是处理牺牲强一致性而追求更高可用性的另一种设计模式，通常会和重试模式配合使用。还在上面的例子，A 系统状态更新成功了，但是在请求 B 系统的时候，B 系统却报了个错，表示这个交易无法完成（对方账户没了啊，商品库存不够了啊，商品已经下架了啊）。这时候无论你怎么进行重试，事务都不可能完成了。那怎么办呢？你需要去补偿 A 系统。你要告诉 A 系统：”有内鬼，交易终止”，然后让 A 系统补偿之前的状态更新操作（账号上把钱加回来啊啥的）。
当然，你一定会想到，如果补偿也失败了呢？而且是那种业务上完全无法完成的补偿，这时候咋办？理论上来说，我觉得这个问题是无解的。比如 A 让你把钱交给 B，但是在你给到 B 之前 B 被人杀了，你想把钱还给 A，结果发现 A 也被杀了，那么这件把 A 的钱转交给 B 的事务就用于没法被”做完”，或者被”没做”。对于这种问题，我们只能说减小它发生的概率（比如设计一些两阶段提交之类的东西，当然这显然增加了系统的复杂度，而我们讨厌复杂度），并且设计好兜底方案。如果说你的业务真的无法接受这件事情的发生的话，恐怕你只能让 A 自己直接把钱交给 B 了（不要拆分这两个系统）。</description></item><item><title>信息化与自动化</title><link>https://chenminhua.github.io/posts/2019_%E4%BF%A1%E6%81%AF%E5%8C%96%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96/</link><pubDate>Sun, 10 Mar 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E4%BF%A1%E6%81%AF%E5%8C%96%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96/</guid><description>这些年来，”工业 4.0”，”2025 计划”等新名词越来越多的出现在人们的视野，工业互联网概念得到了各国政府部门以及产业界的重点关注。尽管对于什么是”工业 4.0”依旧还没有一个固定的标准，但是在这条向未来探索的路上，人们渐渐摸出了一些方向。未来的工业，可能会呈现出这样一番景象：所有的生产资源（人，机，料）都通过网络被连接起来并相互感知，并通过智能系统的控制完成生产决策，生产过程中的所有信息都将可被追溯，而这将全面改变现有的生产管理与供应链管理。未来或许已经并不遥远，而在未来到来之前，工业界更多地在做的是这两件事：信息化和自动化。
信息化和自动化都并非新鲜事，可以说从第一次工业革命开始，工业就已经走上了信息化与工业化的道路。200 年前，人们就已经开始用蒸汽机取代人类完成一些生产工作。我曾经参观过青岛啤酒的产线，一个巨大的车间里面，只有数十个工作人员，从一袋袋小麦到一箱箱啤酒，工作人员只需要在现场“监督”那些巨大的机器工作，并进行一些质检工作，而在现场的屏幕上，实时地刷新着生产的具体情况：正在进行哪个工单的生产，进度如何等等。
当然，在现有的工业体系中，能够很好地做到信息化和自动化的企业并不多，提前上车的企业往往能够率先得到信息化与自动化带来的红利，而要真正提高整个行业的效率，则必须在全行业推行先进的生产技术与管理模式。
信息化往往更偏向与管理上的升级，而自动化更偏向于技术上的升级。事实上，不止是工业界，很多领域往往都可以一分为二的从管理和技术两个方面上分析。
举个例子，为什么 google cloud 落到了 aws 和 azure 的后面？google 拥有世界上最好的搜索引擎，也就意味着它有着最好的流量，而云服务又是面向互联网企业的服务，google 完全可以凭借其搜索引擎巨大的流量优势来吸引互联网企业，但是它却掉到了亚马逊和微软的后面，到底是啥原因呢？原因就在于 google 骨子里就是一家技术上成功的公司，他们擅长的打法就是做出一个世界上最牛逼的产品，然后你们自己来用。而云服务某种程度上是服务业，你需要更好地去服务你的客户，帮助你的客户获得成功，而这种模式不是仅仅有技术就能做到的，更需要先进的管理来支撑。
对于工业界来说，技术上的成功与管理上的成功都非常重要，信息化与自动化也需要齐头并进。
小结 随着硬件计算能力的增强，网络基础设施的普及，人工智能与大数据分析技术的发展，信息化和自动化还将向前大跨一步。信息化与自动化也将更加的融为一体。从供应链管理，生产资料管理，生产过程管理等环节，都将被准确地记录并实时地反馈出来，而这些关键的信息也将对生产的自动化产生有价值的指导。另一方面，自动化带来的大量数据也将被信息化记录，并可从中分析出更多精细的数据。</description></item><item><title>关于麻将能不能进入奥运会的讨论</title><link>https://chenminhua.github.io/posts/2019_%E5%85%B3%E4%BA%8E%E9%BA%BB%E5%B0%86%E8%83%BD%E4%B8%8D%E8%83%BD%E8%BF%9B%E5%85%A5%E5%A5%A5%E8%BF%90%E4%BC%9A%E7%9A%84%E8%AE%A8%E8%AE%BA/</link><pubDate>Sun, 10 Mar 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E5%85%B3%E4%BA%8E%E9%BA%BB%E5%B0%86%E8%83%BD%E4%B8%8D%E8%83%BD%E8%BF%9B%E5%85%A5%E5%A5%A5%E8%BF%90%E4%BC%9A%E7%9A%84%E8%AE%A8%E8%AE%BA/</guid><description>这篇文章来源于一群软件工程师在晚餐时的讨论，论题是中国麻将能不能进入奥运会。这类问题在不同的群体间相信已经发生过无数次，这次当然也毫无例外的并没有得出任何有价值的结论。但这并不妨碍这是一个有意思的问题，并值得花一些时间思考。
先说说我的观点吧，我个人并不看好麻将进入奥运会。在我看来，麻将是一个比较容易出现弱胜强情况的游戏（相信大家对这一点都有所体会，一个第一次玩麻将的人居然连续赢了好几把钱）。
说到这，我们遇到了一个比较关键的问题，如何定义强和弱？
如何量化一个麻将手的实力？很容易想到大数定理。根据大数定理我们知道，只要实验次数趋近无穷，实验结果的均值就会趋近于事物的本质。也就是说，如果麻将高手和麻将菜鸟打上无数圈麻将，赢的多的那个就更强。在不考虑打麻将风格相克之类的因素的假设下，我们甚至可以设立一个基准麻将手，并用一个选手和基准麻将手玩的成绩来量化一个麻将手的能力。
问题是，大数定理只有在实验次数非常非常多的情况下才奏效，但是在奥运会上，我们甚至不可能打一百圈麻将。而至于打多少圈以上我们才能相信战绩体现了实力，这又是另一个有趣而值得思考的问题了。
当然，我的观点也遭到了一些反驳。理由是：竞技体育中也充满了运气因素，即使 nba 总决赛也不过只是打七场而已（事实上这取决于你如何看待这个问题中的事件，究竟比赛是一场一场打的，还是一个回合一个回合打的，这又是一个有趣且非常复杂的问题）。
在我看来，这种观点存在一些缺陷，或者说这种类比并不准确。麻将正在的问题在于，在所有玩家 take action 前（摸完牌，但是打出第一张牌前），在玩家实力未知的情况下，每个玩家获胜的条件概率(given 发牌情况与后面码好的牌的情况)是不均匀的，并且可能是严重不均匀。简单点说，就是有的玩家一手好牌，有的则一手烂牌。竞技体育则不同，在球队实力未知的情况下，在开球前两支球队获胜的概率几乎是相同的。
对于麻将这类游戏，我有另外一种类比。假设我们对奥运会男子 400 米赛的规则进行一些修改，增加一些人为的趣味性（不确定性），在发令枪响前，由一个随机系统给每个运动员分配一个 1 到 8 的数字（不重复，记为 i），每个选手需要跑完 400 + 0.1i 米的距离，或许对于博尔特之类的选手，即使抽到 8 也有机会夺冠。而如果我们修改一下规则，每个运动员要在比赛中跑完 400 + 10i 的距离，也就是说抽到 1 的要跑 410 米，而抽到 8 的要跑 480 米。这时候场外因素显然开始对比赛产生影响了，抽到 1 的选手即使实力最差，也极有可能第一个完成比赛获得冠军。如果我们再修改一下规则，每个运动员要在比赛中完成 400 + 1000*i 的距离，那这场比赛几乎就成了一场抽签比赛，因为只有有选手抽到了 1，他几乎就稳赢了，这个时候每个选手的胜率几乎是一样的。当然，我们依然可以说这是一场公平的比赛，但是这不是一个好的竞技项目。
扔硬币也是公平的比赛。假设现在奥运会加入了一场扔硬币比赛，我们几乎可以说，在玩家开始扔之前，玩家们的获胜概率必然是均匀的。倘若真的能够练出在非常高的扔均匀硬币次数下让硬币正面朝上的次数明显高于反面朝上次数的能力，那么在概率统计的意义上来说，扔硬币就是一种比麻将更适合于竞技的游戏。
事实上，我们只需要再修改一下规则，这个田径比赛就会更接近麻将游戏。假设每次发令枪响前，每个选手会抽中一个实数 i,然后他需要跑 400 + i 的距离，其中 i 服从正态分布。这个模型还存在一点点缺陷，因为麻将摸牌不是独立事件，所以在把 i 变成一个向量，服从高维正态分布。多么简洁而漂亮的模型！
稍微总结一下，什么样的游戏适合竞技呢？我觉得需要满足两点。第一，在玩家能力未知的情况下，玩家获胜的概率是近似于均匀分布的。第二，在玩家能力已知的情况下，玩家获胜的概率应当偏离均匀分布（学过信息论的同学应该一下就能想到信息增益的概念吧）。通俗点说就是：外部影响因素要少，选手能力影响要大（至少要有影响吧，不然真成抛硬币了）。</description></item><item><title>模型设计的两大准则：NFL与奥卡姆剃刀</title><link>https://chenminhua.github.io/posts/2019_nfl%E4%B8%8E%E5%A5%A5%E5%8D%A1%E5%A7%86%E5%89%83%E5%88%80/</link><pubDate>Sat, 09 Mar 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_nfl%E4%B8%8E%E5%A5%A5%E5%8D%A1%E5%A7%86%E5%89%83%E5%88%80/</guid><description>NFL(无免费午餐)定理 模型的合理性很大程度上取决于待解决问题本身的特征。
无免费午餐（No Free Lunch, NFL）定理证明了任何模型在所有问题上的性能都是相同的，其总误差和模型本身是没有关系的。可是既然大家谁都不比谁好，那关于机器学习算法和模型不计其数的研究又有什么意义呢？理解 NFL 的关键在于“所有问题”的表述。
从模型的角度来看，如果单独拿出一个特定的模型来观察的话，这个模型必然会在解决某些问题时误差较小，而在解决另一些问题时误差较大。从问题的角度来看，如果单独拿出一个特定的问题来观察的话，必然有某些模型在解决这些问题时具有较高的精度，而另一些模型的精度就没那么理想了。
NFL 定理最重要的指导意义在于先验知识的使用，也就是具体问题具体分析。说白了就是：没有最好的模型，只有最合适的模型
奥卡姆剃刀原则 如果有多种模型都能够同等程度地符合同一个问题的观测结果，那就应该选择其中使用假设最少的，也就是最简单的模型。一个问题存在多个可接受的模型，其中的每一个都可以演化出无数个更为复杂的变体，其原因在于可以把任何解释中的错误归结于某种特例的出现，将这个特例纳入模型就可以避免原来错误的发生。更多特例的引入无疑会降低模型的通用性和可解释性，把薄薄的教材变成厚重的词典，这就是奥卡姆剃刀偏爱简单模型的原因。
过于简单的模型就像做快餐，按照一定的参数标准统一的做几个菜，可能老板和服务员自己都觉得一般般，广大消费者吃起来自然也不会觉得多好吃。就像欠拟合的模型在训练集上都没有良好的表现，别提泛化了。相比之下，过于复杂的模型则是私人定制餐点，你爱吃酸的我就放酸的，可是真的拿到市场上卖，爱吃酸的人并不多，这就像过拟合的模型能够在训练集上表现优异，却不具备良好的泛化性能。
过拟合也好，欠拟合也罢，都是想避免却又无法避免的问题。用较为简单的模型来模拟复杂的数据生成机制，欠拟合的发生其实是不可避免的。可欠拟合本身还不是更糟糕的，更糟糕的是模型虽然没有找到真正的相关性，却自己脑补出一组关系，并把自己的错误的想象当做真实情况加以推广和应用，得到和事实大相径庭的结果——其实就是过拟合。
模型的复杂度也可以从误差组成的角度一窥端倪。模型的误差包括三个部分：偏差（bias），方差（variance）和噪声（noise）。噪声是不可约误差（irreducible error），并不能通过模型的训练加以改善。除了噪声之外，偏差和方差都与模型本身有关，两者对误差的影响可以用误差的偏差 - 方差分解（bias-variance decomposition）来表示。偏差的含义是模型预测值的期望和真实结果之间的区别，如果偏差为 0，模型给出的估计的就是无偏估计。但这个概念是统计意义上的概念，它并不意味着每个预测值都与真实值吻合。方差的含义则是模型预测值的方差，也就是预测值本身的波动程度，方差越小意味着模型越有效。抛开噪声不论，模型的误差就等于偏差的平方与方差之和。
偏差和方差之间的折中与模型自身的特性息息相关。偏差来源于模型中的错误假设，偏差过高就意味着模型所代表的特征和分类结果之间的关系是错误的，对应着欠拟合现象；方差则来源于模型对训练数据波动的过度敏感，方差过高意味着模型对数据中的随机噪声也进行了建模，将本不属于特征 - 分类关系中的随机特性也纳入到模型之中，对应着过拟合现象。
根据上面的理解，就不难得到结论：理想的模型应该是低偏差低方差的双低模型，就像一个神箭手每次都能将箭射进代表 10 环的红心之内；应该避免的模型则是高偏差高方差的双高模型，这样的箭手能射得箭靶上到处窟窿，却没有一个哪怕落在最外层的圆圈里。更加实际的情形是偏差和方差既不会同时较低，也不会同时较高，而是在跷跷板的两端此起彼伏，一个升高另一个就降低。
一般说来，模型的复杂度越低，其偏差也就越高；模型的复杂度越高，其方差也就越高。比较简单的模型像是个斜眼的箭手，射出的箭都在远离靶心的 7 环的某一点附近；比较复杂的模型则是个心理不稳定的箭手，本来是 9 环水平却一下射出 10 环一下射出 8 环。对模型复杂度的调整就是在偏差 - 方差的折中中找到最优解，使得两者之和所表示的总误差达到最小值。这样的模型既能提取出特征和分类结果之间的关系，又不至于放大噪声和干扰的影响。</description></item><item><title>身高背后的统计学</title><link>https://chenminhua.github.io/posts/2019_%E8%BA%AB%E9%AB%98%E8%83%8C%E5%90%8E%E7%9A%84%E7%BB%9F%E8%AE%A1%E5%AD%A6/</link><pubDate>Fri, 08 Mar 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E8%BA%AB%E9%AB%98%E8%83%8C%E5%90%8E%E7%9A%84%E7%BB%9F%E8%AE%A1%E5%AD%A6/</guid><description>给同年龄的一百个小孩量身高，已经量了 99 个，请问最后一个小孩的身高有 99%的概率会小于多少。
我们只知道这些数据来自同一个总体（服从同一个分布），前 99 个小孩和最后一个是一视同仁的，也就是说，这一百个小孩每个都有 1%的可能是最高的。所以最后那个小孩的身高有 99%的概率小于前面 99 个小孩中最高的那个。
而一些同学可能会有不同的观点，通常来说同龄小孩身高会服从正态分布。通过分析前 99 个小孩的身高我们是可以算出这个正态分布的参数的。假设均值为 100，方差为 4，则可以很容易算出最后一个小孩以 99%的概率低于 100 + 2 * 2.365 = 104.73 厘米。
参数模型与非参数模型 （parametric/non-parametric model） 上面两种方法中，第一种是非参数模型，它并不关心这些数据属于什么分布。第二种则是参数模型，其依赖于一个很强的先验假设：身高服从正态分布。换句话说，如果模型有一组固定的参数来描述其概率分布，则为参数模型；否则为非参数模型。
参数模型的优点是只有几个少量的参数就刻画了整个模型，每个参数都有其明确的统计意义（比如上面的均值和方差），但是它需要依赖于超强的先验假设：所有数据符合特定类型的概率分布。学习的过程就是利用训练数据估计未知参数的过程，这些估计出来的参数就是训练数据的浓缩。在这个过程中，先验知识确定了假设空间的取值范围，学习算法（比如最大似然估计或是最大后验概率估计）则在给定的范围内求解最优化问题。
可如果先验分布本身就不符合实际（换句话说你的假设空间错了），学习算法再强，数据再好也得不出正确结果。所以当对所要学习的问题知之甚少的时候，应当避免对潜在模型做出过多的假设。这类不使用先验信息，完全依赖数据进行学习得到的模型就是非参数模型。
非参数模型不是“无参数模型”，恰恰相反，非参数模型意味着模型参数的数目是不固定的，并且极有可能是无穷大，这决定了非参数模型不可能像参数模型那样用固定且有限数目的参数来完全刻画。在非参数模型中不存在关于数据潜在模式和结构化特性的任何假设，数据的所有统计特性都来源于数据本身，一切都是“所见即所得”。当训练数据趋于无穷多时，非参数模型可以逼近任意复杂的真实模型，而代价是非常大的时空复杂度。
归根结底，非参数模型其实可以理解为一种局部模型，就像战国时代每个诸侯国都有自己的国君一样，每个局部都有支配特性的参数。在局部上，相似的输入会得到相似的输出，而全局的分布就是所有局部分布的叠加。相比之下，参数模型具有全局的特性，所有数据都满足统一的全局分布，这就像履至尊而制六合得到的扁平化结构，一组全局分布的参数支配着所有的数据。
数据模型(data model)与算法模型(algorithm model) 从数据分布的角度看，不同的模型可以划分为参数模型和非参数模型两类。如果将这个划分标准套用到模型构造上的话，得到的结果就是数据模型（data model）和算法模型（algorithm model）。相比于参数对数据分布的刻画，这种分类方式更加侧重于模型对数据的拟合能力和预测能力。
http://www2.math.uu.se/~thulin/mm/breiman.pdf 统计模型，两种不同的文化。
作为一个统计学家，布雷曼看重的是学习算法从数据中获取有用结论和展示数据规律的能力。从这一点出发，他将从输入 xx 到输出 yy 的关系看成黑盒，数据模型认为这个黑盒里装着一组未知的参数，学习的对象是这组参数；算法模型则认为这个黑盒里装着一个未知的映射 f()˙f()˙，学习的对象也是这个映射。
数据模型和参数模型类似，其最典型的方法就是线性回归。线性回归的含义明确而清晰：输入数据每个单位的变化对输出都会产生同步的影响，影响的程度取决于这个特征的权重系数，不同特征对结果的贡献一目了然。
算法模型和非参数模型类似，其著名代表就是随机森林算法。随机森林是一种集成学习方法，构成这座森林的每一颗树都是决策树，每一棵决策树都用随机选取数据和待选特征构造出来，再按照少数服从多数的原则从所有决策树的结果中得到最终输出。
如果说参数模型与非参数模型的核心区别在于数据分布特征的整体性与局部性，那么数据模型和算法模型之间的矛盾就是模型的可解释性与精确性的矛盾。数据模型有更好的可解释性，而算法模型则相对而言抛弃了可解释性（对于特别复杂的问题，追求可解释性几乎是不可能的，追求精确性更重要）。
决策树本身是具有较好可解释性的数据模型，它表示的是几何意义上对特征空间的划分，但是精确度却不甚理想。随机森林解决了这个问题：通过综合使用建立在同一个数据集上的不同决策树达到出人意料的良好效果，在很多问题上都将精确度提升了数倍。但精确度的提升换来的是可解释性的下降。每个决策树对特征空间的单独划分共同织成一张剪不断理还乱的巨网，想要理解这张巨网背后的语义无异于水中望月、雾里看花。
生成模型与判别模型 还有另一种针对学习对象的划分方式，那就是生成模型和判别模型之分。简单地说，生成模型学习的对象是输入 xx 和输出 yy 的联合分布 p(x,y)p(x,y)，判别模型学习的则是已知输入 xx 的条件下，输出 yy 的条件分布 p(y|x)p(y|x)。两个分布可以通过贝叶斯定理建立联系。
生成模型和判别模型的区别可以这样来理解：假如我被分配了一个任务，要判断一个陌生人说的是什么语言。如果用生成模型来解决的话，我就需要把这个老外可能说的所有语言都学会，再根据他的话来判定语言的种类。但可能等我学完这些语言时，这个陌生人都说不出话了。可是用判别模型就简单多了，我只需要掌握不同语言的区别就足够了。即使不会西班牙语或者德语的任何一个单词，单凭语感也可以区分出这两种语言，这就是判别模型的优势。
针对生成模型和判别模型的利弊，支持向量机的奠基者弗拉基米尔·瓦普尼克（Vladimir Vapnik）有句名言：“（解决分类问题）应该直截了当，不要用兜圈子的方式，搞一个更难的问题（比如求解似然概率）做为中间步骤”。一般来说，生成模型的求解更加复杂，当数据量趋于无穷大时，渐进条件下的精确性也更差，但其收敛的速度更快，在较少数据的训练后就可以收敛到错误的下界。相比之下，判别模型的形式更加简单，在分类问题上的表现也更出色，却不能提供关于数据生成机制的信息。有些情况下，生成模型和判别模型会成对出现。例如在分类问题中，朴素贝叶斯和逻辑回归就是一对生成 - 判别分类器。</description></item><item><title>一场赌局背后的统计学</title><link>https://chenminhua.github.io/posts/2019_%E4%B8%80%E5%9C%BA%E8%B5%8C%E5%B1%80%E8%83%8C%E5%90%8E%E7%9A%84%E7%BB%9F%E8%AE%A1%E5%AD%A6/</link><pubDate>Thu, 07 Mar 2019 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2019_%E4%B8%80%E5%9C%BA%E8%B5%8C%E5%B1%80%E8%83%8C%E5%90%8E%E7%9A%84%E7%BB%9F%E8%AE%A1%E5%AD%A6/</guid><description>A 和 B 两人进行一场赌局，方式是抛一枚特制的硬币。如果硬币正面朝上，则 A 得一分，反之 B 得一分，先得六分的获胜。假设现在 A 以 5：3 领先，请问最终 B 获胜的概率要多高。
概率学派 频率学派认定待估计的参数是固定不变的常量，这里也就是硬币正面朝上的概率，用 p 来表示。频率学派认为，A 之所以 5：3 领先，是因为 5：3 这种情况出现的概率高，所以 p 应该是能够让 5：3 出现的概率最高的值。而求这个值的方法通常是最大似然法。此处似然函数为 L=p^5(1-p)^3,令一阶导=0 得出 p=5/8。而 B 获胜的概率就是 B 连胜三局，也就是答案是 27 / 512。
对于频率学派来说，估计值本质上是利用数据构造出来的函数，既然数据是随机分布的，估计值肯定也是随机的。参数是确定的，数据是随机的，利用随机的数据推断确定的参数，得到的结果也是随机的。
贝叶斯学派 贝叶斯学派的核心是贝叶斯定理，用于计算后验概率。P(H|D)=P(D|H)⋅P(H) / P(D)。式中的 P(H) 被称为先验概率（prior probability）；P(D|H) 被称为似然概率（likelihood probability）；P(H|D) 被称为后验概率（posterior probability）。
在贝叶斯学派看来，5：3 的结果不能证明硬币正面朝上的概率更高，只能证明硬币正面朝上的概率更高的概率更高（仔细体会这句话），可能只是这次 B 运气不太好。因此，处理参数 p 的方式应该从变量的角度去观察，考虑所有可能的取值，再计算在所有可能的取值下 B 获胜概率的数学期望，从而消除 p 的不确定性对结果的影响。
换句话说，我们应当考虑 p 在不同的取值情况下的概率（请再次理解为什么 5:3 只能证明硬币正面朝上的概率更高的概率更高）分布，并以此来对不同 p 值情况加权。在这样的思想下，B 获胜的概率就可以写成 E=∫(1−p)^3 P(p|A=5,B=3)dp 利用贝叶斯定理可以求得结果为 0.</description></item><item><title>市场营销方法论</title><link>https://chenminhua.github.io/posts/2018_%E5%B8%82%E5%9C%BA%E8%90%A5%E9%94%80%E6%96%B9%E6%B3%95%E8%AE%BA/</link><pubDate>Thu, 20 Dec 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E5%B8%82%E5%9C%BA%E8%90%A5%E9%94%80%E6%96%B9%E6%B3%95%E8%AE%BA/</guid><description>最近在看美剧《广告狂人》，于是对广告业产生了一些兴趣，进而去了解了一下市场营销的方法论。Marketing 集成了商业的全部功能，并通过广告，销售以及其他市场活动直接和客户打交道。Marketing 是艺术与科学的混合，其中的知识非常广博。
市场营销过程是一个循环过程，一个市场计划的各个步骤和方面需要相互配合支持来达到目的。在市场计划中，做对一件事情是容易的，但是制定一个内部统一且相互支持的市场计划并不容易。整个市场营销过程主要包括以下几步。
1.客户分析 2.市场分析 3.竞争对手分析 4.分发渠道分析 5.制定营销组合 6.评估营销效益 7.重复1-6步并不断修正和扩展 客户分析 客户分析是市场营销的第一步。你必须先弄明白你的营销工作的对象是谁，以便对他们展开你的工作。
理清需求 需求类别是什么？谁需要？为什么需要？比如说电子烟产品吧。使用电子烟的人可能是为了戒烟，也可能是一名电子烟烟雾玩家。可能只是希望让自己看起来更酷一点。
理清购买者和用户 who is the buyer？ who is the user？ buyer 和 user 很可能不是同一个人，比如男士袜子的购买者常常是女性,所以在运动台推广袜子往往没什么用。
理清购买过程 购买过程可不是指用户是支付宝付款还是微信付款，而是指用户从产生需求想法到最终完成购买之后的整个过程。不同品类的产品，用户会有完全不同的购买过程。
比如你需要买一组旅行套装（小包装的牙刷牙膏肥皂等），你家门口正好有一个名创优品或者无印良品，你下班路过的时候直接走进店里，随手拿了一套就结账了。如果使用感受不错，你以后还会反复购买同样的产品。
比如你想买一个电动牙刷，可能是因为电视剧中的女主角使用电动牙刷的镜头吸引了你。然后你就去淘宝上搜了一下然后直接下单，或者看了两篇评测文章后做出决定。老实说，电动牙刷看起来都差不多，随便选一个品牌的价格较低的产品对你来说不会构成心理负担。大概一个小时内，你自己都没有意识到你已经下单了。
比如你想买一辆车，首先是你觉得你需要一辆车，而不是因为你路过了一个 4s 店。然后，你可能会咨询一些懂车的朋友，或者去知乎上看看高分的评论，或者去微博上随便搜搜看。终于你锁定了三到五款不同的车，他们各有利弊。A 车的油耗最低，但是外形不好看；B 车最有设计感，但是不太保值；C 车你很满意，但是稍稍有点超出你的预算了；D 车最近在促销感觉很划算，但是这个品牌的口碑不是太好。经过了反复地信息搜集和内心斗争。最终你决定买下其中的某一款。然后在开了两个月后，你开始慢慢评估自己的购买决定，比如我真的太蠢了，或者我真的太明智了。
总体来说，购买过程往往包括：先感知需求，再信息搜索，再评估替代产品，最后完成购买。其实还有一步，就是评估自己的购买决定。了解购买过程的一个主要方法是进行客户调查。
理清参与度 你需要弄明白，你卖的是一个高参与度的产品还是低参与度的产品？参与度可以用客户在购买过程中付出的精力和思考来衡量。通常来说，参与度和购买产品的风险有关。
如果客户在购买商品时感到较高的风险，那这就是一个高参与度的产品，比如买房子肯定是一个非常高参与度的事情。而买纸巾或者矿泉水则往往比较随机，用户对品牌甚至价格都是无感的。
提高用户参与度也对产品推广很有帮助。可以通过一些有参与度的广告（比如百事，耐克这些产品的广告）。可以给产品加入一些重要特性（killer feature）。
划分市场 在理清了上面的这些问题之后，你就可以划分市场了。 你可以选择按照地理位置划分，在北方投放羽绒服和取暖器广告的效果肯定比海南强的多。 你可以选择按照人口组成划分，比如划分婴儿、学生、中年人、老年人奶粉市场。
市场分析 市场分析步骤从更广的角度分析市场规模，发展趋势，竞争环境，行业监管环境。分析的目的是为了判断是否有必要投入精力在这个市场进行营销活动。市场分析需要弄明白三个问题：相关市场，生命周期，竞争因素。
相关市场 比如你打算向市场推出一种新的牛排产品，请注意，牛排市场不是你的相关市场。（下面的数据都是我乱讲的）假设全球牛排市场年销售总额是 1000 亿，其中中国市场占 10%，也就是 100 亿，而你的牛排产品打算在超市和电商售卖（零售），这部分市场核算下来大约有 50 亿，而且你的牛排产品属于 100 元以上一块的高价位牛排，这个细分市场算下来可能只剩 5 亿美元了。这才是你的相关市场。
生命周期（PLC） PLC 主要分为引入期，成长期，成熟期，衰退期。
引入期的时候大家还不太明白产品是什么，比如两年前的区块链。
成长期的时候大家都在问哪儿能买到，比如智能马桶盖这种东西。
成熟期的时候大家问为什么要买它，比如电动牙刷或者手机之类的产品。</description></item><item><title>聊聊微信读书</title><link>https://chenminhua.github.io/posts/2018_%E8%81%8A%E8%81%8A%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/</link><pubDate>Sun, 28 Oct 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E8%81%8A%E8%81%8A%E5%BE%AE%E4%BF%A1%E8%AF%BB%E4%B9%A6/</guid><description>这两天下了几个读书应用，发现市面上类似产品还真不少，比如微信读书，京东阅读，豆瓣阅读等等。我也深度体验了一下微信读书，这里谈谈个人的感受吧。
社交与用户 很多人都说微信读书试图用社交来撬动阅读，目前看来在这一点上，微信还是非常非常克制的，目前微信并没有大量采用群、朋友圈、小程序之类的流量武器给微信读书导流，但是却机智的使用了微信的通讯录，也就是说让用户在微信读书中看到他的朋友在看什么书（而不是微信中）。
微信读书也在试图突出用户在读书活动中的地位，并且带动一部分 ugc 内容与书本内容的整合。这是一件有点想象空间的事情，我们可以类比于音乐行业与网易云音乐，网易云虽然在版权上面输给了腾讯，但是其精心维护的社区和评论确实是同类产品中独一无二的，这也成为了他们的核心竞争优势。微信读书也有机会创造这样的一块 ugc 价值出来，并通过社交放大。
市场 读书的市场和音乐的市场能比吗？不好回答。但从感觉上看，音乐市场是完胜的。It’s not even close.
腾讯音乐在经历一系列整合之后，目前的估值已经达到了 300 亿美元，这简直就是一个天文数字，已经超过了当前网易的市值，离京东也不远了。那书这个行业呢？目前来看，阅文可能是目前最大的头部玩家，市值达到 430 亿港币，虽然和腾讯音乐还有一定的差距，但也是一个超出我想象的数字。
那么腾讯处在什么位置呢？等等，你仔细看下，阅文集团背后站着的，就是腾讯。腾讯对阅文的持股比重超过了 60%。腾讯音乐在整合音乐版权的时候，面对的上游通常是大型唱片公司；而网络书籍这一块呢，除了部分的出版商外，还有数不清的网络文学作家。我认为对腾讯来说，这简直是一场稳赢的战争，因为腾讯有阅文，他可以轻松的吃下这部分双边市场。但是需要注意一点，阅文的财报并不好看，相比于其市值，它的利润确实不怎么好看，市盈率破百，有很大的被高估风险。
目前阅文更多切入的是网络文学的市场，而读书市场绝对不仅仅这么简单。我觉得在线读书还有一块很大的可以切的市场是在线教育，比如像现在得到做的精读产品等等，这些产品的边际成本几乎为零，谁的流量成本低，谁就赚的多。那么，谁的流量成本能比微信低呢？
微信读书会改变什么？ 在微信读书上，你有两种不同的消费方式。你可以选择买一本书，钱货两讫，你付了钱，得到在这个平台上阅读这本电子书的权利。你也可以选择买一份微信读书的订阅(所谓的 netflix 模式)，此时你并没有得到任何书，但是你得到了在一定时间内在这个平台上阅读的权利。
这种订阅模式并不是什么新鲜玩意儿，相信大家各个平台的会员也都没少买。但是这种订阅模式从一定程度上，确实改变了供求关系。一个最简单的问题就是，平台如何给内容生产者付费？
平台可以选择买断式，也就是我一次性交付一大笔钱给你，购买你的作品的播放权阅读权，甚至我再多付一点钱，要求独家权利。这样一来，平台的定价权可能就会非常大。还有一种就是平台按照打开次数或者阅读时长等数据来计算费用，这种方式的话，作品价格就会和平台 kpi 直接绑定，谁给平台 kpi 贡献大，谁就多分钱。
无论如何，如果这种订阅模式成为书的主要渠道的话，都可能会对创作者的创作方式，创作质量产生巨大的影响。</description></item><item><title>敏捷开发</title><link>https://chenminhua.github.io/posts/2018_%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/</link><pubDate>Wed, 12 Sep 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/</guid><description>在 2001 年，十七名软件开发人员在犹他州的雪鸟度假村会面，讨论这些轻量级的开发方法，并由 Jeff Sutherland，Ken Schwaber 和 Alistair Cockburn 发起，一同发布了敏捷软件开发宣言。
敏捷开发宣言 个体和交互 胜过 过程和工具 可以工作的软件 胜过 面面俱到的文档 客户合作 胜过 合同谈判 响应变化 胜过 遵循计划
敏捷开发就是在一个高度协作的环境中，不断地使用反馈进行自我调整和完善。
核心 迭代开发，价值优先。你需要经常性的交付对用户有价值的软件。工作的软件是首要的进度衡量标准，你应该使用短迭代，增量发布，不停交付你的软件，让客户做决定。
分解任务，真实进度。你需要分解你的项目工作，准确把控项目的进度。
站立会议，交流畅通。立会能够让团队之间交流更顺畅，彼此知道对方正在进行什么工作，进展如何，是否遇到一些障碍。最有效的交流方式就是面对面。
用户参与，调整方向。同 1，我们不能闭门造车，而是要和用户一起，让用户的需求反映进来。
结对编程，测试驱动，代码评审，保证质量。代码质量非常重要。
CI/CD。CICD 要尽早搭建起来，持续集成，持续发布，一切都要自动化。
定期回顾，持续改进。定期反省和调整。
不断学习，提高能力。关注优秀的技能和好的设计。 对团队投资，分享你的知识和你获得知识的方法。 定期举行读书会和讲座。 打破砂锅问到底。为什么用于比怎么做重要。
关于会议 会议一定要设立最终期限，防止陷入无休止的辩论。每个会议都要有一个负责人。
每天早上都要有立会。立会要足够简单有效，每个人需要回答三个问题：我昨天干了啥，我今天准备干啥，我遇到了什么阻塞。猪和鸡中，只有猪可以参加立会。
关于技术和代码 防微杜渐，不要只想着骗过测试。
如果你看到别人的一些代码很傻逼，重写掉它。
如果有人误解了需求，那这个误解可能会被传递下去。确保尽快消除这些误解。
指责不能修复 bug，我只关心解决问题。提出你的顾虑，而不是否定你的队友。维护你的队友，就算他犯了错，也不要让他在大家面前难堪。
代码集体所有制，每个人都可以改别人的代码。
要有一致的编码风格和代码规范，api 规范，非常重要。新人要先适应规则，再贡献代码。
架构师必须写代码，不要在 ppt 里面编程。主程应该试着承担架构师的角色。程序员拒绝设计，就是在拒绝思考。
架构师最重要的任务是：通过找到移除软件设计不可逆性的方式，从而去除所谓架构的概念。
记录问题解决日志。就像海盗的航海日记，飞行员的飞行手册一样。daylog 要可以搜索，可以 comment,记录问题（要详细，什么程序什么版本什么平台），debug 过程和解决方案。
关于团队和个人 围绕被激励起来的个体构建项目，给他们支持和信任。允许大家自己想办法。
可持续的开发速度，don’t burn out。
最好的架构，需求和设计出自自组织的团队。
帮助你的队友，让他们愿意来找你。对事不对人。 勇于承认自己不知道答案，这让人更放心。
不要试图说“这不是我的错”，如果你从来不犯错，那你可能也不是很努力。
如果你在的团队非常不职业，赶紧离开。
优秀的工程师并不拘泥于特定的任务，也不受公司信息和计算能力的约束。那些无论你是否批准都按自己想法做事的人，才值得你投资。
你不仅需要对你的团队抱有信任，也必须有足够的自信，才能给员工自由，让他们自己去寻找更好的答案。在物色领导人的时候，要挑选那些不会将一己之利置于企业利益之上的人。</description></item><item><title>需求变更的一致性</title><link>https://chenminhua.github.io/posts/2018_%E9%9C%80%E6%B1%82%E5%8F%98%E6%9B%B4%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/</link><pubDate>Thu, 02 Aug 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E9%9C%80%E6%B1%82%E5%8F%98%E6%9B%B4%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/</guid><description>最近在工作中遇到一次重大需求变更，对业务模型的设计也产生了非常大的影响。基本上就是在地基上挖个洞的那种变更。目前迭代还在进行中，但是我觉得是时候进行一些回顾，来思考这次大型迭代中我们做对和做错了哪些事情了。
产品一致性的重要性 复杂软件通常都会由几个不同模块组成。比如一个做包装功能的产品经理，突然改了一个需求，原本一个包装内只能装一种东西，现在要改成可以装不同的东西。当这个变更发生的时候，另一个可能使用包装的产品经理和相应的程序员都应该被告知，并修改相应的逻辑，并配合其一起上线。可是有时候，做底层功能的这个产品经理和程序员并不足够了解谁在依赖他们，可能就这么稀里糊涂开始写了，写着写着发现这个变更会影响到上层模块。而这时候上层模块正在经历属于它自己的迭代，一切就都搅和在一起了。
这种重新打地基式的迭代是非常糟糕的，你的团队会失去可用的共同语言，失去对产品的一致理解，失去相互间的信任。
所以，在项目建设的前期，做好需求调研和设计规划是最重要的。这能帮我们打好基础，让大家达成一定的共识。并且能够在产品方向出现分歧的时候作为一个指引。
但是，有些时候你很难在早期弄清楚用户到底需要什么，有时候避免不了会出现大的一些需求变更，甚至你会发现自己的模型根本就是错的。这时候你可能会做出一个产品迭代的决定，将现有的模型换掉。而这时候问题就来了。
你决定从底层的服务开始改起来，上层服务依赖着底层服务，所以上层服务也要改。而上层服务同时还有其他需求正在做，一切就都乱了套了。更可怕的是，你的服务已经上线了，这意味着已经有用户在使用你的软件。所以你要考虑 migration，你要考虑兼容性。于是你要在这段时间内需要搞定太多太多的事情了，或许模型本身并不复杂，但是因为这些问题，这样的迭代会非常困难。
这种不必要的复杂往往来源于产品的不一致性。当产品从一个合理的模型演变为另一个合理的模型的过程中，为了避免迭代周期过长，敏捷开发会将其拆分为一个一个细粒度的迭代。绝大多数情况下，敏捷开发都是好的。但是如果拆分不当，敏捷也会很危险。比如你把一个底层模块的变更安排在了一个迭代中，而上层模块先去写一些代码兼容它，code base 中会出现很多临时代码，如果这些代码由一些不熟悉这些业务的程序员来编写，或者由一些责任心不强的程序员来编写，就等于挖了一个坑。在这中情况下，应该尽可能让整个系统的功能保持一致性，宁可将底层模块的变更拆分到不同的迭代，也不要出现上下游服务不一致的情况。这需要团队内部充分的沟通，千万不能形成“安分守己”的团队文化。
程序员的责任到底是什么 程序员最重要的职责就是维护代码。这里的维护有两个含义，一方面是指让你的代码能够稳定正确地运行。更重要的一点在于，程序员应该为自己代码的整洁性和可维护性战斗。产品经理不会知道这个功能有多难做，你必须不停的告诉他，你必须习惯于不停地 challenge 产品经理，让他只做最重要最合理的需求。
一个好的技术团队，必须要相互挑战，产品经理站在用户的立场说话，程序员则必须为自己的代码战斗。如果程序员也站到了用户那边，代码就很可能越写越多越写越烂。很多时候，产品经理跑来跟你说一个需求，你乍一听挺合理，但是实现起来非常的困难，你一定不能直接答应下来。先推，让产品明白这东西很难做。再问产品为什么要这个功能，有没有其他方法满足他。产品经理往往会直接给你一个解决方案，但是优秀的程序员要去找到根上的那个问题。
总之，程序员的工作并不是完成产品经理的需求，而是开发并维护你的代码。这两者，从来都不是一回事。</description></item><item><title>三门问题</title><link>https://chenminhua.github.io/posts/2018_%E4%B8%89%E9%97%A8%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 23 Jul 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E4%B8%89%E9%97%A8%E9%97%AE%E9%A2%98/</guid><description>背景 这是一个非常有名的问题，wiki。
简单说就是，有三扇门，一扇后面有奖，两扇后面有山羊。如果选手猜中有奖的门，就可以拿走奖品。 在选手做出选择之后，主持人（知道哪扇门后面有奖品）会选择选手没选的两扇中的一扇没有奖品的门打开。 这时候选手有一次改变自己选择的机会。
这时候，有人提出，选手改变选择能提高其获奖概率。起初这一观点遭到了强烈抨击。后来无数实验证明，这个观点是对的。 下面我们用 ebay 的一个开源库来证明一下，选手改变选择确实能提高其获奖概率。
实验 from bayesian.bbn import build_bbn def f_prize_door(prize_door): return 0.33333333 def f_guest_door(guest_door): return 0.33333333 def f_monty_door(prize_door, guest_door, monty_door): if prize_door == guest_door: if prize_door == monty_door: return 0 else: return 0.5 else: if prize_door == monty_door: return 0 if guest_door == monty_door: return 0 return 1 g = build_bbn( f_prize_door, f_guest_door, f_monty_door, domains=dict( prize_door = [&amp;#34;A&amp;#34;,&amp;#34;B&amp;#34;,&amp;#34;C&amp;#34;], guest_door = [&amp;#34;A&amp;#34;,&amp;#34;B&amp;#34;,&amp;#34;C&amp;#34;], monty_door = [&amp;#34;A&amp;#34;,&amp;#34;B&amp;#34;,&amp;#34;C&amp;#34;] ) ) 然后我们运行一下,假设选手选了 A 门，而主持人打开了 B 门</description></item><item><title>聊聊面向对象</title><link>https://chenminhua.github.io/posts/2018_%E8%81%8A%E8%81%8A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/</link><pubDate>Sun, 15 Jul 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E8%81%8A%E8%81%8A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/</guid><description>看到这个标题，可能很多朋友都会呵呵一笑。面向对象谁不知道？可是事实上，能正确理解和使用面向对象编程范式的人并不多，在不同语言背景下的程序员也往往对面向对象有不同的理解。我看过很多有一定经验的程序员写的代码，用着所谓面向对象的编程语言，写出来的代码却是根本无法维护的。为什么呢？因为他的代码没有隐藏该隐藏的信息，没有保护变化源。所以，OO 根本不是为了什么更好地模拟现实世界（那是给培训班用的卖点），而是为了隐藏信息，拥抱变化。
谈到 OO，就不得不提其三个基本特征：封装，继承，多态。下面我们就一起来看看这三个特性。
封装 一个比较流行的关于封装的定义是，隐藏对象的属性和实现细节，外部程序只能通过公开的接口来访问内部数据与方法。这种设计方式在硬件设计中是不言自明的，你拿到一个芯片，只需要阅读其说明书，知道每个管脚的作用，而不必知道其内部是如何实现的。在编程领域呢？封装是面向对象独有的吗？如何在不同的编程范式中实现封装呢？
首先，封装是面向对象独有的吗？
c 语言显然不是我们所认为的面向对象编程语言（尽管有一本很经典的编程书籍叫《面向对象 c 语言》）。但是事实上，c 语言有着非常好的封装特性。c 程序员喜欢将一堆方法签名写在一个头文件中，而需要使用这个模块的程序员会 include 这个头文件，事实上他们可能只能看到这个头文件。假设我们要实现一个栈。
struct Stack; typedef struct Stack Stack; Stack *newStack(); void destoryStack(Stack * stack); void * popStack(); void pushStack(void * ele); int sizeOfStack(Stack *stack); 使用这个栈的程序员看到的源代码只有这么多。他不知道你是怎么实现这个栈的。是用了数组还是链表？struct Stack 有哪些域？计算 size 的时候是遍历了所有元素还是在每次变更的时候去统计栈的长度？客户程序员对此一无所知。多么完美的封装啊。
c++可能是大多数程序员入门面向对象编程的语言了吧。在这里我们第一次学到了 public，private 这些个访问控制符。相比于 c 语言，我们开始拥有了类这个概念。c++程序员喜欢把类定义写在头文件里面，而将 c 语言里面的各种函数变成类的成员方法。c++之于 c 的另一个重大改变是泛型编程，但这不是本文讨论的重点。下面我们还是来看看栈这个例子。
template &amp;lt;class T&amp;gt; class Stack { private: std::vector&amp;lt;T&amp;gt; elems; // elements public: void push(T const&amp;amp;); // push element void pop(); // pop element T top() const; // return top element bool empty() const { // return true if empty.</description></item><item><title>feature vs function</title><link>https://chenminhua.github.io/posts/2018_feature_vs_function/</link><pubDate>Thu, 10 May 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_feature_vs_function/</guid><description>最近看到一段关于微服务的视频：拆分单体应用，其中有一段话引起了我的注意：split code by feature not by functionality。
大多数项目在一开始往往都只有一个后端服务。但是随着团队的扩展，业务需求的增加，单服务的可扩展性问题就会开始困扰你。如何拆分服务就成为了一个重要的问题。
关于上面那段话：split code by feature not by functionality。我查了一些资料，自己也做了一些思考，但是还是感觉很模糊。stackexchange 上的这个问题甚至被直接关闭了，理由是这个问题的答案很主观。
在日常的开发中，我们也常常会混用这两个词，加个 feature 和加个功能听起来是一回事，如果不分语境地强行去区分这两者，感觉没什么意义。但是在服务拆分的语境下面，区分这两个词或许是有意义的，甚至是有必要的。
function 更接近于描述我们想要的功能，比如记账的功能，汇率转换的功能，聊天的功能。而 feature 更接近于我们实现功能的方式，比如自动记账，手动记账，扫码记账。function 更为抽象，而 feature 更为具体。function 更稳定，而 feature 更易变。</description></item><item><title>spring aop中遇到的一个小问题</title><link>https://chenminhua.github.io/posts/2018_spring_aop%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E9%97%AE%E9%A2%98/</link><pubDate>Sat, 05 May 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_spring_aop%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E9%97%AE%E9%A2%98/</guid><description>最近做的一个项目使用了 spring+mybatis 的技术栈。实现很简单，在数据访问层写一系列 mapper 接口，定义一系列数据查询的方法。在服务启动时，让 spring 去扫这些接口，并为这些接口生成代理对象，也就是 DAO，这些 DAO 会实现 mapper 接口。同时这些 dao 都被 spring IOC 注入到相应的 service 中。
然后有一天，我们遇到了一个需求，某几个 mapper 中的某几个方法需要做一些特殊判断逻辑，并且需要改掉返回的数据。
一种方案是直接去改使用 mapper 的地方，但是以现有的架构来看，mapper 和 service 之间没有新的分层了，这会导致这个奇葩的需求需要写到 service 中的各个角落。如果有一天你想用删掉这些代码，或者修改这部分逻辑，后果不堪设想。
另一种方案是加切面，这样这部分逻辑就被集中到了代码主流程的外部，灵活度更高。
spring aop 有两种常用的给方法加切面的方式。一种是给方法加 annotation，另一种是用 execute()表达式。
起初我的想法是用 annotation 的方式。原因是这样更显式，在以后改代码的时候能够给自己一个提醒，其他伙伴改代码的时候也能知道这个方法会被拦截。于是我就写了个 annotation 加在 mapper 接口的某个方法签名上，然后去拦截这个 annotation 注解的方法。但是，拦截并没有生效。做了一番调查之后，我发现原来 annotation 不能从 interface 继承过来。参考 stackoverflow。简单来说就是@Inherited 只能在 superclass 上的注解才能起作用，而在接口上不起作用（不会往上追溯到接口）。这种设计的考虑可能是因为 java 单继承多实现的设计，如果去拿接口的 annotaion 可能会导致冲突。另外要注意的一点是，annotation 的继承并不能在运行时通过反射的方式直接在类上看到，而是通过类继承树向上查找的方式实现的。
如果换成使用 execute()表达式的方法，对既有代码的侵入性更低（有好处也有坏处），也确实可以解决问题。因为在拦截对象方法的时候，不用去查 annotation，而是直接找到实现该接口的指定方法去拦截。</description></item><item><title>相关与因果</title><link>https://chenminhua.github.io/posts/2018_%E7%9B%B8%E5%85%B3%E4%B8%8E%E5%9B%A0%E6%9E%9C/</link><pubDate>Wed, 02 May 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E7%9B%B8%E5%85%B3%E4%B8%8E%E5%9B%A0%E6%9E%9C/</guid><description>人类天生善于从噪声中寻找模式，这是一种与生俱来的能力。比如发现直角边的平方和等于斜边的平方，比如发现十二平均律以及五度音，比如发现一年有三百六十五天（公转周期）…
很多时候，人们会发现两件事往往同时出现，或者当一件事情发生时另一件往往不会发生。比如（下面都是我瞎说的）：
爸爸胖很可能儿子也胖。
喜欢跑马拉松的人很可能爱听 hiphop。
下雨天很可能堵车。
熬夜会容易长胖。
吸烟对环境有好处。
等等，最后一条是不是写错了？其实最后一条是我在 twitter 看来的，大概是说：吸烟会杀死人类，而人类对环境有害，所以吸烟有益环境保护。这一条论断看似非常离谱，但确是一条比较明确的因果推断。
而熬夜容易长胖这一条呢？一种解释方法是，熬夜的人比较容易吃零食，所以会容易胖（因果推断）。但是我们也可以说，工作压力大的人容易熬夜，工作压力大的人运动太少所以会长胖。这时候长胖和熬夜就变成了相关，换句话说，就算你现在不熬夜了，如果你工作压力还是很大，你依然会胖。
在统计学中，我们总是反反复复地和这两个概念打交道。甚至在统计学创建之前，我们就已经开始进行大量这方法的脑力活动–预测。
预测，在很多人看来是一种极度不靠谱的行为。我认同这种不靠谱，或者我们给它换一个好听点的名字：不确定性。这种不确定性是如此的确定，如此的科学，如此的贴近事物本质。尽管人们总是试图去对抗这种不确定性，但不可否认，它是不可战胜的。
但这依旧不能阻止人们去预测 &amp;mdash; 以一种更科学的方式。</description></item><item><title>一件让我愤怒的事</title><link>https://chenminhua.github.io/posts/2018_%E4%B8%80%E4%BB%B6%E8%AE%A9%E6%88%91%E6%84%A4%E6%80%92%E7%9A%84%E4%BA%8B/</link><pubDate>Wed, 18 Apr 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E4%B8%80%E4%BB%B6%E8%AE%A9%E6%88%91%E6%84%A4%E6%80%92%E7%9A%84%E4%BA%8B/</guid><description>最近在工作中遇到一些事情，让我有点不爽，或者说是愤怒。我觉得很多程序员根本称不上是 engineer，只能勉强算是个”terrible programmer”。
有些程序员不关心自己的代码，能不能被其他人看懂，会不会被别人错误地理解和使用。有些程序员甚至不关心自己的代码能不能被三天后的自己看懂。有些程序员其实根本不知道自己在写什么？他们只是凭借自己的感觉写完代码，然后扔给测试，然后等待测试提 bug，然后跑去问别人这边的逻辑应该是什么样的，然后用最“简单”的方式修复这个 bug（让这个 bug 不再发生）。
很多人都抱有这样的心态，甚至这种结果导向已经成为了一种政治正确。代码写的好坏不重要，赶紧通过测试，修好手上的 bug 上线才是最重要的。当然我同意修 bug 很重要（绝大多数情况下优先级最高），但是很多时候，大家都只想着怎么关掉这个 bug，而不会想想更重要的一些问题：这是不是一个 bug？这个 bug 是从哪来的？修复这个 bug 的方式会不会影响到其他逻辑?这个 bug 后面是不是还藏着别的坑？
如果你不去思考这些问题，而是快速看一眼 Jira,打开 debug 模式找到问题的原因(比如说，需要在某一段处理逻辑中加一段条件判断，在某种情况下跳过某几行代码的执行)。然后你想，oh，这个 bug 很好修，我只要多写个 if 然后在这种情况下跳过这几行代码就行了。你开心的写完这两行代码，提交并发布到测试环境，然后告诉测试那个 bug 被你修好了。接着去处理你还没处理的那十个新的 bug。
你觉得自己效率很高么？你错了，你糟糕透了，因为你失去了最适合思考和重构代码的时机。你被其他人催着跑，却丢掉了你最重要的东西。产品经理不会关心你的代码，测试不会关心你的代码，架构师不会关心你的代码，他们只要你把事情搞定。但是你必须关心你的代码，如果有必要的话，fight for your code!
如果需求要你写出难以维护的代码，你必须站出来发声，别人不会知道这东西有多坑，你必须非常严肃地告诉他们在技术实现上这是一个多么糟糕的主意。否则，你很可能为了一个优先级很低的需求，毁了你优雅的系统设计。
如果你不关心你的代码，那你永远也写不出好的代码，你的代码也不会成为好的产品。</description></item><item><title>十年</title><link>https://chenminhua.github.io/posts/2018_%E5%8D%81%E5%B9%B4/</link><pubDate>Wed, 11 Apr 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E5%8D%81%E5%B9%B4/</guid><description>github 十年了，这个被戏称为同性交友网站的章鱼猫，度过了十周岁生日。
十年前，我还在读高一，凯尔特人三巨头即将捧起奥布莱恩杯，利物浦在欧冠半决赛输给了切尔西，那时候我还不知道啥是程序员（那时的梦想是当一个 DJ）。当然，那时候也没有 github 和 stackOverflow(同样也创立于 2008 年)，不知道大家都去哪里抄代码。
2008 年的世界，已经遥远得无法想象。但是就像贝索斯说的“相比于未来十年会发生什么变化而言，未来十年什么不会变是一个更重要的问题”。那么 2008-2018，有什么没变呢？
朝鲜依然在搞核试验 java,php,c++依然是最受企业欢迎的编程语言 詹姆斯依然在骑士队（天真）
事实上，我发现想出几个没变的事物居然比想出几个变化的事物难很多。那么未来十年，在软件开发领域什么是不会变的呢？</description></item><item><title>聊聊抽象</title><link>https://chenminhua.github.io/posts/2018_%E8%81%8A%E8%81%8A%E6%8A%BD%E8%B1%A1/</link><pubDate>Sun, 08 Apr 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E8%81%8A%E8%81%8A%E6%8A%BD%E8%B1%A1/</guid><description>不要抽象。
上面这句是和一个架构师聊天时他说了二十遍的话。这句话对大多数程序员来说，都是非常反直觉的。可以说抽象是计算机软件设计中极为重要的一环，是每个程序员每天都要做的事情。当你在设计一个类来表达一组数据的时候，你正在完成一次抽象；当你设计出一个抽象类或者接口，你正在抽象你的抽象。
如果你是一个数学家，你应该会对“不要抽象”这四个字嗤之以鼻。数学家喜欢归纳和抽象，并从中发现数学之美。吴军在《数学之美》中甚至直接给出了一个论断：好的数学模型一定简单。
大量的数学模型都验证了这一点，欧拉公式，傅里叶级数，贝叶斯定理…所有这些公式在经过一系列推导和符号约减后，都成为一个可以被以最大号字体写在 T 恤胸口位置的公式。在我们为这些公式拍案叫绝的时候，我们往往忘记了：
That’s the good part of the world.
bad part 真实世界往往没有那么美好，很多事情未必能通过简单的推导和符号约简来简化。有些时候，我们会努力去识别问题中的一些 pattern，或者意外发现一些事物中的相关性。于是你惊喜地发现，只要变化一下看问题的角度，或者提出一些看起来很正确的假设，原本复杂的问题就会变得非常简单！
但是现实往往没有那么容易讨好，现实中的符号约简往往是一个非常危险的行为。因为你看问题的角度很可能不是最全面的，或者你的假设其实是错的。
很多时候，大脑处理现实复杂性的唯一方法是把庞大复杂的系统简化，这也是计算机编程中非常有用的机制。但是，如果将其视为理所当然，就会陷入符号简缪论。
在软件设计中，让分离的概念保持分离几乎是一条真理。尽管很多时候我们会遇到很多看起来相似的概念，让我们忍不住去合并它们，但是倘若引起它们改变的因素是不同的并且不可知的，那你很可能还是要将它们拆开的（很快）。所以有些时候，费力进行抽象带来的边际效益会很低。
感兴趣的朋友可以看看这个演讲 prefer duplication over the wrong abstraction
我们依然需要抽象 回到文章开头那句话：不要抽象。其实我依旧并不同意这句话。尽管那位前辈说：你还年轻，等你挖的坑够多之后你就明白了。
抽象是危险的，一味追求简单而完美的模型会把我们带入误区。但如果因此放弃抽象，将现实的 bad part 直接带入我们设计的系统中，更是一种投鼠忌器的表现，甚至可以说是偷懒并且不负责任的设计。保持灵活的最好方式是少写代码，而在概念产生明显分化之前，采用相对抽象的概念确实能够帮助你少些很多代码。除此之外，当我们采用“非抽象”方式完成部分系统设计和代码编写的过程中，不断审视自己过去的想法，寻找 pattern，也能帮助我们构建更易于理解和维护代码。
其实抽象也好，不抽象也罢，和其他系统设计的问题一样，我们都可以用一个看起来没什么用但是永远正确的词来回答：balance。你要去平衡开发团队的能力，合作者（需要理解这些概念的人）的数量，对系统边界的影响，开发时长，以及灵活性（能否推翻你当前的选择）等等所有的因素，最终决定抽象的层级。
拥抱抽象，但要适可而止。</description></item><item><title>如何告诉一个外星人什么是树</title><link>https://chenminhua.github.io/posts/2018_%E5%A6%82%E4%BD%95%E5%91%8A%E8%AF%89%E4%B8%80%E4%B8%AA%E5%A4%96%E6%98%9F%E4%BA%BA%E4%BB%80%E4%B9%88%E6%98%AF%E6%A0%91/</link><pubDate>Sat, 07 Apr 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E5%A6%82%E4%BD%95%E5%91%8A%E8%AF%89%E4%B8%80%E4%B8%AA%E5%A4%96%E6%98%9F%E4%BA%BA%E4%BB%80%E4%B9%88%E6%98%AF%E6%A0%91/</guid><description>在《认知开发潜能》一书中，我曾读到这样一段关于树的话，大意是：你可以把一棵树看作一个单独的，离散的对象。但事实上，一棵树至少由两个主要系统连接：树叶和空气的处理循环与根和泥土的处理循环。这段话让我开始思考一个问题，我们应该如何告诉一个外星人什么是树?
让我们一起来试试吧。首先，
树是一种植物。 主要组成部分是根、干、枝、叶、花、果。
那树有什么特性呢？
通常长在泥土里。 生长需要水和阳光。 通过叶子进行光合作用（又一个难以解释的概念）。
树是从哪来的？
balabala 进化来的吧。。。（生物学的不好）
方法论 如同我们讨论树的方式一般，通常我们可以从定义、特性、实现、场景、历史、相关、抽象等不同角度去看待事物。下面我们再试试解释下后朋克好了。
后朋克(post punk)是一种80年代极为流行的音乐流派。 后朋克相对于传统摇滚乐而言更为实验，音乐更另类也更艺术化。 以the cure和new order等乐队为代表的80年代后朋乐队都非常擅长使用合成器技术， 并且作曲非常好听（不像某些朋克乐队）。 后朋克在80年代初流行，但是在80年代中期逐渐走向没落，并逐渐转向了另类摇滚。 后朋克和朋克的关系就像javascript和java的关系一样--没啥关系。 事实上和后朋克常常混起来的是新浪潮和另类摇滚，大多数时候，区分他们也没什么意义。</description></item><item><title>move slow and mend things</title><link>https://chenminhua.github.io/posts/2018_move_slow_and_mend_things/</link><pubDate>Fri, 06 Apr 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_move_slow_and_mend_things/</guid><description>“move fast and break things” 这是 fackbook 著名的 motto，意思是说，在使用新技术和新工具的时候，尽管其可能会有不稳定的地方，但是为了追求开发速度，应当果断使用那些能够提升开发效率的新技术。由于有了 facebook 的成功背书，很多初创公司都将其引为自己公司的开发宗旨。
但是，很多人都误解了这句话，认为只要短期内 move fast 了，就可以随意的 break things，事实上这样做只会让你走得更累也更慢。更重要的一点是著名的破窗理论：“如果你的一扇窗户破了，你不去修复，很快其他窗也会跟着破，房子会变得一片狼藉”。很多人认为为了 move fast，就可以稍微放弃一点点对软件质量的要求。但是这样的妥协就像是纵容了一扇破窗，软件会快速腐坏并让你崩溃。
我也曾经历过由于项目进度紧张而导致没有时间重构代码，没有时间 review 项目总体设计的情况。实际教训告诉我，宁可加班，宁可项目延期，也不能放弃对代码质量的要求。我司技术 vp 曾经跟我说，快是衡量一个技术团队的唯一标准。但我相信，这一论述永远要加上保证软件质量的前提。
事实上前两年，facebook 也把他们的 Motto 改成了”move fast with stable infra”。你看，facebook 也受不了工程师随便 break things 了。
有些时候，与其”move fast and break things”不如”move slow and mend things”。</description></item><item><title>数学与经济</title><link>https://chenminhua.github.io/posts/2018_%E6%95%B0%E5%AD%A6%E4%B8%8E%E7%BB%8F%E6%B5%8E/</link><pubDate>Fri, 06 Apr 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E6%95%B0%E5%AD%A6%E4%B8%8E%E7%BB%8F%E6%B5%8E/</guid><description>数学的优势在于，它需要精确定义，而且为多样化的领域提供了共同语言，但是它也有局限性。公式与其基本假设，往往夸大了可以从经济理论预测出来的精密度。比起任何实际的经济而言，许多经济理论，更多关乎一个完全虚构的世界。经济模型可能成为空中楼阁，结构精巧而一无是处。
当一个经济理论被表达为一个数学公式，就事先假定了它是公正的，而事实往往并非如此。
亚当·斯密在出版于 1776 年的经典著作《国富论》中，提出了一个非常引入注目的理论——自由市场理论。通过简化假设，他将自由市场的运作描述为受供给和需求力量驱动的典型市场。在这一 18 世纪的伟大经济模型中，他提出了价格将起到核心作用，因为价格表示了稀缺或盈余，并将达成理想的市场状态。亚当·斯密的主要观点是，自由市场可以有效调节生产、分配，就像一只看不见的手。在亚当·斯密的描述中，政府通常如同恶魔，干扰价格信号，扰乱自由市场的均衡机制。
新古典经济学家简单地认为：人的理性行为是一致的、可预测的、可靠的，并且深深植根于人的自身利益。同时他们还认为，人的理性行为假设在经济模式中很普遍，它可以用术语“经济人”来代表，即结合所有这些特性的一种神秘动物。
支持自由市场理论的经济学家更有可能认为人是完全理性的，而且他们的行为是在掌握了完全的信息和客观性的前提下做出的。自由市场理论的怀疑者认为，行为和条件不够完美时，自由市场理论也不太可能完美。凯恩斯的研究起点不是完美市场运作的假设，而是基于 20 世纪 30 年代“大萧条”这一现实，他的理论不受限于“经济人”或者其他新古典经济学假设。
有趣的是，这两种经济学家都可能在数学上达成正确的结论，而得出完全矛盾的经济学理论。更有趣的是，这两种经济学家都在过去 40 年内被授予了诺贝尔奖。</description></item><item><title>质数</title><link>https://chenminhua.github.io/posts/2018_%E8%B4%A8%E6%95%B0/</link><pubDate>Mon, 02 Apr 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E8%B4%A8%E6%95%B0/</guid><description>突然想知道第 n 个质数是多少，比如说我的生日是 11 月 24 日，那么属于我的那个质数是多少呢？
先写个判断一个数是不是质数的函数
bool isPrime(int n){ if (n == 1){ return false; }else { for (int i = 2; i &amp;lt;= floor(sqrt(n)); i++){ if (n % i == 0){ return false; } } return true; } } 然后调用它
int main() { int n; cin &amp;gt;&amp;gt; n; int count = 0; int j = 2; while (true) { if (isPrime(j)){ count += 1; cout &amp;lt;&amp;lt; j &amp;lt;&amp;lt; endl; if (count &amp;gt;= n) { break; } } j += 1; } } 结果显示第 1124 个质数为 9043。</description></item><item><title>akka</title><link>https://chenminhua.github.io/posts/2018_akka/</link><pubDate>Sun, 01 Apr 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_akka/</guid><description>akka 不是一个 framework，而是一个 toolkit 或者说运行时，用于在 jvm 上构建高并发、分布式、弹性、消息驱动的应用。Actor 执行操作来响应消息。这些操作包括更改 actor 自己的内部状态，以及发出其他消息和创建其他 actor。所有消息都是异步交付的，因此将消息发送方与接收方分开。这种分离，使得 actor 系统具有内在的并发性：可以不受限制地并行执行任何拥有输入消息的 actor。
像真实世界的演员一样，Akka actor 也需要一定程度的隐私。您不能直接将消息发送给 Akka actor。相反，需要将消息发送给等同于邮政信箱的 actor 引用。然后通过该引用将传入的消息路由到 actor 的邮箱，以后再传送给 actor。Akka actor 甚至要求所有传入的消息都是不可变的。
与一些真实世界中演员的需求不同，Akka 中由于某种原因而存在一些看似强制要求的限制。 使用 actor 的引用可阻止交换消息以外的任何交互，这些交互可能破坏 actor 模型核心上的解耦本质。 Actor 在执行上是单线程的（不超过 1 个线程执行一个特定的 actor 实例），所以邮箱充当着一个缓冲器，在处理消息前会一直保存这些消息。 消息的不可变性意味着根本无需担心可能影响 actor 之间各种共享的数据的同步问题。
actors sending messages changing its state changing its behavior creating more actors
class Activity class Disable(val password: String) class Enable(val password: String) class Alarm(val password: String): AbstractLoggingActor() { override fun createReceive(): Receive { return disabled } val enabled = receiveBuilder() .</description></item><item><title>并发与并行</title><link>https://chenminhua.github.io/posts/2018_%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C/</link><pubDate>Thu, 29 Mar 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C/</guid><description>很多初级程序员都会把并发和并行搞混在一起，或者认为并发和并行根本就是一回事。而其实并发和并行压根就不是在讨论一个问题。本文我们就一起来看看究竟什么是并发和并行，以及如何实现并发和并行。
并发与并行 并发（concurrency）用于描述问题。如果一个问题可以被拆分成多个问题进行局部求解，或者更本质的说，如果每个局部的子问题的求解都不因其求解的顺序改变而改变，那么这就是一个可并发的问题。（再次注意：并发描述的是问题）
并行描述的是解决问题的方法。二十个人一起搬砖也好，二十个 CPU 核一起计算也好，并行描述的就是将任务分配给多个可以执行任务的执行者，分别执行任务的方式。
举个简单的例子。大家都应该去过图书馆借书，假设现在图书馆有一个前台管理员，A 同学去前台借书，同时 B 同学去前台还书，C 同学在咨询某个问题。这时候，图书管理员可以同时处理你们的”请求”，先从 A 手中接过书，然后回到 C 同学的问题，再用扫码枪扫 B 同学的书，然后帮 A 同学办理借书登记。整个过程中，管理员执行的任何一个子任务都不会因为其处理的先后顺序而导致其处理结果的变化。因此我们说，图书管理员的工作是一个可并发的工作（可以”同时”处理多个任务）。事实上，类比到服务端开发上，图书管理员不过就是一个开放了若干接口（借书，还书，咨询等）的服务器么。
而随着来图书馆的同学越来越多，尽管图书管理员依旧面对一个可并发的问题，但是其处理问题的速度（计算能力）是有限的，而不停在不同任务之间切换（上下文切换）更增加了他处理问题的时间成本。于是图书馆决定增加两名前台管理员，这就是并行处理问题的方式。
后端服务通常都是在处理可并发的问题。在不增加计算能力的情况下，通过增加线程（这里的线程是一个抽象的概念，可以理解为一组具有独立上下文的计算资源）的方式可以让服务能够更好的处理并发问题（同时处理多个任务）。当某个任务需要占用较长时间，但并不占用 cpu 时，服务可以切换去其他任务，让 cpu 先去处理其他任务，之后再回来。
矩阵乘法 我们再换个例子，google 引以为傲的 page rank 算法中最关键的一步就是计算两个矩阵的乘积，然后得到不同网页之间的相关性。但是现在的互联网太大了，网页数都是以亿为单位的。计算两个超大矩阵的乘积显然是一个非常耗时的工作。如果用一台计算机算显然是不可能的。
事实上这压根不是一个计算机问题，而是一个矩阵乘积计算的数学问题。简单来说，两个矩阵的乘积可以由其各自的部分子矩阵的乘积组合而乘（非常基础的线性代数知识）。假设我们要计算两个 300,000,000 _ 300,000,000 的矩阵的乘积，我们可以将其分别划分为 9 个 100,000,000 _ 100,000,000 的矩阵，一共需要进行 27 次 100,000,000 * 100,000,000 的矩阵的乘法和若干次矩阵加法（相比于矩阵乘法而言，矩阵加法的时间复杂度要低很多，可以暂且忽略）。
现在我们的超大矩阵乘法就变成了 27 个稍微小一点的矩阵的乘法了。尽管看上去没什么了不起，但是这个特性却是决定性的，因为我们可以把矩阵乘法拆分到不同的机器上计算，再集合到一起就行了。事实上，你可以继续拆分，把 100,000,000 _ 100,000,000 的矩阵继续拆分成 100 个 10,000,000 _ 10,000,000 个矩阵，这时候问题就变成了 27000 个 10,000,000 * 10,000,000 的矩阵的乘积。
如果你有 27000 台服务器的话，这个超大矩阵计算的时间复杂度就降低了 27000 倍！！原本需要计算一个月的问题现在只需要一分半钟就可以解决。</description></item><item><title>The rule of hole</title><link>https://chenminhua.github.io/posts/2018_the_rule_of_hole/</link><pubDate>Tue, 27 Mar 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_the_rule_of_hole/</guid><description>The rule of hole: If you fall into a hole, don&amp;rsquo;t dig.
对很多人来说，承认自己错了并不是一件容易办到的事情，即使他们看上去并不是一个固执的人。有时候是因为害羞，有时候是为了面子，有时候是为了某些利益，有时候是觉得自己能扭转局面，人会在意识到自己错了之后，继续沿着原路往前走，越陷越深。
这种心态可以用“沉没成本”理论来解释，说白了，就是我已经走了这么远了，现在掉头的话，前面做的都白做了。前面做的所有努力，都成为了这一刻选择掉头的“沉没成本”，而你走得越远，“沉没成本”就越高。
关于如何成为一个职业的程序员，我们常常被教育要说到做到。能就是能，不能就是不能，不要说试试看。当然，我完全同意这些话，但是有些同学会把这句话理解为，如果我接了这个需求，我就一定要做到。
上面的两种说法看起来差不多，其实换了个角度，表达的意思就完全不同了。在评估需求的时候，我们当然要足够认真仔细，明白什么是你能做到的，什么是你做不到的，什么是你能做到但是让你觉得不对劲的。（如果你只把自己当做一个勤劳的码农，觉得评审需求是产品经理和架构师的事，那你并不是一个合格的工程师。如果你们公司不让你参加需求评审，那还是趁早换个地方吧。）但是当你在开发过程中，发现之前评审的需求中某个地方有逻辑漏洞，或者你发现你必须搞一堆很奇怪的东西（在代码里下毒）才能完成需求，你应该立即站出来，而不是闷着头做下去。
这是我在工作中学到最重要的一件事：掉坑别挖。</description></item><item><title>copy on write</title><link>https://chenminhua.github.io/posts/2018_copy_on_write/</link><pubDate>Sat, 24 Mar 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_copy_on_write/</guid><description>swift 中的 cow swift 中有 struct 和 class 这两种数据结构，很多入门教程都会介绍说，struct 和 class 最大的区别是，struct 是值类型，而 class 是引用类型。换句话说，struct 在传递的过程中是值传递，而 class 传的则是引用。那么为什么需要这两种传值机制呢？
从并发角度看，值传递似乎是一种更安全的选择。因为值传递在每次传递过程中，对象都会被拷贝一份，这样可以防止对象被意外修改。 但是在很多情况下，或许用户确实需要一个对象在不同的执行块共享，甚至共同修改，这时候引用传递显然更适合。 更重要的是，引用传递是一种开销更小的传递方式，程序不需要为这次传递申请一块新的内存并拷贝对象，也不用考虑对象失去全部有效引用时回收这块新开辟的内存。 那有没有可能实现一种技术，让我们同时享受值传递和引用传递的优点呢？答案是”写时复制”(cow, copy-on-write)。顾名思义，cow 就是说当使用值传递的时候，在新的代码块中依旧引用原来的对象，直到改变(写)对象的时候，才复制一份对象并引用新对象。在 swift 中，你可以使用 mutating 关键字来标识 struct 的某个方法是否会改变这个对象。当调用一个 mutating 方法时，才会真的复制一份对象。
cow 与引用计数 英文好的同学建议直接读这篇 instagram 的原文 「在 instagram 停用了 python 的垃圾回收」。
linux 内核有一个这样的机制：子进程启动时会共享父进程的内存页，但是只有当子进程试图去写这些内存页的时候，才会把这些内存拷贝到新的内存页，也就是我们说的”写时复制”。但是在 python 中，由于 python 使用引用计数来进行垃圾回收，这导致了每次读一个对象，都需要去写这个对象的引用数(加 1)，所以所有的读就都变成了写，cow 机制就失效了。为此，instagram 关掉了 python 的 gc…</description></item><item><title>我只是想要一个函数啊</title><link>https://chenminhua.github.io/posts/2018_kotlin%E4%B8%AD%E7%9A%84%E5%8F%AF%E7%A9%BA%E7%B1%BB%E5%9E%8B/</link><pubDate>Fri, 23 Mar 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_kotlin%E4%B8%AD%E7%9A%84%E5%8F%AF%E7%A9%BA%E7%B1%BB%E5%9E%8B/</guid><description>kotlin 中的可空类型 最近在公司使用 Kotlin 写后端服务（spring + mybatis），遇到 optional 的小问题，如下
fun getProject(projectCode: String): ProjectDO = projectMapper.getProjectByCode(projectCode) 上面这个方法根据项目号去数据库拿项目，从类型签名上看，getProject 方法返回的是一个 ProjectDO 类型的对象，而且由于不是可空类型，所以不会是 null。但是，如果数据库里面确实没有这个项目号的项目呢？试验一下
print(getProject(&amp;#34;no such project&amp;#34;)) // null 返回结果是 null!!
kotlin 欺骗了我们，明明说好是非空，怎么就返回了一个 null 给我!!
其实这锅 kotlin 真不背。了解 mybatis 的同学应该知道，mybatis 采用的是 jdk 代理的模式来代理 Mapper 接口。尽管我们在定义 mapper 接口时写明了返回非空类型的对象，
projectMapper.getProjectByCode(projectCode): ProjectDO 但是在 jvm 上运行的时候，运行时类型可没有什么非空不非空的。查不到数据，mybatis 的 mapper 的代理对象就返回了一个 null 给调用者，调用的地方拿这个对象赋值也好，返回也好，也不存在可空类型，拿到 null 就是 null 了。
所以 kotlin 的可空类型，只能在编译时帮你搞定一些程序员搞出来的空指针异常。而在一些使用了代理技术的地方，运行时还是会给你跑出一个 null 来，仍然需要你手动处理。
by the way，如果你阅读 kotlin 代码编译后的字节码，会发现其实 kotlin 在所有不是可空的变量上加上了@NotNull 注解，其 RetentionPolicy 为 class</description></item><item><title>我只是想要一个函数啊</title><link>https://chenminhua.github.io/posts/2018_%E6%88%91%E5%8F%AA%E6%98%AF%E6%83%B3%E8%A6%81%E4%B8%80%E4%B8%AA%E5%87%BD%E6%95%B0%E5%95%8A/</link><pubDate>Mon, 19 Mar 2018 20:00:08 +0800</pubDate><guid>https://chenminhua.github.io/posts/2018_%E6%88%91%E5%8F%AA%E6%98%AF%E6%83%B3%E8%A6%81%E4%B8%80%E4%B8%AA%E5%87%BD%E6%95%B0%E5%95%8A/</guid><description>从面向对象说起 显然，面向对象编程在很长一段时间内，都是最主流的一种编程范式。那到底什么是面向对象呢？为什么我们需要对象呢？
面向对象的最重要特性有三个：封装，继承，多态。
在我看来，多态无疑是这三者中最为重要的特性，它解决了软件架构中最为复杂的依赖问题，也就是我们常说的解耦。 继承则解决了代码复用的问题，并实现了一定程度的抽象。 而封装则使数据变得更安全，同时也隐藏了数据的存储结构与类型。 对象的本质 假设我们现在要写一个人员管理的软件，需要实现一个给人员年龄加 1 的功能。非面向对象的写法可能是
addOneYearAge(person) 我们拿到一个数据的引用，然后给其年龄加一。而面向对象的方式则可能是
person.growUpOneYear() 这里我们有一个对象，然后给对象发送了一个消息，通知它发生一些变化。
这两种写法都能实现我们的目标，那么那种更好呢？如果我们抛开运行性能，抛开运行时函数入口跳转等等奇怪的字眼，单纯的看看上面两段代码，我觉得他们是一样的（我相信肯定有人会说第二种更好，或许也有人会支持第一种）。但是，当你的数据有二十种改变的方式的时候，第一种写法会崩溃的更快，各种改变 person 的函数会被写在你永远想象不到的地方，而第二种写法则相对容易管理，因为你控制了数据的改变（如果你知道你在做什么的话）。
所以，对象是什么已经很显而易见了。对象是一堆数据的集合，以及可以操作这些数据的方法。
闭包 为什么要从面向对象扯到闭包？这两个东西八竿子打不着啊？
从前我也是这么认为的，直到有一天我读了 ruby 作者松本行宏的书《代码的本质》。他说：对象和闭包是同一事物的两面。下面是一段简单的 js 中使用了闭包的代码。
function outside() { var a = 0; return function inside() { a++; console.log(a); }; } var f = outside(); f(); //1 f(); //2 f(); //3 我们可以看到 outside 函数返回了一个 inside 函数，inside 函数可以访问 outside 函数作用域内声明的变量 a。
通常情况下，我们认为当函数返回时，其调用栈的栈帧(stack frame)以及其上的变量就会被销毁，所以当 outside 返回的时候，a 就应该不能访问了，但事实是 inside 函数可以始终访问到 a 变量。关于闭包可能导致的内存泄露问题不是本文讨论的重点。真正让我觉得有趣的依然是松本先生的那句话：对象和闭包是同一事物的两面。
其实，我们可以认为对象是通过类机制将过程（方法）封装到了数据里面，而闭包是通过作用域将数据封装到过程（方法）里面。它们的本质都是将数据与操作数据的过程（方法）放到一起，将数据与计算放在一起罢了。
(如果你还是不能理解这段内容，请仔细阅读《sicp》的第二章。)</description></item><item><title/><link>https://chenminhua.github.io/posts/2022_jenkins/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://chenminhua.github.io/posts/2022_jenkins/</guid><description>mkdir $HOME/jenkins_home docker run -d -p 8080:8080 \ -v $HOME/jenkins_home:/var/jenkins_home \ --name jenkins jenkins/jenkins docker logs jenkins #access http://localhost:8080</description></item><item><title/><link>https://chenminhua.github.io/posts/the_elements_of_style/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://chenminhua.github.io/posts/the_elements_of_style/</guid><description>Writing is hard, even for authors who do it all the time. What should be easy and flowing looks tangled or feeble or overblown — not what was meant at all.
We are all writers and readers as well as communicators, with the need at times to please and satisfy ourselves with the clear and almost perfect thought.
Write in a way that comes naturally. Revise and rewrite. Do not explain too much.</description></item></channel></rss>