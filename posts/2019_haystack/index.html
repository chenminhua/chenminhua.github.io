<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Haystack(facebook是怎么存照片的) - 硕大的汤姆</title><meta name=viewport content="width=device-width,initial-scale=1"><meta itemprop=name content="Haystack(facebook是怎么存照片的)"><meta itemprop=description content="本文写于 21 世纪 10 年代最后一个圣诞节的晚上，内容为 facebook 的论文 《Finding a needle in Haystack: Facebook’s photo storage》的阅读笔记。该论文旨在解决社交网络中海量小文件且请求具有长尾特性的服务能力问题。
简单来说，传统文件系统会给每个文件建立 metadata，比如 inode 这种数据结构，在访问文件的时候，需要先从磁盘找到 inode，然后从 inode 里面查到文件真正的位置，再去拿文件，于是 metadata lookup 就成了瓶颈。而 haystack 所做的就是尽可能减少磁盘访问。
当然，那文件的那次磁盘 IO 是跑不掉的，那有没有可能省掉 metadata lookup 这一此磁盘 IO 呢？有点难，因为要处理海量的小文件，他们的 metadata 也是非常非常大的，内存肯定放不下。所以思路就到了怎么压缩 metadata，以使其能够放入内存中去。
具体是怎么做的呢？卖个关子，去我的知乎专栏看吧~ https://zhuanlan.zhihu.com/p/99388774"><meta itemprop=datePublished content="2019-12-25T20:00:08+08:00"><meta itemprop=dateModified content="2019-12-25T20:00:08+08:00"><meta itemprop=wordCount content="40"><meta itemprop=keywords content><meta property="og:title" content="Haystack(facebook是怎么存照片的)"><meta property="og:description" content="本文写于 21 世纪 10 年代最后一个圣诞节的晚上，内容为 facebook 的论文 《Finding a needle in Haystack: Facebook’s photo storage》的阅读笔记。该论文旨在解决社交网络中海量小文件且请求具有长尾特性的服务能力问题。
简单来说，传统文件系统会给每个文件建立 metadata，比如 inode 这种数据结构，在访问文件的时候，需要先从磁盘找到 inode，然后从 inode 里面查到文件真正的位置，再去拿文件，于是 metadata lookup 就成了瓶颈。而 haystack 所做的就是尽可能减少磁盘访问。
当然，那文件的那次磁盘 IO 是跑不掉的，那有没有可能省掉 metadata lookup 这一此磁盘 IO 呢？有点难，因为要处理海量的小文件，他们的 metadata 也是非常非常大的，内存肯定放不下。所以思路就到了怎么压缩 metadata，以使其能够放入内存中去。
具体是怎么做的呢？卖个关子，去我的知乎专栏看吧~ https://zhuanlan.zhihu.com/p/99388774"><meta property="og:type" content="article"><meta property="og:url" content="https://chenminhua.github.io/posts/2019_haystack/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-12-25T20:00:08+08:00"><meta property="article:modified_time" content="2019-12-25T20:00:08+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Haystack(facebook是怎么存照片的)"><meta name=twitter:description content="本文写于 21 世纪 10 年代最后一个圣诞节的晚上，内容为 facebook 的论文 《Finding a needle in Haystack: Facebook’s photo storage》的阅读笔记。该论文旨在解决社交网络中海量小文件且请求具有长尾特性的服务能力问题。
简单来说，传统文件系统会给每个文件建立 metadata，比如 inode 这种数据结构，在访问文件的时候，需要先从磁盘找到 inode，然后从 inode 里面查到文件真正的位置，再去拿文件，于是 metadata lookup 就成了瓶颈。而 haystack 所做的就是尽可能减少磁盘访问。
当然，那文件的那次磁盘 IO 是跑不掉的，那有没有可能省掉 metadata lookup 这一此磁盘 IO 呢？有点难，因为要处理海量的小文件，他们的 metadata 也是非常非常大的，内存肯定放不下。所以思路就到了怎么压缩 metadata，以使其能够放入内存中去。
具体是怎么做的呢？卖个关子，去我的知乎专栏看吧~ https://zhuanlan.zhihu.com/p/99388774"><link rel=stylesheet type=text/css media=screen href=https://chenminhua.github.io/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://chenminhua.github.io/css/main.css><link id=dark-scheme rel=stylesheet type=text/css href=https://chenminhua.github.io/css/dark.css><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script>
<script src=https://chenminhua.github.io/js/main.js></script></head><body><div class="container wrapper"><div class=header><div class=avatar><a href=https://chenminhua.github.io/><img src="https://avatars.githubusercontent.com/u/10234400?v=4" alt=硕大的汤姆></a></div><h1 class=site-title><a href=https://chenminhua.github.io/>硕大的汤姆</a></h1><div class=site-description><p>The official website of Minhua Chen</p><nav class="nav social"><ul class=flat><li><a href=https://github.com/knadh/hugo-ink title=Github><i data-feather=github></i></a></li><li><a href=/index.xml title=RSS><i data-feather=rss></i></a></li></ul></nav></div><nav class=nav><ul class=flat><li><a href=/>Home</a></li><li><a href=/posts>All posts</a></li><li><a href=/about>About</a></li><li><a href=/tags>Tags</a></li></ul></nav></div><div class=post><div class=post-header><div class=meta><div class=date><span class=day>25</span>
<span class=rest>Dec 2019</span></div></div><div class=matter><h1 class=title>Haystack(facebook是怎么存照片的)</h1></div></div><div class=markdown><p>本文写于 21 世纪 10 年代最后一个圣诞节的晚上，内容为 facebook 的论文 《Finding a needle in Haystack: Facebook’s photo storage》的阅读笔记。该论文旨在解决社交网络中海量小文件且请求具有长尾特性的服务能力问题。</p><p>简单来说，传统文件系统会给每个文件建立 metadata，比如 inode 这种数据结构，在访问文件的时候，需要先从磁盘找到 inode，然后从 inode 里面查到文件真正的位置，再去拿文件，于是 metadata lookup 就成了瓶颈。而 haystack 所做的就是尽可能减少磁盘访问。</p><p>当然，那文件的那次磁盘 IO 是跑不掉的，那有没有可能省掉 metadata lookup 这一此磁盘 IO 呢？有点难，因为要处理海量的小文件，他们的 metadata 也是非常非常大的，内存肯定放不下。所以思路就到了怎么压缩 metadata，以使其能够放入内存中去。</p><p>具体是怎么做的呢？卖个关子，去我的知乎专栏看吧~ <a href=https://zhuanlan.zhihu.com/p/99388774>https://zhuanlan.zhihu.com/p/99388774</a></p></div><div class=tags></div><div class=back><a href=https://chenminhua.github.io/><span aria-hidden=true>← Back</span></a></div><div class=back></div></div></div><div class="footer wrapper"><nav class=nav><div>2019</div></nav></div><script>feather.replace()</script></body></html>