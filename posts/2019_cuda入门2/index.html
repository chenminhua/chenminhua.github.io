<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Cuda实战入门2: 将矩阵乘法速度提升 5000 倍 - 硕大的汤姆</title><meta name=viewport content="width=device-width,initial-scale=1"><meta itemprop=name content="Cuda实战入门2: 将矩阵乘法速度提升 5000 倍"><meta itemprop=description content="本实验采用不同的方法来计算 8192 * 8192 的整型矩阵乘法运算。
C 语言版 C 语言是大家公认的高性能语言，那我们就从 C 语言开始吧。
// 用一位数组表示二维矩阵 mat1 = (int*) malloc(m_size * m_size * sizeof(int)); mat2 = (int*) malloc(m_size * m_size * sizeof(int)); result = (int*) malloc(m_size * m_size * sizeof(int)); // initialize for (int i = 0; i < m_size * m_size; i++) { mat1[i] = rand()/1000000; mat2[i] = rand()/1000000; result[i] = 0; } for (int r = 0; r < m_size; r++) { for (int c = 0; c < m_size; c++) { for (int n = 0; n < m_size; n++) { result[r*m_size + c] += mat1[r*m_size+n] * mat2[n*m_size+c]; } } } 这代码没什么可说的，值得一提的可能就是用一维数组来存二维矩阵，这样可以让矩阵在内存中的分布更连续。很容易估算出来这段代码需要进行万亿级别的乘法或加法运算，倘若使用 1950 年冯."><meta itemprop=datePublished content="2019-08-24T20:00:08+08:00"><meta itemprop=dateModified content="2019-08-24T20:00:08+08:00"><meta itemprop=wordCount content="589"><meta itemprop=keywords content><meta property="og:title" content="Cuda实战入门2: 将矩阵乘法速度提升 5000 倍"><meta property="og:description" content="本实验采用不同的方法来计算 8192 * 8192 的整型矩阵乘法运算。
C 语言版 C 语言是大家公认的高性能语言，那我们就从 C 语言开始吧。
// 用一位数组表示二维矩阵 mat1 = (int*) malloc(m_size * m_size * sizeof(int)); mat2 = (int*) malloc(m_size * m_size * sizeof(int)); result = (int*) malloc(m_size * m_size * sizeof(int)); // initialize for (int i = 0; i < m_size * m_size; i++) { mat1[i] = rand()/1000000; mat2[i] = rand()/1000000; result[i] = 0; } for (int r = 0; r < m_size; r++) { for (int c = 0; c < m_size; c++) { for (int n = 0; n < m_size; n++) { result[r*m_size + c] += mat1[r*m_size+n] * mat2[n*m_size+c]; } } } 这代码没什么可说的，值得一提的可能就是用一维数组来存二维矩阵，这样可以让矩阵在内存中的分布更连续。很容易估算出来这段代码需要进行万亿级别的乘法或加法运算，倘若使用 1950 年冯."><meta property="og:type" content="article"><meta property="og:url" content="https://chenminhua.github.io/posts/2019_cuda%E5%85%A5%E9%97%A82/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-08-24T20:00:08+08:00"><meta property="article:modified_time" content="2019-08-24T20:00:08+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Cuda实战入门2: 将矩阵乘法速度提升 5000 倍"><meta name=twitter:description content="本实验采用不同的方法来计算 8192 * 8192 的整型矩阵乘法运算。
C 语言版 C 语言是大家公认的高性能语言，那我们就从 C 语言开始吧。
// 用一位数组表示二维矩阵 mat1 = (int*) malloc(m_size * m_size * sizeof(int)); mat2 = (int*) malloc(m_size * m_size * sizeof(int)); result = (int*) malloc(m_size * m_size * sizeof(int)); // initialize for (int i = 0; i < m_size * m_size; i++) { mat1[i] = rand()/1000000; mat2[i] = rand()/1000000; result[i] = 0; } for (int r = 0; r < m_size; r++) { for (int c = 0; c < m_size; c++) { for (int n = 0; n < m_size; n++) { result[r*m_size + c] += mat1[r*m_size+n] * mat2[n*m_size+c]; } } } 这代码没什么可说的，值得一提的可能就是用一维数组来存二维矩阵，这样可以让矩阵在内存中的分布更连续。很容易估算出来这段代码需要进行万亿级别的乘法或加法运算，倘若使用 1950 年冯."><link rel=stylesheet type=text/css media=screen href=https://chenminhua.github.io/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://chenminhua.github.io/css/main.css><link id=dark-scheme rel=stylesheet type=text/css href=https://chenminhua.github.io/css/dark.css><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script>
<script src=https://chenminhua.github.io/js/main.js></script></head><body><div class="container wrapper"><div class=header><div class=avatar><a href=https://chenminhua.github.io/><img src="https://avatars.githubusercontent.com/u/10234400?v=4" alt=硕大的汤姆></a></div><h1 class=site-title><a href=https://chenminhua.github.io/>硕大的汤姆</a></h1><div class=site-description><p>The official website of Minhua Chen</p><nav class="nav social"><ul class=flat><li><a href=https://github.com/knadh/hugo-ink title=Github><i data-feather=github></i></a></li><li><a href=/index.xml title=RSS><i data-feather=rss></i></a></li></ul></nav></div><nav class=nav><ul class=flat><li><a href=/>Home</a></li><li><a href=/posts>All posts</a></li><li><a href=/about>About</a></li><li><a href=/algo>Algo</a></li><li><a href=/principles>原则</a></li><li><a href=/tags>Tags</a></li></ul></nav></div><div class=post><div class=post-header><div class=meta><div class=date><span class=day>24</span>
<span class=rest>Aug 2019</span></div></div><div class=matter><h1 class=title>Cuda实战入门2: 将矩阵乘法速度提升 5000 倍</h1></div></div><div class=markdown><p>本实验采用不同的方法来计算 8192 * 8192 的整型矩阵乘法运算。</p><h2 id=c-语言版>C 语言版</h2><p>C 语言是大家公认的高性能语言，那我们就从 C 语言开始吧。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span>    <span style=color:#75715e>// 用一位数组表示二维矩阵
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    mat1 <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span>) malloc(m_size <span style=color:#f92672>*</span> m_size <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>    mat2 <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span>) malloc(m_size <span style=color:#f92672>*</span> m_size <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>    result <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span>) malloc(m_size <span style=color:#f92672>*</span> m_size <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// initialize
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> m_size <span style=color:#f92672>*</span> m_size; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        mat1[i] <span style=color:#f92672>=</span> rand()<span style=color:#f92672>/</span><span style=color:#ae81ff>1000000</span>;
</span></span><span style=display:flex><span>        mat2[i] <span style=color:#f92672>=</span> rand()<span style=color:#f92672>/</span><span style=color:#ae81ff>1000000</span>;
</span></span><span style=display:flex><span>        result[i] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> r <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; r <span style=color:#f92672>&lt;</span> m_size; r<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> c <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; c <span style=color:#f92672>&lt;</span> m_size; c<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> n <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; n <span style=color:#f92672>&lt;</span> m_size; n<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>                result[r<span style=color:#f92672>*</span>m_size <span style=color:#f92672>+</span> c] <span style=color:#f92672>+=</span> mat1[r<span style=color:#f92672>*</span>m_size<span style=color:#f92672>+</span>n] <span style=color:#f92672>*</span> mat2[n<span style=color:#f92672>*</span>m_size<span style=color:#f92672>+</span>c];
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span></code></pre></div><p>这代码没什么可说的，值得一提的可能就是用一维数组来存二维矩阵，这样可以让矩阵在内存中的分布更连续。很容易估算出来这段代码需要进行万亿级别的乘法或加法运算，倘若使用 1950 年冯.诺依曼用来预测天气的计算机（每秒 5000 次计算），大概要算个六七年吧。</p><p>还好现在是 2019 年，这段代码在我的 i7 cpu 上运行花了 7000 s，差不多两个小时了。（记得开编译器优化，不然可能今天都跑不完）</p><h2 id=eigen-版>eigen 版</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;Eigen/Dense&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>using namespace<span style=color:#f92672>::</span>Eigen;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>typedef</span> Eigen<span style=color:#f92672>::</span>Matrix<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span>, Dynamic, Dynamic<span style=color:#f92672>&gt;</span> IntMatrix;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>IntMatrix <span style=color:#a6e22e>mat1</span>(m_size,m_size);
</span></span><span style=display:flex><span>IntMatrix <span style=color:#a6e22e>mat2</span>(m_size,m_size);
</span></span><span style=display:flex><span>IntMatrix <span style=color:#a6e22e>result</span>(m_size,m_size);
</span></span><span style=display:flex><span>mat1.setRandom();
</span></span><span style=display:flex><span>mat2.setRandom();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> mat1 <span style=color:#f92672>*</span> mat2;
</span></span></code></pre></div><p>运行此段代码需要下载 eigen 库，并在编译时 link 上去。这段代码在我的机器（i7 单核）上运行花了 120s，从两个小时直接变成了两分钟，代码还简单了很多啊握草。（同样记得开编译器优化）</p><p>给 eigen 跪了啊，这比我快了快 60 倍啊，这告诉我们一个道理，轮子该用还是得用啊。（ eigen 进行了指令级级别的优化，以后有机会在写篇文章深入讲下。）</p><p>CUDA 显然，矩阵乘法是一个天然完美的可并行问题。事实上，大量伟大的理论研究和工程实践都基于矩阵乘法可并行这一前提，比如 google。</p><p>CPU 并不擅长并行计算，但是 GPU 擅长啊。GPU 可以一口气拉起一个网格(grid)的线程，像一个计算方针一样同时处理计算的不同部分。关于 CUDA 可以参考前面一篇文章。​ 在矩阵乘法这个问题中，结果矩阵中的每一个位置的数据都不依赖于其他位置数据的计算过程和结果。所以我们完全可以拉一堆进程起来，让他们分别计算某一些位置的结果。</p><p>你可以想象为你们学校要算两个 100 * 100 的矩阵的乘法，这个矩阵计算的结果是万级的，而运算量可是百万级的。于是你们校长找到 50 个班主任，给每个班主任分配两行结果计算任务，你们班呢，分到了前两行，也就是要算出结果矩阵中前两行的 200 个数字。班主任再把这两百个数字分给了 50 个同学，每个同学只要算 4 个数字，大约 400 次加法和 400 次乘法。于是一个巨复杂的计算问题，你们学校半天就完成了。</p><p>下面是我的代码实现</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span><span style=color:#75715e>&lt;cuda.h&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e>#include</span><span style=color:#75715e>&lt;cuda_runtime.h&gt;</span><span style=color:#75715e>
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span><span style=color:#75715e>#define BLOCK_NUM 32   </span><span style=color:#75715e>//块数量
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#75715e>#define THREAD_NUM 256 </span><span style=color:#75715e>// 每个块中的线程数
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#75715e>#define R_SIZE BLOCK_NUM * THREAD_NUM
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define M_SIZE R_SIZE * R_SIZE
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>mat_mul</span>(<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>mat1, <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>mat2, <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>result) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> bid <span style=color:#f92672>=</span> blockIdx.x;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> tid <span style=color:#f92672>=</span> threadIdx.x;
</span></span><span style=display:flex><span>    <span style=color:#75715e>// 每个线程计算一行
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> row <span style=color:#f92672>=</span> bid <span style=color:#f92672>*</span> THREAD_NUM <span style=color:#f92672>+</span> tid;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> c <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; c <span style=color:#f92672>&lt;</span> R_SIZE; c<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> n <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; n <span style=color:#f92672>&lt;</span> R_SIZE; n<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>            result[row<span style=color:#f92672>*</span>R_SIZE<span style=color:#f92672>+</span>c] <span style=color:#f92672>+=</span> mat1[row<span style=color:#f92672>*</span>R_SIZE<span style=color:#f92672>+</span>n] <span style=color:#f92672>*</span> mat2[n<span style=color:#f92672>*</span>R_SIZE<span style=color:#f92672>+</span>c];
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(<span style=color:#66d9ef>int</span> argc, <span style=color:#66d9ef>char</span> <span style=color:#f92672>*</span>argv[]) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>mat1, <span style=color:#f92672>*</span>mat2, <span style=color:#f92672>*</span>result;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>g_mat1, <span style=color:#f92672>*</span>g_mat2, <span style=color:#f92672>*</span>g_mat_result;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// 用一位数组表示二维矩阵
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    mat1 <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span>) malloc(M_SIZE <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>    mat2 <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span>) malloc(M_SIZE <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>    result <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span>) malloc(M_SIZE <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// initialize
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> M_SIZE; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        mat1[i] <span style=color:#f92672>=</span> rand()<span style=color:#f92672>/</span><span style=color:#ae81ff>1000000</span>;
</span></span><span style=display:flex><span>        mat2[i] <span style=color:#f92672>=</span> rand()<span style=color:#f92672>/</span><span style=color:#ae81ff>1000000</span>;
</span></span><span style=display:flex><span>        result[i] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaMalloc((<span style=color:#66d9ef>void</span> <span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>g_mat1, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> M_SIZE);
</span></span><span style=display:flex><span>    cudaMalloc((<span style=color:#66d9ef>void</span> <span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>g_mat2, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> M_SIZE);
</span></span><span style=display:flex><span>    cudaMalloc((<span style=color:#66d9ef>void</span> <span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>g_mat_result, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> M_SIZE);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaMemcpy(g_mat1, mat1, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> M_SIZE, cudaMemcpyHostToDevice);
</span></span><span style=display:flex><span>    cudaMemcpy(g_mat2, mat2, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> M_SIZE, cudaMemcpyHostToDevice);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    mat_mul<span style=color:#f92672>&lt;&lt;&lt;</span>BLOCK_NUM, THREAD_NUM<span style=color:#f92672>&gt;&gt;&gt;</span>(g_mat1, g_mat2, g_mat_result);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaMemcpy(result, g_mat_result, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> M_SIZE, cudaMemcpyDeviceToHost);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>这段代码在我的机器(RTX 2080TI)上运行了多久呢？</p><p>22 秒！！！</p><p>差不多比 c 写的第一版要快了 300 倍了。</p><h2 id=tensorflow>Tensorflow</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>mat1 <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>random_uniform([<span style=color:#ae81ff>8192</span>, <span style=color:#ae81ff>8192</span>], minval<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, maxval<span style=color:#f92672>=</span><span style=color:#ae81ff>65536</span>, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)
</span></span><span style=display:flex><span>mat2 <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>random_uniform([<span style=color:#ae81ff>8192</span>, <span style=color:#ae81ff>8192</span>], minval<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, maxval<span style=color:#f92672>=</span><span style=color:#ae81ff>65536</span>, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sess <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>Session()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sess<span style=color:#f92672>.</span>run(mat1)
</span></span><span style=display:flex><span>sess<span style=color:#f92672>.</span>run(mat2)
</span></span><span style=display:flex><span>sess<span style=color:#f92672>.</span>run(tf<span style=color:#f92672>.</span>matmul(mat1, mat2))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sess<span style=color:#f92672>.</span>close()
</span></span></code></pre></div><p>这段代码在我的机器上也运行了 22 秒，和上面我自己手写 cuda 程序性能相当。</p><h2 id=cublas>CUBLAS</h2><p>22 秒已经到极限了吗？还早得很呢！我们可以使用 CUBLAS 库，不但可以屏蔽掉复杂的底层实现以及不同计算设备带来的参数设计的影响，还有机会把矩阵乘法的效率进一步提升。先贴出 cublas 的一份文档 。 <a href=https://developer.nvidia.com/sites/default/files/akamai/cuda/files/Misc/mygpu.pdf>https://developer.nvidia.com/sites/default/files/akamai/cuda/files/Misc/mygpu.pdf</a>​ 下面是我的代码实现</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#75715e>// 用一位数组表示二维矩阵
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    mat1 <span style=color:#f92672>=</span> (<span style=color:#66d9ef>float</span><span style=color:#f92672>*</span>) malloc(m_size <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>float</span>));
</span></span><span style=display:flex><span>    mat2 <span style=color:#f92672>=</span> (<span style=color:#66d9ef>float</span><span style=color:#f92672>*</span>) malloc(m_size <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>float</span>));
</span></span><span style=display:flex><span>    result <span style=color:#f92672>=</span> (<span style=color:#66d9ef>float</span><span style=color:#f92672>*</span>) malloc(m_size <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>float</span>));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// initialize
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> m_size; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        mat1[i] <span style=color:#f92672>=</span> rand()<span style=color:#f92672>/</span><span style=color:#ae81ff>10000000</span>;
</span></span><span style=display:flex><span>        mat2[i] <span style=color:#f92672>=</span> rand()<span style=color:#f92672>/</span><span style=color:#ae81ff>10000000</span>;
</span></span><span style=display:flex><span>        result[i] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    cudaMalloc((<span style=color:#66d9ef>void</span> <span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>g_mat1, <span style=color:#66d9ef>sizeof</span>(<span style=color:#f92672>*</span>mat1) <span style=color:#f92672>*</span> m_size);
</span></span><span style=display:flex><span>    cudaMalloc((<span style=color:#66d9ef>void</span> <span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>g_mat2, <span style=color:#66d9ef>sizeof</span>(<span style=color:#f92672>*</span>mat2) <span style=color:#f92672>*</span> m_size);
</span></span><span style=display:flex><span>    cudaMalloc((<span style=color:#66d9ef>void</span> <span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>g_mat_result, <span style=color:#66d9ef>sizeof</span>(<span style=color:#f92672>*</span>result) <span style=color:#f92672>*</span> m_size);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// initialize CUBLAS context
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    stat <span style=color:#f92672>=</span> cublasCreate(<span style=color:#f92672>&amp;</span>handle);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    stat <span style=color:#f92672>=</span> cublasSetMatrix(r_size, r_size, <span style=color:#66d9ef>sizeof</span>(<span style=color:#f92672>*</span>mat1), mat1, r_size, g_mat1, r_size);
</span></span><span style=display:flex><span>    stat <span style=color:#f92672>=</span> cublasSetMatrix(r_size, r_size, <span style=color:#66d9ef>sizeof</span>(<span style=color:#f92672>*</span>mat2), mat2, r_size, g_mat2, r_size);
</span></span><span style=display:flex><span>    stat <span style=color:#f92672>=</span> cublasSetMatrix(r_size, r_size, <span style=color:#66d9ef>sizeof</span>(<span style=color:#f92672>*</span>result), result, r_size, g_mat_result, r_size);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>float</span> al <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0f</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>float</span> bet <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0f</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    stat <span style=color:#f92672>=</span> cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N,
</span></span><span style=display:flex><span>        r_size, r_size, r_size, <span style=color:#f92672>&amp;</span>al, g_mat1,
</span></span><span style=display:flex><span>        r_size, g_mat2, r_size, <span style=color:#f92672>&amp;</span>bet, g_mat_result, r_size);
</span></span><span style=display:flex><span>    stat <span style=color:#f92672>=</span> cublasGetMatrix(r_size, r_size, <span style=color:#66d9ef>sizeof</span>(<span style=color:#f92672>*</span>result), g_mat_result, r_size, result, r_size);
</span></span></code></pre></div><p>其中的 cublasSgemm 方法就是计算矩阵乘法的函数，具体请参考上面 pdf 的 2.4 小节。</p><p>这段代码计算 8192 * 8192 的矩阵乘法要多久呢？</p><p>答案是：1.35 秒 ！！！我们在第一版 c 语言实现的基础上完成了 5000 倍的提升！！！</p><h2 id=总结>总结</h2><p>本篇文章中，我们将 8192 * 8192 的矩阵运算从 7000 秒一路提升到了 1.35 秒，提升了五千多倍。这是一个成就感与挫败感并存的过程，一方面不断提升计算效率很爽，一方面又感觉这种提升并非来自我的智慧而是他人完成的工作。</p><p>这篇文章虽然暂时告一段落，但是我相信，这里面依然有各种优化的空间。另外，如果矩阵更大呢？如果是稀疏矩阵呢？如果想利用多块 GPU 呢？</p><p>游戏才刚刚开始呢。</p><p>PS: 本文代码我都放到 github 上啦。 github.com/chenminhua/math</p><p>PS: 有朋友质疑为什么第一个 C 语言版本的运行时长这么慢，是不是没开编译器优化。事实上我是开了 O3 的，编译器是 gcc49。我的猜测是计算这么慢应该和内存访问有关，因为这两个数组都比较大，而内存是分页管理的，这让 cpu 不停地在不同的页上取数据，cpu 上的页表地址缓存一直不能命中，所以比较慢。网友 Antholiqi 提到，如果把左乘矩阵按行储存，右乘矩阵按列存储，计算效率大幅提升，事实确实如此。并且每个线程计算的区域最好不是一行，而是一块矩形。比如每个线程计算 64*64 的区域，则只需要扫描两个矩阵各 64 行数据即可，而不用读整个右矩阵。总而言之，第一版的 c 语言代码其实还有非常多非常多的优化空间啦。</p><p>PS: 还有网友问「Eigen 指令级别优化是啥意思」，大家可以去参考 eigen 的文档 <a href=https://github.com/libigl/eigen/blob/1f05f51517ec4fd91eed711e0f89e97a7c028c0e/doc/InsideEigenExample.dox>https://github.com/libigl/eigen/blob/1f05f51517ec4fd91eed711e0f89e97a7c028c0e/doc/InsideEigenExample.dox</a></p></div><div class=tags></div><div class=back><a href=https://chenminhua.github.io/><span aria-hidden=true>← Back</span></a></div><div class=back></div></div></div><div class="footer wrapper"><nav class=nav><div>2019</div></nav></div><script>feather.replace()</script></body></html>